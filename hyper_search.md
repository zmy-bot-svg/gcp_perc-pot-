2025-07-13 15:57:05.568457: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-07-13 15:57:05.581558: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1752393425.597167    1853 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1752393425.601749    1853 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1752393425.614282    1853 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1752393425.614298    1853 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1752393425.614300    1853 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1752393425.614301    1853 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-07-13 15:57:05.617846: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
[I 2025-07-13 15:57:07,813] Using an existing study with name 'GCPNet_PotNet_4090_hyperopt' instead of creating a new one.
‚úÖ PotNet CythonÊ®°ÂùóÂØºÂÖ•ÊàêÂäü
üóÑÔ∏è Ë∂ÖÂèÇÊï∞‰ºòÂåñ‰ªªÂä°Ôºå‰∏ªËæìÂá∫ÁõÆÂΩï: ./output_potnet_4090
üíæ Â≠òÂÇ®Ë∑ØÂæÑ (Storage): sqlite:///./output_potnet_4090/GCPNet_PotNet_4090_hyperopt.db
‚úÇÔ∏è Ââ™ÊûùÂô® (Pruner): Â∑≤‰ªéÈÖçÁΩÆÊñá‰ª∂Âä†ËΩΩ MedianPruner (ÂèÇÊï∞: {'n_startup_trials': 5, 'n_warmup_steps': 6, 'interval_steps': 2})
üî≠ ÈááÊ†∑Âô® (Sampler): Â∑≤‰ªéÈÖçÁΩÆÊñá‰ª∂Âä†ËΩΩ TPESampler (ÂèÇÊï∞: {'n_startup_trials': 10})
üìà Á†îÁ©∂Â∑≤Âä†ËΩΩÔºåÂéÜÂè≤ËØïÈ™åÊ¨°Êï∞: 32

üöÄ ÂºÄÂßã‰ºòÂåñ... Â∞ÜËøêË°å 80 Ê¨°ËØïÈ™å„ÄÇ

  0%|          | 0/80 [00:00<?, ?it/s]
üöÄ Starting Trial #32 (Seed: 986)
  Parameters:
    - lr: 0.0004375317664740182
    - dropout_rate: 0.09034034860476083
    - weight_decay: 3.51710115958272e-05
    - batch_size: 64
    - hidden_features: 192
    - coulomb_param: 1.6499801726497378
    - london_param: 0.9906353729820756
    - pauli_param: 3.612235124659038
    - R_grid: 4
train length: 12000 val length: 1500 test length: 1500 unused length: 0 seed : 986
[0;31m<<<<<< ‚ö°Ô∏è cuda is used >>>>>>[0m
‚ñà
epoch     train_loss  train_mae  train_mape  lr        val_loss  val_mae   val_mape  best_val_mae  time    
1.0       0.535       0.536      7.94e+02    0.000438  0.293     0.295     7.05e+02  0.293         32.8      
2.0       0.279       0.279      3.99e+02    0.000438  0.224     0.225     2.86e+02  0.224         32.9      
3.0       0.234       0.234      2.96e+02    0.000438  0.184     0.184     4.1e+02   0.184         32.3      
4.0       0.205       0.205      2.7e+02     0.000438  0.21      0.212     7.32e+02  0.184         32.5      
5.0       0.201       0.201      2.18e+02    0.000438  0.177     0.176     4.1e+02   0.177         33.0      

‚Äã                                      

  0%|          | 0/80 [03:17<?, ?it/s]
Best trial: 7. Best value: 0.0859608:   0%|          | 0/80 [03:17<?, ?it/s]
Best trial: 7. Best value: 0.0859608:   1%|‚ñè         | 1/80 [03:17<4:20:06, 197.54s/it]
‚úÇÔ∏è Trial #32 pruned!
[I 2025-07-13 16:00:25,345] Trial 32 pruned. 

üöÄ Starting Trial #33 (Seed: 996)
  Parameters:
    - lr: 0.001957804120049894
    - dropout_rate: 0.13309166524204724
    - weight_decay: 0.00013859034152345008
    - batch_size: 96
    - hidden_features: 160
    - coulomb_param: 1.400780530001332
    - london_param: 1.518359394336598
    - pauli_param: 1.5930369355736376
    - R_grid: 3
train length: 12000 val length: 1500 test length: 1500 unused length: 0 seed : 996
[0;31m<<<<<< ‚ö°Ô∏è cuda is used >>>>>>[0m
‚ñà
epoch     train_loss  train_mae  train_mape  lr        val_loss  val_mae   val_mape  best_val_mae  time    
1.0       0.782       0.782      4.88e+02    0.00196   0.257     0.257     6.21e+02  0.257         26.0      
2.0       0.281       0.281      2.42e+02    0.00196   0.243     0.243     3.38e+02  0.243         26.2      
3.0       0.242       0.242      2.13e+02    0.00196   0.244     0.244     1.64e+02  0.243         25.4      
4.0       0.211       0.211      2.04e+02    0.00196   0.181     0.181     5.69e+02  0.181         26.4      
5.0       0.195       0.195      1.16e+02    0.00196   0.17      0.17      1.41e+02  0.17          26.4      
6.0       0.189       0.189      1.06e+02    0.00196   0.163     0.163     2.91e+02  0.163         25.7      
7.0       0.175       0.175      1.57e+02    0.00196   0.209     0.209     4.06e+02  0.163         25.1      
8.0       0.166       0.166      1.45e+02    0.00196   0.152     0.152     2.69e+02  0.152         26.0      
9.0       0.16        0.16       68.0        0.00196   0.148     0.148     1.41e+02  0.148         26.2      
10.0      0.153       0.153      1.31e+02    0.00196   0.15      0.15      2.73e+02  0.148         25.0      
11.0      0.157       0.157      87.3        0.00196   0.162     0.162     2.7e+02   0.148         25.1      
12.0      0.147       0.147      1.53e+02    0.00196   0.137     0.137     3.1e+02   0.137         25.7      
13.0      0.14        0.14       1.56e+02    0.00196   0.14      0.141     1.77e+02  0.137         25.1      
14.0      0.136       0.136      1.7e+02     0.00196   0.13      0.13      3.1e+02   0.13          25.2      
15.0      0.131       0.131      1.5e+02     0.00196   0.122     0.122     3.04e+02  0.122         26.5      
16.0      0.126       0.126      94.4        0.00196   0.136     0.136     1.7e+02   0.122         24.9      
17.0      0.128       0.128      1.01e+02    0.00196   0.141     0.141     2.59e+02  0.122         24.9      
18.0      0.128       0.128      1.14e+02    0.00196   0.14      0.14      2.47e+02  0.122         25.0      
19.0      0.125       0.125      1.28e+02    0.00196   0.131     0.131     2.57e+02  0.122         25.4      
20.0      0.125       0.125      1.21e+02    0.00196   0.127     0.127     97.7      0.122         25.2      
21.0      0.117       0.117      1.23e+02    0.00196   0.126     0.126     2.37e+02  0.122         24.9      
22.0      0.12        0.12       90.8        0.00196   0.12      0.12      1.45e+02  0.12          25.3      
23.0      0.114       0.114      84.7        0.00196   0.113     0.113     1.86e+02  0.113         25.4      
24.0      0.112       0.112      1.29e+02    0.00196   0.123     0.123     2.51e+02  0.113         25.0      
25.0      0.108       0.108      84.7        0.00196   0.114     0.114     4.73e+02  0.113         25.4      
26.0      0.11        0.11       1.2e+02     0.00196   0.109     0.109     2.25e+02  0.109         25.6      
27.0      0.106       0.106      1.02e+02    0.00196   0.112     0.112     2.86e+02  0.109         24.8      
28.0      0.109       0.109      90.7        0.00196   0.116     0.116     1.48e+02  0.109         25.2      
29.0      0.111       0.111      1.02e+02    0.00196   0.131     0.131     3.21e+02  0.109         25.0      
30.0      0.103       0.103      1.5e+02     0.00196   0.114     0.114     2.39e+02  0.109         24.8      
31.0      0.103       0.103      1.33e+02    0.00196   0.116     0.116     2.3e+02   0.109         25.2      
32.0      0.103       0.103      1.05e+02    0.00196   0.123     0.124     3.42e+02  0.109         25.5      
33.0      0.104       0.104      1.31e+02    0.00196   0.114     0.114     2.95e+02  0.109         25.8      
34.0      0.105       0.105      94.6        0.00196   0.121     0.121     4.03e+02  0.109         24.7      
35.0      0.0997      0.0997     1.06e+02    0.00196   0.122     0.123     1.39e+02  0.109         25.0      
36.0      0.103       0.103      1.32e+02    0.00196   0.115     0.115     4.07e+02  0.109         24.7      
37.0      0.0986      0.0986     1.05e+02    0.00196   0.11      0.11      3.36e+02  0.109         24.9      
38.0      0.0796      0.0796     1.09e+02    0.000979  0.0912    0.0913    3.17e+02  0.0912        25.4      
39.0      0.0708      0.0708     83.0        0.000979  0.0914    0.0916    2.94e+02  0.0912        24.8      
40.0      0.0704      0.0704     74.2        0.000979  0.0861    0.086     3.32e+02  0.0861        25.4      
41.0      0.0664      0.0664     74.8        0.000979  0.0876    0.0877    4.96e+02  0.0861        24.8      
42.0      0.067       0.067      85.8        0.000979  0.0872    0.0874    4.5e+02   0.0861        25.0      
43.0      0.0644      0.0644     80.0        0.000979  0.0885    0.0887    7.15e+02  0.0861        24.9      
44.0      0.0674      0.0674     91.4        0.000979  0.0877    0.0877    5.28e+02  0.0861        25.3      
45.0      0.0674      0.0674     71.7        0.000979  0.0932    0.0931    4.7e+02   0.0861        25.1      
46.0      0.0657      0.0657     80.8        0.000979  0.0868    0.0867    4.35e+02  0.0861        24.6      
47.0      0.066       0.066      79.4        0.000979  0.089     0.0892    2.65e+02  0.0861        25.0      
48.0      0.0642      0.0642     76.4        0.000979  0.0894    0.0896    5.21e+02  0.0861        25.3      
49.0      0.0631      0.0631     1.04e+02    0.000979  0.0874    0.0875    5.32e+02  0.0861        25.3      
50.0      0.0642      0.0642     76.5        0.000979  0.0927    0.0927    5.05e+02  0.0861        25.1      
    epoch  train_loss  train_mae  ...    val_mape  best_val_mae       time
0       1    0.782469   0.782469  ...  620.753235      0.257278  26.007529
1       2    0.281253   0.281253  ...  337.684509      0.243449  26.194652
2       3    0.242081   0.242081  ...  163.843307      0.243449  25.375533
3       4    0.210843   0.210843  ...  569.456726      0.181143  26.386907
4       5    0.194505   0.194505  ...  140.611755      0.170473  26.377874
5       6    0.189020   0.189020  ...  291.356720      0.162501  25.654230
6       7    0.174852   0.174852  ...  406.006409      0.162501  25.072937
7       8    0.166042   0.166042  ...  269.420471      0.152074  25.999684
8       9    0.159922   0.159922  ...  140.772461      0.148479  26.150434
9      10    0.152776   0.152776  ...  273.038422      0.148479  25.002921
10     11    0.157441   0.157441  ...  269.852386      0.148479  25.131922
11     12    0.146679   0.146679  ...  310.488190      0.137077  25.693499
12     13    0.139961   0.139961  ...  177.436203      0.137077  25.148510
13     14    0.136165   0.136165  ...  309.905182      0.129729  25.226098
14     15    0.131062   0.131062  ...  303.515076      0.122070  26.494044
15     16    0.125666   0.125666  ...  169.941055      0.122070  24.884330
16     17    0.127917   0.127917  ...  259.246368      0.122070  24.932728
17     18    0.127815   0.127815  ...  246.768585      0.122070  24.997025
18     19    0.124879   0.124879  ...  257.263428      0.122070  25.444966
19     20    0.125368   0.125368  ...   97.652832      0.122070  25.200403
20     21    0.117254   0.117254  ...  237.016922      0.122070  24.876550
21     22    0.120215   0.120215  ...  145.488663      0.119610  25.263544
22     23    0.114006   0.114006  ...  185.821213      0.113486  25.383703
23     24    0.112368   0.112368  ...  250.693268      0.113486  24.953574
24     25    0.107667   0.107667  ...  473.242889      0.113486  25.445499
25     26    0.110260   0.110260  ...  224.929855      0.109123  25.566366
26     27    0.105672   0.105672  ...  286.302612      0.109123  24.816294
27     28    0.109494   0.109494  ...  148.165466      0.109123  25.234122
28     29    0.110639   0.110639  ...  320.540955      0.109123  24.972834
29     30    0.103429   0.103429  ...  239.044708      0.109123  24.808201
30     31    0.102827   0.102827  ...  229.874252      0.109123  25.190922
31     32    0.102879   0.102879  ...  341.716675      0.109123  25.511822
32     33    0.103759   0.103759  ...  295.259979      0.109123  25.802726
33     34    0.104526   0.104526  ...  403.404907      0.109123  24.723259
34     35    0.099745   0.099745  ...  139.466110      0.109123  24.955884
35     36    0.103001   0.103001  ...  407.326904      0.109123  24.671773
36     37    0.098559   0.098559  ...  336.144257      0.109123  24.912360
37     38    0.079636   0.079637  ...  316.793823      0.091243  25.410463
38     39    0.070812   0.070812  ...  293.911560      0.091243  24.838287
39     40    0.070419   0.070419  ...  332.189331      0.086125  25.365166
40     41    0.066393   0.066393  ...  496.496918      0.086125  24.757884
41     42    0.066994   0.066994  ...  450.068909      0.086125  24.998495
42     43    0.064409   0.064409  ...  715.005005      0.086125  24.904079
43     44    0.067408   0.067408  ...  528.189819      0.086125  25.255812
44     45    0.067438   0.067438  ...  469.886993      0.086125  25.078816
45     46    0.065709   0.065709  ...  434.834015      0.086125  24.611431
46     47    0.065965   0.065965  ...  264.670288      0.086125  25.034275
47     48    0.064243   0.064243  ...  520.684021      0.086125  25.280166
48     49    0.063138   0.063138  ...  531.926025      0.086125  25.276652
49     50    0.064155   0.064155  ...  505.187988      0.086125  25.070209

[50 rows x 10 columns]


  0%|                                                                        | 0/16 [00:00<?, ?it/s][A

  0%|                        | 0/16 [00:00<?, ?it/s, val_loss=0.0901, val_mae=0.0901, val_mape=0.33][A

  6%|‚ñà               | 1/16 [00:00<00:12,  1.21it/s, val_loss=0.0901, val_mae=0.0901, val_mape=0.33][A

  6%|‚ñâ              | 1/16 [00:00<00:12,  1.21it/s, val_loss=0.0884, val_mae=0.0884, val_mape=0.229][A

  6%|‚ñâ              | 1/16 [00:00<00:12,  1.21it/s, val_loss=0.0926, val_mae=0.0926, val_mape=0.361][A

 19%|‚ñà‚ñà‚ñä            | 3/16 [00:00<00:03,  3.92it/s, val_loss=0.0926, val_mae=0.0926, val_mape=0.361][A

 19%|‚ñà‚ñà‚ñà             | 3/16 [00:00<00:03,  3.92it/s, val_loss=0.0846, val_mae=0.0846, val_mape=2.32][A

 19%|‚ñà‚ñà‚ñà‚ñè             | 3/16 [00:01<00:03,  3.92it/s, val_loss=0.104, val_mae=0.104, val_mape=0.311][A

 31%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé           | 5/16 [00:01<00:01,  6.56it/s, val_loss=0.104, val_mae=0.104, val_mape=0.311][A

 31%|‚ñà‚ñà‚ñà‚ñà‚ñã          | 5/16 [00:01<00:01,  6.56it/s, val_loss=0.0901, val_mae=0.0901, val_mape=0.867][A

 31%|‚ñà‚ñà‚ñà‚ñà‚ñã          | 5/16 [00:01<00:01,  6.56it/s, val_loss=0.0682, val_mae=0.0682, val_mape=0.466][A

 44%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå        | 7/16 [00:01<00:01,  7.30it/s, val_loss=0.0682, val_mae=0.0682, val_mape=0.466][A

 44%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà         | 7/16 [00:01<00:01,  7.30it/s, val_loss=0.0836, val_mae=0.0836, val_mape=0.37][A

 44%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà         | 7/16 [00:01<00:01,  7.30it/s, val_loss=0.0822, val_mae=0.0822, val_mape=5.42][A

 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà       | 9/16 [00:01<00:00,  8.88it/s, val_loss=0.0822, val_mae=0.0822, val_mape=5.42][A

 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã        | 9/16 [00:01<00:00,  8.88it/s, val_loss=0.118, val_mae=0.118, val_mape=377][A

 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç      | 9/16 [00:01<00:00,  8.88it/s, val_loss=0.0997, val_mae=0.0997, val_mape=0.281][A

 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 11/16 [00:01<00:00, 10.41it/s, val_loss=0.0997, val_mae=0.0997, val_mape=0.281][A

 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 11/16 [00:01<00:00, 10.41it/s, val_loss=0.0709, val_mae=0.0709, val_mape=0.277][A

 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà     | 11/16 [00:01<00:00, 10.41it/s, val_loss=0.0852, val_mae=0.0852, val_mape=127][A

 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 13/16 [00:01<00:00, 11.12it/s, val_loss=0.0852, val_mae=0.0852, val_mape=127][A

 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 13/16 [00:01<00:00, 11.12it/s, val_loss=0.0873, val_mae=0.0873, val_mape=0.179][A

 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 13/16 [00:01<00:00, 11.12it/s, val_loss=0.0745, val_mae=0.0745, val_mape=0.198][A

 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 15/16 [00:01<00:00, 11.81it/s, val_loss=0.0745, val_mae=0.0745, val_mape=0.198][A

 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 15/16 [00:01<00:00, 11.81it/s, val_loss=0.0889, val_mae=0.0886, val_mape=41.8][A
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:01<00:00,  8.10it/s, val_loss=0.0889, val_mae=0.0886, val_mape=41.8]
                                                                                       

Best trial: 7. Best value: 0.0859608:   1%|‚ñè         | 1/80 [24:24<4:20:06, 197.54s/it]
Best trial: 7. Best value: 0.0859608:   1%|‚ñè         | 1/80 [24:25<4:20:06, 197.54s/it]
Best trial: 7. Best value: 0.0859608:   2%|‚ñé         | 2/80 [24:25<17:55:07, 827.02s/it]
{'val_loss': 0.08891552966088057, 'val_mae': 0.08855615556240082, 'val_mape': 41.7917366027832}

üèÅ Trial #33 completed! Result: 0.085984
[I 2025-07-13 16:21:32,993] Trial 33 finished with value: 0.08598381280899048 and parameters: {'lr': 0.001957804120049894, 'dropout_rate': 0.13309166524204724, 'weight_decay': 0.00013859034152345008, 'batch_size': 96, 'hidden_features': 160, 'coulomb_param': 1.400780530001332, 'london_param': 1.518359394336598, 'pauli_param': 1.5930369355736376, 'R_grid': 3}. Best is trial 7 with value: 0.08596083521842957.

üöÄ Starting Trial #34 (Seed: 1006)
  Parameters:
    - lr: 0.0019023534048765896
    - dropout_rate: 0.1330676123678908
    - weight_decay: 0.0001436487637450185
    - batch_size: 96
    - hidden_features: 160
    - coulomb_param: 1.3734931828336714
    - london_param: 1.532100714272999
    - pauli_param: 1.4870748620373437
    - R_grid: 3
train length: 12000 val length: 1500 test length: 1500 unused length: 0 seed : 1006
[0;31m<<<<<< ‚ö°Ô∏è cuda is used >>>>>>[0m
‚ñà
epoch     train_loss  train_mae  train_mape  lr        val_loss  val_mae   val_mape  best_val_mae  time    
1.0       0.788       0.788      1.53e+03    0.0019    0.277     0.276     2e+02     0.277         25.7      
2.0       0.273       0.273      3.19e+02    0.0019    0.244     0.245     67.3      0.244         25.3      
3.0       0.24        0.24       2.71e+02    0.0019    0.232     0.232     73.2      0.232         25.4      
4.0       0.211       0.211      1.74e+02    0.0019    0.208     0.207     94.8      0.208         25.5      
5.0       0.2         0.2        1.79e+02    0.0019    0.18      0.18      70.0      0.18          25.3      

‚Äã                                                                                        

Best trial: 7. Best value: 0.0859608:   2%|‚ñé         | 2/80 [26:58<17:55:07, 827.02s/it]
Best trial: 7. Best value: 0.0859608:   2%|‚ñé         | 2/80 [26:58<17:55:07, 827.02s/it]
Best trial: 7. Best value: 0.0859608:   4%|‚ñç         | 3/80 [26:58<11:06:32, 519.38s/it]
‚úÇÔ∏è Trial #34 pruned!
[I 2025-07-13 16:24:06,328] Trial 34 pruned. 

üöÄ Starting Trial #35 (Seed: 1016)
  Parameters:
    - lr: 0.0003037278939716166
    - dropout_rate: 0.10842631786176743
    - weight_decay: 0.0002006610338888567
    - batch_size: 96
    - hidden_features: 160
    - coulomb_param: 1.168465587162042
    - london_param: 1.7959010429824103
    - pauli_param: 2.8409946791251905
    - R_grid: 3
train length: 12000 val length: 1500 test length: 1500 unused length: 0 seed : 1016
[0;31m<<<<<< ‚ö°Ô∏è cuda is used >>>>>>[0m
‚ñà
epoch     train_loss  train_mae  train_mape  lr        val_loss  val_mae   val_mape  best_val_mae  time    
1.0       0.502       0.502      4.55e+02    0.000304  0.372     0.37      1.82e+02  0.372         25.4      
2.0       0.309       0.309      5.52e+02    0.000304  0.292     0.291     1.81e+02  0.292         25.8      
3.0       0.255       0.255      3.08e+02    0.000304  0.206     0.205     5.87      0.206         25.8      
4.0       0.211       0.211      3.29e+02    0.000304  0.261     0.261     1.02e+02  0.206         25.1      
5.0       0.201       0.201      2.96e+02    0.000304  0.201     0.201     93.2      0.201         25.8      
6.0       0.174       0.174      2.73e+02    0.000304  0.169     0.169     1.52e+02  0.169         26.0      
7.0       0.168       0.168      2.12e+02    0.000304  0.183     0.183     7.42      0.169         24.9      
8.0       0.166       0.166      2.63e+02    0.000304  0.147     0.147     46.8      0.147         25.7      
9.0       0.159       0.159      2.05e+02    0.000304  0.152     0.152     70.1      0.147         25.1      
10.0      0.15        0.15       1.94e+02    0.000304  0.136     0.136     10.8      0.136         25.5      
11.0      0.145       0.145      1.81e+02    0.000304  0.167     0.167     14.1      0.136         25.5      
12.0      0.149       0.149      1.67e+02    0.000304  0.149     0.15      64.4      0.136         25.1      
13.0      0.142       0.142      1.28e+02    0.000304  0.144     0.145     63.9      0.136         25.1      
14.0      0.133       0.133      1.72e+02    0.000304  0.132     0.133     3.49      0.132         25.9      
15.0      0.133       0.133      1.64e+02    0.000304  0.143     0.142     2.94      0.132         25.0      
16.0      0.132       0.132      1.57e+02    0.000304  0.132     0.132     3.29      0.132         25.4      
17.0      0.13        0.13       1.78e+02    0.000304  0.133     0.133     49.4      0.132         25.4      
18.0      0.125       0.125      1.44e+02    0.000304  0.122     0.122     26.8      0.122         25.6      
19.0      0.122       0.122      1.89e+02    0.000304  0.142     0.142     4.23      0.122         25.0      
20.0      0.118       0.118      1.11e+02    0.000304  0.118     0.118     25.0      0.118         25.7      
21.0      0.118       0.118      1.43e+02    0.000304  0.12      0.121     21.5      0.118         25.1      
22.0      0.114       0.114      1.2e+02     0.000304  0.118     0.119     14.3      0.118         25.3      
23.0      0.114       0.114      1.2e+02     0.000304  0.118     0.118     21.2      0.118         25.3      
24.0      0.107       0.107      1.14e+02    0.000304  0.11      0.111     2.94      0.11          25.6      
25.0      0.111       0.111      1.03e+02    0.000304  0.13      0.13      15.7      0.11          25.2      
26.0      0.108       0.108      1.3e+02     0.000304  0.125     0.125     6.49      0.11          25.5      
27.0      0.101       0.101      1.05e+02    0.000304  0.116     0.117     68.4      0.11          25.0      
28.0      0.103       0.103      92.1        0.000304  0.112     0.113     27.7      0.11          25.0      
29.0      0.0989      0.0989     1.18e+02    0.000304  0.11      0.11      3.66      0.11          25.5      
30.0      0.102       0.102      1.36e+02    0.000304  0.124     0.124     49.8      0.11          25.1      
31.0      0.0998      0.0998     1.2e+02     0.000304  0.109     0.109     26.9      0.109         26.0      
32.0      0.0993      0.0993     1.05e+02    0.000304  0.112     0.113     16.2      0.109         25.7      
33.0      0.0944      0.0944     92.8        0.000304  0.116     0.116     12.9      0.109         25.7      
34.0      0.0957      0.0957     96.4        0.000304  0.112     0.113     10.4      0.109         24.9      
35.0      0.0979      0.0979     1.36e+02    0.000304  0.104     0.105     7.59      0.104         26.7      
36.0      0.0944      0.0944     1.46e+02    0.000304  0.109     0.11      4.99      0.104         24.4      
37.0      0.094       0.094      1.13e+02    0.000304  0.105     0.105     15.2      0.104         25.3      
38.0      0.0946      0.0946     1.16e+02    0.000304  0.12      0.12      15.9      0.104         25.6      
39.0      0.0947      0.0947     1.11e+02    0.000304  0.111     0.112     4.53      0.104         25.3      
40.0      0.0923      0.0923     1.05e+02    0.000304  0.108     0.108     2.96      0.104         24.8      
41.0      0.0858      0.0858     1.09e+02    0.000304  0.109     0.109     9.11      0.104         24.6      
42.0      0.088       0.088      95.5        0.000304  0.107     0.108     9.4       0.104         25.1      
43.0      0.0869      0.0869     95.4        0.000304  0.116     0.116     7.11      0.104         25.1      

‚Äã                                                                                        

Best trial: 7. Best value: 0.0859608:   4%|‚ñç         | 3/80 [45:35<11:06:32, 519.38s/it]
Best trial: 7. Best value: 0.0859608:   4%|‚ñç         | 3/80 [45:35<11:06:32, 519.38s/it]
Best trial: 7. Best value: 0.0859608:   5%|‚ñå         | 4/80 [45:35<15:56:47, 755.37s/it]
‚úÇÔ∏è Trial #35 pruned!
[I 2025-07-13 16:42:43,412] Trial 35 pruned. 

üöÄ Starting Trial #36 (Seed: 1026)
  Parameters:
    - lr: 0.0016307796197042364
    - dropout_rate: 0.15534699823145268
    - weight_decay: 1.1213901299461896e-05
    - batch_size: 96
    - hidden_features: 160
    - coulomb_param: 1.4776116390610288
    - london_param: 1.402420454213782
    - pauli_param: 1.2491438518601683
    - R_grid: 3
train length: 12000 val length: 1500 test length: 1500 unused length: 0 seed : 1026
[0;31m<<<<<< ‚ö°Ô∏è cuda is used >>>>>>[0m
‚ñà
epoch     train_loss  train_mae  train_mape  lr        val_loss  val_mae   val_mape  best_val_mae  time    
1.0       0.768       0.768      7.95e+02    0.00163   0.329     0.329     5.8e+02   0.329         25.8      
2.0       0.283       0.283      3.8e+02     0.00163   0.315     0.314     4.11e+02  0.315         25.8      
3.0       0.248       0.248      3.66e+02    0.00163   0.257     0.257     3.89e+02  0.257         25.4      
4.0       0.234       0.234      2.3e+02     0.00163   0.21      0.209     1.78e+02  0.21          25.6      
5.0       0.219       0.219      2.66e+02    0.00163   0.204     0.204     1.47e+02  0.204         25.7      

‚Äã                                                                                        

Best trial: 7. Best value: 0.0859608:   5%|‚ñå         | 4/80 [48:09<15:56:47, 755.37s/it]
Best trial: 7. Best value: 0.0859608:   5%|‚ñå         | 4/80 [48:09<15:56:47, 755.37s/it]
Best trial: 7. Best value: 0.0859608:   6%|‚ñã         | 5/80 [48:09<11:13:17, 538.64s/it]
‚úÇÔ∏è Trial #36 pruned!
[I 2025-07-13 16:45:17,800] Trial 36 pruned. 

üöÄ Starting Trial #37 (Seed: 1036)
  Parameters:
    - lr: 0.002333361591246197
    - dropout_rate: 0.2002214192063848
    - weight_decay: 7.593448205898473e-05
    - batch_size: 96
    - hidden_features: 128
    - coulomb_param: 1.3870928431687743
    - london_param: 1.1970714279456336
    - pauli_param: 1.710922863012887
    - R_grid: 5
train length: 12000 val length: 1500 test length: 1500 unused length: 0 seed : 1036
[0;31m<<<<<< ‚ö°Ô∏è cuda is used >>>>>>[0m
‚ñà
epoch     train_loss  train_mae  train_mape  lr        val_loss  val_mae   val_mape  best_val_mae  time    
1.0       0.738       0.738      6.4e+02     0.00233   0.333     0.332     83.6      0.333         22.0      
2.0       0.274       0.274      3.04e+02    0.00233   0.26      0.259     83.9      0.26          22.1      
3.0       0.247       0.247      2.07e+02    0.00233   0.268     0.267     1.02e+02  0.26          21.7      
4.0       0.218       0.218      1.95e+02    0.00233   0.217     0.218     1.24e+02  0.217         22.1      
5.0       0.205       0.205      1.71e+02    0.00233   0.206     0.206     84.2      0.206         21.4      

‚Äã                                                                                        

Best trial: 7. Best value: 0.0859608:   6%|‚ñã         | 5/80 [50:21<11:13:17, 538.64s/it]
Best trial: 7. Best value: 0.0859608:   6%|‚ñã         | 5/80 [50:21<11:13:17, 538.64s/it]
Best trial: 7. Best value: 0.0859608:   8%|‚ñä         | 6/80 [50:21<8:13:40, 400.27s/it] 
‚úÇÔ∏è Trial #37 pruned!
[I 2025-07-13 16:47:29,464] Trial 37 pruned. 

üöÄ Starting Trial #38 (Seed: 1046)
  Parameters:
    - lr: 0.0009445161721234186
    - dropout_rate: 0.21979756242688378
    - weight_decay: 5.5904224169563465e-05
    - batch_size: 48
    - hidden_features: 160
    - coulomb_param: 1.8756750237772453
    - london_param: 1.4622386239556908
    - pauli_param: 1.2310839672943181
    - R_grid: 3
train length: 12000 val length: 1500 test length: 1500 unused length: 0 seed : 1046
[0;31m<<<<<< ‚ö°Ô∏è cuda is used >>>>>>[0m
‚ñà
epoch     train_loss  train_mae  train_mape  lr        val_loss  val_mae   val_mape  best_val_mae  time    
1.0       0.563       0.563      7.28e+02    0.000945  0.315     0.316     2.5e+02   0.315         34.4      
2.0       0.282       0.282      4.46e+02    0.000945  0.209     0.21      95.4      0.209         34.2      
3.0       0.238       0.238      3.78e+02    0.000945  0.189     0.188     53.3      0.189         34.9      
4.0       0.209       0.209      1.92e+02    0.000945  0.171     0.173     1.81e+02  0.171         34.5      
5.0       0.188       0.188      2.46e+02    0.000945  0.221     0.223     58.1      0.171         34.2      

‚Äã                                                                                       

Best trial: 7. Best value: 0.0859608:   8%|‚ñä         | 6/80 [53:47<8:13:40, 400.27s/it]
Best trial: 7. Best value: 0.0859608:   8%|‚ñä         | 6/80 [53:47<8:13:40, 400.27s/it]
Best trial: 7. Best value: 0.0859608:   9%|‚ñâ         | 7/80 [53:47<6:49:50, 336.86s/it]
‚úÇÔ∏è Trial #38 pruned!
[I 2025-07-13 16:50:55,719] Trial 38 pruned. 

üöÄ Starting Trial #39 (Seed: 1056)
  Parameters:
    - lr: 0.0022844034248751515
    - dropout_rate: 0.14456032108784306
    - weight_decay: 0.00031660538843579424
    - batch_size: 96
    - hidden_features: 128
    - coulomb_param: 1.6063249312754972
    - london_param: 1.7688818468767729
    - pauli_param: 2.182917266101808
    - R_grid: 5
train length: 12000 val length: 1500 test length: 1500 unused length: 0 seed : 1056
[0;31m<<<<<< ‚ö°Ô∏è cuda is used >>>>>>[0m
‚ñà
epoch     train_loss  train_mae  train_mape  lr        val_loss  val_mae   val_mape  best_val_mae  time    
1.0       0.81        0.81       4.9e+02     0.00228   0.301     0.301     4.37e+02  0.301         21.9      
2.0       0.265       0.265      4.04e+02    0.00228   0.287     0.288     2.72e+02  0.287         21.8      
3.0       0.246       0.246      3.28e+02    0.00228   0.271     0.271     2.6e+02   0.271         22.0      
4.0       0.228       0.228      3.29e+02    0.00228   0.214     0.214     2.65e+02  0.214         22.0      
5.0       0.208       0.208      1.62e+02    0.00228   0.203     0.203     2.98e+02  0.203         21.4      

‚Äã                                                                                       

Best trial: 7. Best value: 0.0859608:   9%|‚ñâ         | 7/80 [55:58<6:49:50, 336.86s/it]
Best trial: 7. Best value: 0.0859608:   9%|‚ñâ         | 7/80 [55:59<6:49:50, 336.86s/it]
Best trial: 7. Best value: 0.0859608:  10%|‚ñà         | 8/80 [55:59<5:25:41, 271.42s/it]
‚úÇÔ∏è Trial #39 pruned!
[I 2025-07-13 16:53:07,047] Trial 39 pruned. 

üöÄ Starting Trial #40 (Seed: 1066)
  Parameters:
    - lr: 0.0011529561566842388
    - dropout_rate: 0.2184238758982033
    - weight_decay: 0.00010935556137115826
    - batch_size: 96
    - hidden_features: 160
    - coulomb_param: 1.7342024577712019
    - london_param: 1.6021603493488157
    - pauli_param: 3.261853894290747
    - R_grid: 4
train length: 12000 val length: 1500 test length: 1500 unused length: 0 seed : 1066
[0;31m<<<<<< ‚ö°Ô∏è cuda is used >>>>>>[0m
‚ñà
epoch     train_loss  train_mae  train_mape  lr        val_loss  val_mae   val_mape  best_val_mae  time    
1.0       0.721       0.721      1.29e+03    0.00115   0.307     0.307     95.4      0.307         25.8      
2.0       0.282       0.282      4.59e+02    0.00115   0.234     0.234     52.3      0.234         26.1      
3.0       0.256       0.256      4.09e+02    0.00115   0.231     0.232     1.06e+02  0.231         25.6      
4.0       0.215       0.215      2.52e+02    0.00115   0.215     0.215     73.7      0.215         26.0      
5.0       0.201       0.201      2.95e+02    0.00115   0.191     0.191     45.8      0.191         25.6      

‚Äã                                                                                       

Best trial: 7. Best value: 0.0859608:  10%|‚ñà         | 8/80 [58:33<5:25:41, 271.42s/it]
Best trial: 7. Best value: 0.0859608:  10%|‚ñà         | 8/80 [58:34<5:25:41, 271.42s/it]
Best trial: 7. Best value: 0.0859608:  11%|‚ñà‚ñè        | 9/80 [58:34<4:38:08, 235.04s/it]
‚úÇÔ∏è Trial #40 pruned!
[I 2025-07-13 16:55:42,102] Trial 40 pruned. 

üöÄ Starting Trial #41 (Seed: 1076)
  Parameters:
    - lr: 0.0015644539432556283
    - dropout_rate: 0.13197490208316084
    - weight_decay: 5.925821651363181e-06
    - batch_size: 48
    - hidden_features: 160
    - coulomb_param: 1.2605168301783873
    - london_param: 0.679903146028241
    - pauli_param: 2.8238963084593696
    - R_grid: 4
train length: 12000 val length: 1500 test length: 1500 unused length: 0 seed : 1076
[0;31m<<<<<< ‚ö°Ô∏è cuda is used >>>>>>[0m
‚ñà
epoch     train_loss  train_mae  train_mape  lr        val_loss  val_mae   val_mape  best_val_mae  time    
1.0       0.582       0.582      3.32e+02    0.00156   0.264     0.261     1.27e+02  0.264         34.0      
2.0       0.267       0.267      3.21e+02    0.00156   0.227     0.225     2.78e+02  0.227         34.3      
3.0       0.249       0.249      1.93e+02    0.00156   0.202     0.2       1.32e+02  0.202         35.3      
4.0       0.216       0.216      2.78e+02    0.00156   0.192     0.189     1.23e+02  0.192         34.8      
5.0       0.201       0.201      1.65e+02    0.00156   0.181     0.178     2.35e+02  0.181         33.8      
6.0       0.184       0.184      1.51e+02    0.00156   0.159     0.159     68.1      0.159         34.7      
7.0       0.172       0.172      1.24e+02    0.00156   0.153     0.15      56.4      0.153         34.5      
8.0       0.175       0.175      1.34e+02    0.00156   0.148     0.147     90.1      0.148         34.5      
9.0       0.164       0.164      1.39e+02    0.00156   0.136     0.136     1.53e+02  0.136         35.1      
10.0      0.153       0.153      1.26e+02    0.00156   0.144     0.143     86.6      0.136         33.5      
11.0      0.156       0.156      1.09e+02    0.00156   0.166     0.166     1.36e+02  0.136         33.8      
12.0      0.147       0.147      1.15e+02    0.00156   0.13      0.13      1.24e+02  0.13          35.0      
13.0      0.141       0.141      1.02e+02    0.00156   0.175     0.174     1.01e+02  0.13          33.8      
14.0      0.143       0.143      1.42e+02    0.00156   0.13      0.129     1.59e+02  0.13          34.4      
15.0      0.135       0.135      1.21e+02    0.00156   0.131     0.13      1.21e+02  0.13          34.9      
16.0      0.133       0.133      1.13e+02    0.00156   0.154     0.154     1.02e+02  0.13          34.6      
17.0      0.131       0.131      1.42e+02    0.00156   0.129     0.128     77.3      0.129         35.2      
18.0      0.13        0.13       1.35e+02    0.00156   0.133     0.132     1.79e+02  0.129         34.7      
19.0      0.126       0.126      1.7e+02     0.00156   0.144     0.143     88.0      0.129         34.5      
20.0      0.127       0.127      1.22e+02    0.00156   0.122     0.123     92.5      0.122         34.6      
21.0      0.125       0.125      1.22e+02    0.00156   0.129     0.129     85.2      0.122         34.4      
22.0      0.119       0.119      1.45e+02    0.00156   0.148     0.146     1.62e+02  0.122         34.4      
23.0      0.123       0.123      1.43e+02    0.00156   0.124     0.123     60.5      0.122         34.4      
24.0      0.118       0.118      1.35e+02    0.00156   0.138     0.136     1.61e+02  0.122         34.2      
25.0      0.117       0.117      1.11e+02    0.00156   0.12      0.117     1.91e+02  0.12          35.0      

‚Äã                                                                                       

Best trial: 7. Best value: 0.0859608:  11%|‚ñà‚ñè        | 9/80 [1:13:31<4:38:08, 235.04s/it]
Best trial: 7. Best value: 0.0859608:  11%|‚ñà‚ñè        | 9/80 [1:13:31<4:38:08, 235.04s/it]
Best trial: 7. Best value: 0.0859608:  12%|‚ñà‚ñé        | 10/80 [1:13:31<8:32:46, 439.52s/it]
‚úÇÔ∏è Trial #41 pruned!
[I 2025-07-13 17:10:39,492] Trial 41 pruned. 

üöÄ Starting Trial #42 (Seed: 1086)
  Parameters:
    - lr: 0.0008370744598947401
    - dropout_rate: 0.08819590024609822
    - weight_decay: 1.8099728885390102e-06
    - batch_size: 128
    - hidden_features: 192
    - coulomb_param: 0.6367916168178374
    - london_param: 1.8914573809483144
    - pauli_param: 1.6474548137551404
    - R_grid: 3
train length: 12000 val length: 1500 test length: 1500 unused length: 0 seed : 1086
[0;31m<<<<<< ‚ö°Ô∏è cuda is used >>>>>>[0m
‚ñà
epoch     train_loss  train_mae  train_mape  lr        val_loss  val_mae   val_mape  best_val_mae  time    
1.0       0.694       0.695      6.59e+02    0.000837  0.296     0.296     2.63e+02  0.296         28.6      
2.0       0.304       0.304      3.1e+02     0.000837  0.344     0.344     1.61e+02  0.296         27.4      
3.0       0.246       0.246      2.2e+02     0.000837  0.235     0.235     1.38e+02  0.235         28.5      
4.0       0.202       0.201      2.24e+02    0.000837  0.183     0.183     1.07e+02  0.183         28.5      
5.0       0.192       0.192      1.94e+02    0.000837  0.18      0.18      1.2e+02   0.18          28.0      
6.0       0.181       0.181      2.15e+02    0.000837  0.16      0.16      1.17e+02  0.16          27.9      
7.0       0.172       0.171      2.23e+02    0.000837  0.194     0.194     99.7      0.16          27.4      

‚Äã                                                                                          

Best trial: 7. Best value: 0.0859608:  12%|‚ñà‚ñé        | 10/80 [1:17:15<8:32:46, 439.52s/it]
Best trial: 7. Best value: 0.0859608:  12%|‚ñà‚ñé        | 10/80 [1:17:16<8:32:46, 439.52s/it]
Best trial: 7. Best value: 0.0859608:  14%|‚ñà‚ñç        | 11/80 [1:17:16<7:09:43, 373.68s/it]
‚úÇÔ∏è Trial #42 pruned!
[I 2025-07-13 17:14:23,896] Trial 42 pruned. 

üöÄ Starting Trial #43 (Seed: 1096)
  Parameters:
    - lr: 0.0012132868745427224
    - dropout_rate: 0.171159864591199
    - weight_decay: 2.2971898781773332e-05
    - batch_size: 96
    - hidden_features: 128
    - coulomb_param: 1.505647143933176
    - london_param: 1.7057049351974314
    - pauli_param: 1.0000652975981286
    - R_grid: 4
train length: 12000 val length: 1500 test length: 1500 unused length: 0 seed : 1096
[0;31m<<<<<< ‚ö°Ô∏è cuda is used >>>>>>[0m
‚ñà
epoch     train_loss  train_mae  train_mape  lr        val_loss  val_mae   val_mape  best_val_mae  time    
1.0       0.588       0.588      1.13e+03    0.00121   0.265     0.266     85.8      0.265         21.8      
2.0       0.269       0.269      5.27e+02    0.00121   0.195     0.196     1.68e+02  0.195         21.5      
3.0       0.243       0.243      2.95e+02    0.00121   0.193     0.193     1.77e+02  0.193         21.9      
4.0       0.216       0.216      3.37e+02    0.00121   0.226     0.226     62.2      0.193         21.1      
5.0       0.195       0.195      3.16e+02    0.00121   0.191     0.191     1.42e+02  0.191         21.8      
6.0       0.175       0.175      2.33e+02    0.00121   0.153     0.153     82.7      0.153         21.8      
7.0       0.176       0.176      2.55e+02    0.00121   0.173     0.174     72.0      0.153         21.1      
8.0       0.16        0.16       2.65e+02    0.00121   0.152     0.153     58.5      0.152         21.6      
9.0       0.158       0.158      2.66e+02    0.00121   0.161     0.162     14.2      0.152         22.0      

‚Äã                                                                                          

Best trial: 7. Best value: 0.0859608:  14%|‚ñà‚ñç        | 11/80 [1:20:52<7:09:43, 373.68s/it]
Best trial: 7. Best value: 0.0859608:  14%|‚ñà‚ñç        | 11/80 [1:20:52<7:09:43, 373.68s/it]
Best trial: 7. Best value: 0.0859608:  15%|‚ñà‚ñå        | 12/80 [1:20:52<6:09:13, 325.79s/it]
‚úÇÔ∏è Trial #43 pruned!
[I 2025-07-13 17:18:00,109] Trial 43 pruned. 

üöÄ Starting Trial #44 (Seed: 1106)
  Parameters:
    - lr: 0.0006860561524423489
    - dropout_rate: 0.11483439699586584
    - weight_decay: 0.00027373409132384603
    - batch_size: 48
    - hidden_features: 96
    - coulomb_param: 0.9361045330961029
    - london_param: 0.8604613056528729
    - pauli_param: 3.821742588059063
    - R_grid: 5
train length: 12000 val length: 1500 test length: 1500 unused length: 0 seed : 1106
[0;31m<<<<<< ‚ö°Ô∏è cuda is used >>>>>>[0m
‚ñà
epoch     train_loss  train_mae  train_mape  lr        val_loss  val_mae   val_mape  best_val_mae  time    
1.0       0.465       0.465      5.9e+02     0.000686  0.294     0.296     3.71e+02  0.294         31.5      
2.0       0.265       0.265      3.35e+02    0.000686  0.187     0.188     1.99e+02  0.187         31.2      
3.0       0.22        0.22       2.16e+02    0.000686  0.174     0.175     2.17e+02  0.174         31.1      
4.0       0.193       0.193      2.29e+02    0.000686  0.173     0.174     2.92e+02  0.173         30.7      
5.0       0.186       0.186      2.18e+02    0.000686  0.239     0.24      1e+02     0.173         30.9      
6.0       0.176       0.176      2.45e+02    0.000686  0.147     0.148     53.5      0.147         30.6      
7.0       0.16        0.16       1.52e+02    0.000686  0.166     0.167     48.9      0.147         32.2      
8.0       0.155       0.155      1.67e+02    0.000686  0.142     0.143     1.48e+02  0.142         33.3      
9.0       0.162       0.162      2.02e+02    0.000686  0.175     0.175     85.8      0.142         31.8      
10.0      0.148       0.148      2.25e+02    0.000686  0.196     0.196     1.4e+02   0.142         31.8      
11.0      0.145       0.145      1.47e+02    0.000686  0.185     0.185     55.5      0.142         31.8      
12.0      0.137       0.137      1.39e+02    0.000686  0.138     0.139     1.61e+02  0.138         32.8      
13.0      0.137       0.137      1.94e+02    0.000686  0.15      0.151     1.57e+02  0.138         31.7      
14.0      0.138       0.138      1.89e+02    0.000686  0.138     0.139     73.1      0.138         32.3      
15.0      0.132       0.132      1.36e+02    0.000686  0.139     0.14      2.14e+02  0.138         31.2      
16.0      0.127       0.127      1.4e+02     0.000686  0.129     0.129     1.25e+02  0.129         31.2      
17.0      0.127       0.127      1.77e+02    0.000686  0.126     0.127     41.7      0.126         32.3      
18.0      0.121       0.121      1.15e+02    0.000686  0.124     0.125     1.19e+02  0.124         32.1      
19.0      0.12        0.12       1.23e+02    0.000686  0.118     0.119     1.02e+02  0.118         31.9      
20.0      0.121       0.121      1.55e+02    0.000686  0.118     0.118     1.83e+02  0.118         31.6      
21.0      0.116       0.116      1.15e+02    0.000686  0.12      0.119     2.06e+02  0.118         31.4      
22.0      0.116       0.116      1.48e+02    0.000686  0.126     0.127     61.8      0.118         31.1      
23.0      0.109       0.109      1.1e+02     0.000686  0.123     0.124     1.37e+02  0.118         32.0      
24.0      0.109       0.109      1.13e+02    0.000686  0.115     0.116     1.51e+02  0.115         31.9      
25.0      0.106       0.106      1.12e+02    0.000686  0.11      0.11      50.5      0.11          31.0      
26.0      0.105       0.105      1.09e+02    0.000686  0.126     0.126     1.49e+02  0.11          31.2      
27.0      0.106       0.106      1.11e+02    0.000686  0.124     0.123     1.01e+02  0.11          31.2      
28.0      0.104       0.104      1.3e+02     0.000686  0.138     0.14      95.2      0.11          31.6      
29.0      0.1         0.1        1.12e+02    0.000686  0.105     0.106     1.08e+02  0.105         32.0      
30.0      0.099       0.099      1.08e+02    0.000686  0.105     0.106     37.2      0.105         31.7      
31.0      0.0978      0.0978     1.27e+02    0.000686  0.125     0.125     1.07e+02  0.105         31.2      
32.0      0.0958      0.0958     96.8        0.000686  0.11      0.111     1.53e+02  0.105         31.0      
33.0      0.0928      0.0928     97.8        0.000686  0.101     0.102     44.2      0.101         31.2      
34.0      0.0931      0.0931     76.7        0.000686  0.108     0.108     52.9      0.101         31.3      
35.0      0.0911      0.0911     1.31e+02    0.000686  0.122     0.122     67.1      0.101         30.9      
36.0      0.09        0.09       1.05e+02    0.000686  0.108     0.109     17.8      0.101         31.5      
37.0      0.0893      0.0893     92.2        0.000686  0.106     0.106     55.1      0.101         30.9      
38.0      0.0873      0.0873     72.3        0.000686  0.0963    0.0977    63.4      0.0963        31.6      
39.0      0.0871      0.0871     72.3        0.000686  0.106     0.107     67.2      0.0963        31.0      
40.0      0.0887      0.0887     1.18e+02    0.000686  0.0984    0.0994    65.2      0.0963        31.5      
41.0      0.0855      0.0855     79.8        0.000686  0.0972    0.0977    93.0      0.0963        31.6      
42.0      0.0848      0.0848     58.3        0.000686  0.101     0.101     39.1      0.0963        29.9      
43.0      0.0828      0.0828     80.6        0.000686  0.0992    0.1       1.12e+02  0.0963        31.0      
44.0      0.0791      0.0791     71.6        0.000686  0.103     0.105     51.3      0.0963        31.1      
45.0      0.0785      0.0785     83.8        0.000686  0.0961    0.097     60.4      0.0961        31.9      
46.0      0.0781      0.0781     95.7        0.000686  0.099     0.1       88.1      0.0961        31.1      
47.0      0.0786      0.0786     78.2        0.000686  0.103     0.103     94.4      0.0961        31.3      
48.0      0.0766      0.0766     79.9        0.000686  0.101     0.102     47.9      0.0961        31.5      
49.0      0.0777      0.0777     77.9        0.000686  0.0936    0.0949    41.7      0.0936        31.4      
50.0      0.0773      0.0773     79.2        0.000686  0.0991    0.101     91.9      0.0936        31.4      
    epoch  train_loss  train_mae  ...    val_mape  best_val_mae       time
0       1    0.465164   0.465164  ...  371.123535      0.294232  31.543520
1       2    0.264959   0.264959  ...  199.420776      0.186778  31.158905
2       3    0.219772   0.219772  ...  216.796371      0.174128  31.137059
3       4    0.193472   0.193472  ...  292.248535      0.172589  30.683604
4       5    0.186341   0.186341  ...  100.310684      0.172589  30.898163
5       6    0.175550   0.175550  ...   53.465874      0.146874  30.632910
6       7    0.159848   0.159848  ...   48.873260      0.146874  32.157482
7       8    0.155463   0.155463  ...  148.399704      0.141988  33.276482
8       9    0.161743   0.161743  ...   85.776955      0.141988  31.819371
9      10    0.147599   0.147599  ...  140.086502      0.141988  31.779728
10     11    0.145309   0.145309  ...   55.527271      0.141988  31.819313
11     12    0.137077   0.137077  ...  160.516037      0.137585  32.778432
12     13    0.136824   0.136824  ...  156.710526      0.137585  31.696873
13     14    0.138354   0.138354  ...   73.077393      0.137585  32.349431
14     15    0.131525   0.131525  ...  213.869339      0.137585  31.193548
15     16    0.127376   0.127376  ...  124.675613      0.128836  31.176450
16     17    0.126994   0.126994  ...   41.686516      0.126306  32.270488
17     18    0.121186   0.121186  ...  118.941498      0.124378  32.073498
18     19    0.120344   0.120344  ...  102.359581      0.118495  31.881467
19     20    0.120547   0.120547  ...  182.548080      0.118268  31.560818
20     21    0.115511   0.115511  ...  206.040100      0.118268  31.442166
21     22    0.116028   0.116028  ...   61.799683      0.118268  31.118848
22     23    0.108572   0.108572  ...  136.903214      0.118268  31.983921
23     24    0.108826   0.108826  ...  151.183945      0.114971  31.889276
24     25    0.105985   0.105985  ...   50.492611      0.109702  31.049767
25     26    0.104765   0.104765  ...  148.643982      0.109702  31.249630
26     27    0.105561   0.105561  ...  101.032188      0.109702  31.199123
27     28    0.104174   0.104174  ...   95.201576      0.109702  31.641514
28     29    0.100238   0.100238  ...  108.401711      0.104729  31.993562
29     30    0.098964   0.098964  ...   37.161388      0.104729  31.670032
30     31    0.097801   0.097801  ...  107.140846      0.104729  31.202079
31     32    0.095807   0.095807  ...  153.349976      0.104729  31.028915
32     33    0.092763   0.092763  ...   44.169392      0.101498  31.194391
33     34    0.093051   0.093051  ...   52.885368      0.101498  31.315070
34     35    0.091089   0.091089  ...   67.076248      0.101498  30.918537
35     36    0.090024   0.090024  ...   17.768124      0.101498  31.472179
36     37    0.089260   0.089260  ...   55.089108      0.101498  30.900531
37     38    0.087307   0.087307  ...   63.407204      0.096287  31.612864
38     39    0.087109   0.087109  ...   67.222649      0.096287  31.045388
39     40    0.088663   0.088663  ...   65.229538      0.096287  31.474317
40     41    0.085508   0.085508  ...   93.000458      0.096287  31.636669
41     42    0.084825   0.084825  ...   39.052158      0.096287  29.946211
42     43    0.082827   0.082827  ...  112.040009      0.096287  30.977292
43     44    0.079056   0.079056  ...   51.300499      0.096287  31.112498
44     45    0.078529   0.078529  ...   60.417141      0.096092  31.894321
45     46    0.078126   0.078126  ...   88.117012      0.096092  31.061798
46     47    0.078639   0.078639  ...   94.389343      0.096092  31.306099
47     48    0.076630   0.076630  ...   47.852463      0.096092  31.495032
48     49    0.077710   0.077710  ...   41.704247      0.093649  31.380401
49     50    0.077296   0.077296  ...   91.924126      0.093649  31.404261

[50 rows x 10 columns]


  0%|                                                                        | 0/32 [00:00<?, ?it/s][A

  0%|                          | 0/32 [00:00<?, ?it/s, val_loss=0.114, val_mae=0.114, val_mape=2.46][A

  3%|‚ñå                 | 1/32 [00:00<00:21,  1.41it/s, val_loss=0.114, val_mae=0.114, val_mape=2.46][A

  3%|‚ñå                | 1/32 [00:00<00:21,  1.41it/s, val_loss=0.0696, val_mae=0.0696, val_mape=436][A

  6%|‚ñà                | 2/32 [00:00<00:10,  2.79it/s, val_loss=0.0696, val_mae=0.0696, val_mape=436][A

  6%|‚ñâ              | 2/32 [00:00<00:10,  2.79it/s, val_loss=0.0967, val_mae=0.0967, val_mape=0.323][A

  6%|‚ñà                | 2/32 [00:00<00:10,  2.79it/s, val_loss=0.0978, val_mae=0.0978, val_mape=2.3][A

  6%|‚ñà               | 2/32 [00:00<00:10,  2.79it/s, val_loss=0.0919, val_mae=0.0919, val_mape=0.75][A

  6%|‚ñà                | 2/32 [00:00<00:10,  2.79it/s, val_loss=0.102, val_mae=0.102, val_mape=0.162][A

 19%|‚ñà‚ñà‚ñà‚ñè             | 6/32 [00:00<00:02,  9.13it/s, val_loss=0.102, val_mae=0.102, val_mape=0.162][A

 19%|‚ñà‚ñà‚ñä            | 6/32 [00:00<00:02,  9.13it/s, val_loss=0.0889, val_mae=0.0889, val_mape=0.146][A

 19%|‚ñà‚ñà‚ñà‚ñè             | 6/32 [00:01<00:02,  9.13it/s, val_loss=0.143, val_mae=0.143, val_mape=0.255][A

 19%|‚ñà‚ñà‚ñä            | 6/32 [00:01<00:02,  9.13it/s, val_loss=0.0819, val_mae=0.0819, val_mape=0.211][A

 19%|‚ñà‚ñà‚ñä            | 6/32 [00:01<00:02,  9.13it/s, val_loss=0.0741, val_mae=0.0741, val_mape=0.281][A

 31%|‚ñà‚ñà‚ñà‚ñà‚ñç         | 10/32 [00:01<00:01, 14.58it/s, val_loss=0.0741, val_mae=0.0741, val_mape=0.281][A

 31%|‚ñà‚ñà‚ñà‚ñà‚ñã          | 10/32 [00:01<00:01, 14.58it/s, val_loss=0.0788, val_mae=0.0788, val_mape=28.3][A

 31%|‚ñà‚ñà‚ñà‚ñà‚ñç         | 10/32 [00:01<00:01, 14.58it/s, val_loss=0.0823, val_mae=0.0823, val_mape=0.277][A

 31%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé           | 10/32 [00:01<00:01, 14.58it/s, val_loss=0.129, val_mae=0.129, val_mape=3.04][A

 41%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ          | 13/32 [00:01<00:01, 16.48it/s, val_loss=0.129, val_mae=0.129, val_mape=3.04][A

 41%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã        | 13/32 [00:01<00:01, 16.48it/s, val_loss=0.0827, val_mae=0.0827, val_mape=0.189][A

 41%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé          | 13/32 [00:01<00:01, 16.48it/s, val_loss=0.102, val_mae=0.102, val_mape=187][A

 41%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ          | 13/32 [00:01<00:01, 16.48it/s, val_loss=0.098, val_mae=0.098, val_mape=0.22][A

 50%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå        | 16/32 [00:01<00:00, 17.39it/s, val_loss=0.098, val_mae=0.098, val_mape=0.22][A

 50%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà      | 16/32 [00:01<00:00, 17.39it/s, val_loss=0.0961, val_mae=0.0961, val_mape=1.59e+3][A

 50%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà        | 16/32 [00:01<00:00, 17.39it/s, val_loss=0.143, val_mae=0.143, val_mape=0.309][A

 50%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà         | 16/32 [00:01<00:00, 17.39it/s, val_loss=0.14, val_mae=0.14, val_mape=0.465][A

 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã       | 19/32 [00:01<00:00, 19.37it/s, val_loss=0.14, val_mae=0.14, val_mape=0.465][A

 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ        | 19/32 [00:01<00:00, 19.37it/s, val_loss=0.1, val_mae=0.1, val_mape=0.203][A

 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà       | 19/32 [00:01<00:00, 19.37it/s, val_loss=0.104, val_mae=0.104, val_mape=93.5][A

 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ      | 19/32 [00:01<00:00, 19.37it/s, val_loss=0.0882, val_mae=0.0882, val_mape=1.08][A

 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 22/32 [00:01<00:00, 18.51it/s, val_loss=0.0882, val_mae=0.0882, val_mape=1.08][A

 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 22/32 [00:01<00:00, 18.51it/s, val_loss=0.0908, val_mae=0.0908, val_mape=0.371][A

 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç     | 22/32 [00:01<00:00, 18.51it/s, val_loss=0.074, val_mae=0.074, val_mape=931][A

 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà     | 22/32 [00:01<00:00, 18.51it/s, val_loss=0.108, val_mae=0.108, val_mape=0.257][A

 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 25/32 [00:01<00:00, 19.33it/s, val_loss=0.108, val_mae=0.108, val_mape=0.257][A

 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 25/32 [00:01<00:00, 19.33it/s, val_loss=0.0942, val_mae=0.0942, val_mape=0.397][A

 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 25/32 [00:01<00:00, 19.33it/s, val_loss=0.104, val_mae=0.104, val_mape=32][A

 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 25/32 [00:01<00:00, 19.33it/s, val_loss=0.0764, val_mae=0.0764, val_mape=0.655][A

 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 28/32 [00:01<00:00, 19.88it/s, val_loss=0.0764, val_mae=0.0764, val_mape=0.655][A

 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 28/32 [00:02<00:00, 19.88it/s, val_loss=0.184, val_mae=0.184, val_mape=0.328][A

 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 28/32 [00:02<00:00, 19.88it/s, val_loss=0.0925, val_mae=0.0925, val_mape=1.46][A

 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 28/32 [00:02<00:00, 19.88it/s, val_loss=0.0752, val_mae=0.0752, val_mape=1.83][A

 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 31/32 [00:02<00:00, 20.36it/s, val_loss=0.0752, val_mae=0.0752, val_mape=1.83][A

 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 31/32 [00:02<00:00, 20.36it/s, val_loss=0.0987, val_mae=0.0998, val_mape=106][A
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 14.50it/s, val_loss=0.0987, val_mae=0.0998, val_mape=106]
                                                                                          

Best trial: 7. Best value: 0.0859608:  15%|‚ñà‚ñå        | 12/80 [1:47:08<6:09:13, 325.79s/it]
Best trial: 7. Best value: 0.0859608:  15%|‚ñà‚ñå        | 12/80 [1:47:09<6:09:13, 325.79s/it]
Best trial: 7. Best value: 0.0859608:  16%|‚ñà‚ñã        | 13/80 [1:47:09<13:06:58, 704.76s/it]
{'val_loss': 0.0987346088513732, 'val_mae': 0.09979872405529022, 'val_mape': 106.01189422607422}

üèÅ Trial #44 completed! Result: 0.094862
[I 2025-07-13 17:44:16,881] Trial 44 finished with value: 0.09486166387796402 and parameters: {'lr': 0.0006860561524423489, 'dropout_rate': 0.11483439699586584, 'weight_decay': 0.00027373409132384603, 'batch_size': 48, 'hidden_features': 96, 'coulomb_param': 0.9361045330961029, 'london_param': 0.8604613056528729, 'pauli_param': 3.821742588059063, 'R_grid': 5}. Best is trial 7 with value: 0.08596083521842957.

üöÄ Starting Trial #45 (Seed: 1116)
  Parameters:
    - lr: 0.000670632305709521
    - dropout_rate: 0.11040724202625882
    - weight_decay: 0.00028880026095534476
    - batch_size: 48
    - hidden_features: 96
    - coulomb_param: 0.8994616954200171
    - london_param: 0.8620875794739239
    - pauli_param: 3.856973942394939
    - R_grid: 5
train length: 12000 val length: 1500 test length: 1500 unused length: 0 seed : 1116
[0;31m<<<<<< ‚ö°Ô∏è cuda is used >>>>>>[0m
‚ñà
epoch     train_loss  train_mae  train_mape  lr        val_loss  val_mae   val_mape  best_val_mae  time    
1.0       0.423       0.423      3.98e+02    0.000671  0.251     0.25      1.06e+02  0.251         31.3      
2.0       0.256       0.256      2.83e+02    0.000671  0.209     0.209     90.0      0.209         31.8      
3.0       0.22        0.22       2.39e+02    0.000671  0.234     0.234     60.6      0.209         31.0      
4.0       0.198       0.198      1.8e+02     0.000671  0.172     0.174     74.7      0.172         31.3      
5.0       0.188       0.188      1.98e+02    0.000671  0.209     0.209     83.5      0.172         30.8      

‚Äã                                                                                           

Best trial: 7. Best value: 0.0859608:  16%|‚ñà‚ñã        | 13/80 [1:50:16<13:06:58, 704.76s/it]
Best trial: 7. Best value: 0.0859608:  16%|‚ñà‚ñã        | 13/80 [1:50:16<13:06:58, 704.76s/it]
Best trial: 7. Best value: 0.0859608:  18%|‚ñà‚ñä        | 14/80 [1:50:16<10:03:26, 548.58s/it]
‚úÇÔ∏è Trial #45 pruned!
[I 2025-07-13 17:47:24,632] Trial 45 pruned. 

üöÄ Starting Trial #46 (Seed: 1126)
  Parameters:
    - lr: 0.0005121864415075793
    - dropout_rate: 0.13998507389067327
    - weight_decay: 0.0004928608516372137
    - batch_size: 48
    - hidden_features: 96
    - coulomb_param: 0.8183055578833827
    - london_param: 0.893839756407885
    - pauli_param: 4.302424477130858
    - R_grid: 5
train length: 12000 val length: 1500 test length: 1500 unused length: 0 seed : 1126
[0;31m<<<<<< ‚ö°Ô∏è cuda is used >>>>>>[0m
‚ñà
epoch     train_loss  train_mae  train_mape  lr        val_loss  val_mae   val_mape  best_val_mae  time    
1.0       0.429       0.429      2.98e+02    0.000512  0.356     0.355     3.75e+02  0.356         31.5      
2.0       0.254       0.254      2.56e+02    0.000512  0.205     0.205     1.6e+02   0.205         31.6      
3.0       0.215       0.215      2.36e+02    0.000512  0.186     0.186     1.12e+02  0.186         31.6      
4.0       0.198       0.198      3.2e+02     0.000512  0.183     0.183     1.34e+02  0.183         31.3      
5.0       0.183       0.183      1.69e+02    0.000512  0.163     0.162     26.6      0.163         31.7      
6.0       0.174       0.174      1.92e+02    0.000512  0.175     0.173     52.6      0.163         30.8      
7.0       0.168       0.168      2.28e+02    0.000512  0.184     0.184     93.4      0.163         31.3      
8.0       0.159       0.159      1.76e+02    0.000512  0.149     0.147     61.9      0.149         31.4      
9.0       0.157       0.157      1.59e+02    0.000512  0.161     0.158     1.26e+02  0.149         31.0      
10.0      0.147       0.147      1.82e+02    0.000512  0.132     0.132     8.94      0.132         31.4      
11.0      0.143       0.143      1.76e+02    0.000512  0.144     0.143     25.8      0.132         31.0      
12.0      0.14        0.14       1.36e+02    0.000512  0.131     0.13      11.3      0.131         31.6      
13.0      0.14        0.14       1.34e+02    0.000512  0.127     0.126     97.7      0.127         32.2      
14.0      0.133       0.133      1.8e+02     0.000512  0.143     0.14      31.7      0.127         30.7      
15.0      0.13        0.13       1.48e+02    0.000512  0.121     0.121     81.1      0.121         30.5      
16.0      0.125       0.125      1.49e+02    0.000512  0.124     0.124     35.6      0.121         30.8      
17.0      0.128       0.128      1.59e+02    0.000512  0.127     0.126     24.2      0.121         30.9      
18.0      0.123       0.123      1.4e+02     0.000512  0.122     0.121     33.7      0.121         31.9      
19.0      0.126       0.126      1.8e+02     0.000512  0.117     0.116     35.7      0.117         31.5      
20.0      0.122       0.122      97.7        0.000512  0.117     0.116     46.8      0.117         31.3      
21.0      0.119       0.119      1.55e+02    0.000512  0.156     0.156     62.9      0.117         30.7      
22.0      0.118       0.118      1.3e+02     0.000512  0.118     0.118     57.0      0.117         30.4      
23.0      0.112       0.112      91.1        0.000512  0.137     0.136     1.23e+02  0.117         30.4      
24.0      0.115       0.115      1.2e+02     0.000512  0.109     0.109     16.0      0.109         32.0      
25.0      0.107       0.107      1.5e+02     0.000512  0.121     0.12      65.4      0.109         31.8      
26.0      0.107       0.107      1.32e+02    0.000512  0.111     0.111     38.2      0.109         31.4      
27.0      0.103       0.103      1.43e+02    0.000512  0.117     0.116     55.1      0.109         31.4      
28.0      0.105       0.105      1.44e+02    0.000512  0.12      0.118     51.9      0.109         31.3      
29.0      0.104       0.104      1.09e+02    0.000512  0.111     0.111     29.4      0.109         31.6      
30.0      0.1         0.1        87.1        0.000512  0.119     0.119     85.2      0.109         31.8      
31.0      0.0998      0.0998     1.09e+02    0.000512  0.112     0.112     13.6      0.109         31.6      
32.0      0.098       0.098      1.29e+02    0.000512  0.112     0.112     1.09e+02  0.109         31.6      
33.0      0.0993      0.0993     1.15e+02    0.000512  0.102     0.101     28.1      0.102         31.8      
34.0      0.0945      0.0945     85.6        0.000512  0.113     0.113     31.5      0.102         31.8      
35.0      0.0957      0.0957     1.09e+02    0.000512  0.105     0.105     5.02      0.102         31.2      
36.0      0.0933      0.0933     93.5        0.000512  0.105     0.105     41.5      0.102         31.2      
37.0      0.0928      0.0928     1.22e+02    0.000512  0.101     0.0994    43.5      0.101         32.1      
38.0      0.0903      0.0903     87.6        0.000512  0.104     0.105     29.8      0.101         32.2      
39.0      0.0887      0.0887     89.0        0.000512  0.103     0.102     21.7      0.101         32.4      
40.0      0.0878      0.0878     1.06e+02    0.000512  0.107     0.107     18.8      0.101         31.6      
41.0      0.087       0.087      74.0        0.000512  0.101     0.101     43.1      0.101         31.7      
42.0      0.0859      0.0859     89.2        0.000512  0.106     0.107     6.05      0.101         31.6      
43.0      0.0863      0.0863     1.06e+02    0.000512  0.0992    0.0986    33.4      0.0992        32.6      
44.0      0.0843      0.0843     89.5        0.000512  0.102     0.101     30.0      0.0992        30.3      
45.0      0.083       0.083      86.9        0.000512  0.103     0.103     23.3      0.0992        31.1      
46.0      0.0821      0.0821     1.04e+02    0.000512  0.102     0.101     25.0      0.0992        31.0      
47.0      0.0816      0.0816     65.8        0.000512  0.0994    0.0993    29.7      0.0992        31.7      
48.0      0.0794      0.0794     94.3        0.000512  0.1       0.101     37.4      0.0992        32.1      
49.0      0.0799      0.0799     83.3        0.000512  0.113     0.113     27.9      0.0992        31.2      
50.0      0.0802      0.0802     93.2        0.000512  0.0994    0.0988    24.2      0.0992        31.5      
    epoch  train_loss  train_mae  ...    val_mape  best_val_mae       time
0       1    0.428666   0.428666  ...  375.419281      0.356069  31.478245
1       2    0.253761   0.253761  ...  160.400177      0.205131  31.635032
2       3    0.214800   0.214800  ...  111.503601      0.185804  31.552240
3       4    0.197888   0.197888  ...  134.075989      0.182806  31.342088
4       5    0.183131   0.183132  ...   26.608753      0.163033  31.744383
5       6    0.173591   0.173591  ...   52.573990      0.163033  30.766432
6       7    0.167884   0.167884  ...   93.376434      0.163033  31.292100
7       8    0.159200   0.159200  ...   61.901848      0.148609  31.367069
8       9    0.156515   0.156515  ...  126.097481      0.148609  30.986392
9      10    0.146998   0.146998  ...    8.938702      0.132031  31.438959
10     11    0.142553   0.142553  ...   25.840120      0.132031  30.952350
11     12    0.140115   0.140115  ...   11.266562      0.130936  31.559301
12     13    0.139721   0.139721  ...   97.694481      0.126712  32.185307
13     14    0.132861   0.132861  ...   31.688440      0.126712  30.704913
14     15    0.130373   0.130373  ...   81.141670      0.120545  30.514597
15     16    0.125021   0.125021  ...   35.606548      0.120545  30.814981
16     17    0.127974   0.127974  ...   24.157717      0.120545  30.868143
17     18    0.123131   0.123131  ...   33.706375      0.120545  31.908285
18     19    0.126403   0.126403  ...   35.711052      0.117332  31.515146
19     20    0.122205   0.122205  ...   46.756729      0.116577  31.317556
20     21    0.119193   0.119193  ...   62.850269      0.116577  30.729615
21     22    0.117728   0.117728  ...   56.974354      0.116577  30.437603
22     23    0.112461   0.112461  ...  123.417542      0.116577  30.398167
23     24    0.115111   0.115111  ...   15.980266      0.109418  31.973177
24     25    0.107439   0.107439  ...   65.437927      0.109418  31.777374
25     26    0.107074   0.107074  ...   38.210629      0.109418  31.446486
26     27    0.102906   0.102906  ...   55.053314      0.109418  31.360866
27     28    0.105243   0.105243  ...   51.878292      0.109418  31.255207
28     29    0.103682   0.103682  ...   29.429089      0.109418  31.615600
29     30    0.100385   0.100385  ...   85.199974      0.109418  31.819035
30     31    0.099793   0.099793  ...   13.611883      0.109418  31.637942
31     32    0.097952   0.097952  ...  108.993980      0.109418  31.649115
32     33    0.099293   0.099293  ...   28.084557      0.101839  31.758243
33     34    0.094545   0.094545  ...   31.463011      0.101839  31.830537
34     35    0.095695   0.095695  ...    5.024498      0.101839  31.232547
35     36    0.093285   0.093285  ...   41.465988      0.101839  31.221178
36     37    0.092845   0.092845  ...   43.477928      0.100660  32.141545
37     38    0.090312   0.090312  ...   29.785187      0.100660  32.167983
38     39    0.088685   0.088685  ...   21.745764      0.100660  32.374614
39     40    0.087812   0.087812  ...   18.788876      0.100660  31.613895
40     41    0.086991   0.086991  ...   43.077988      0.100660  31.715799
41     42    0.085917   0.085917  ...    6.049469      0.100660  31.582386
42     43    0.086269   0.086269  ...   33.377556      0.099190  32.601737
43     44    0.084307   0.084307  ...   30.028950      0.099190  30.325734
44     45    0.082994   0.082994  ...   23.335310      0.099190  31.071404
45     46    0.082076   0.082076  ...   24.961941      0.099190  30.983551
46     47    0.081576   0.081576  ...   29.720802      0.099190  31.706279
47     48    0.079429   0.079429  ...   37.382298      0.099190  32.051836
48     49    0.079895   0.079895  ...   27.904943      0.099190  31.157241
49     50    0.080188   0.080188  ...   24.178963      0.099190  31.531845

[50 rows x 10 columns]


  0%|                                                                        | 0/32 [00:00<?, ?it/s][A

  0%|                      | 0/32 [00:00<?, ?it/s, val_loss=0.0971, val_mae=0.0971, val_mape=2.3e+3][A

  3%|‚ñç             | 1/32 [00:00<00:16,  1.83it/s, val_loss=0.0971, val_mae=0.0971, val_mape=2.3e+3][A

  3%|‚ñå                | 1/32 [00:00<00:16,  1.83it/s, val_loss=0.0669, val_mae=0.0669, val_mape=2.3][A

  3%|‚ñç              | 1/32 [00:00<00:16,  1.83it/s, val_loss=0.105, val_mae=0.105, val_mape=4.18e+3][A

  9%|‚ñà‚ñç             | 3/32 [00:00<00:05,  5.41it/s, val_loss=0.105, val_mae=0.105, val_mape=4.18e+3][A

  9%|‚ñà‚ñä                 | 3/32 [00:00<00:05,  5.41it/s, val_loss=0.116, val_mae=0.116, val_mape=581][A

  9%|‚ñà‚ñã                | 3/32 [00:00<00:05,  5.41it/s, val_loss=0.103, val_mae=0.103, val_mape=0.26][A

  9%|‚ñà‚ñç             | 3/32 [00:00<00:05,  5.41it/s, val_loss=0.0935, val_mae=0.0935, val_mape=0.261][A

 19%|‚ñà‚ñà‚ñä            | 6/32 [00:00<00:02,  9.97it/s, val_loss=0.0935, val_mae=0.0935, val_mape=0.261][A

 19%|‚ñà‚ñà‚ñà‚ñç              | 6/32 [00:00<00:02,  9.97it/s, val_loss=0.102, val_mae=0.102, val_mape=1.18][A

 19%|‚ñà‚ñà‚ñà‚ñè             | 6/32 [00:00<00:02,  9.97it/s, val_loss=0.111, val_mae=0.111, val_mape=0.798][A

 19%|‚ñà‚ñà‚ñä            | 6/32 [00:00<00:02,  9.97it/s, val_loss=0.0977, val_mae=0.0977, val_mape=0.781][A

 28%|‚ñà‚ñà‚ñà‚ñà‚ñè          | 9/32 [00:00<00:01, 14.07it/s, val_loss=0.0977, val_mae=0.0977, val_mape=0.781][A

 28%|‚ñà‚ñà‚ñà‚ñà‚ñà             | 9/32 [00:00<00:01, 14.07it/s, val_loss=0.112, val_mae=0.112, val_mape=1.95][A

 28%|‚ñà‚ñà‚ñà‚ñà‚ñä            | 9/32 [00:00<00:01, 14.07it/s, val_loss=0.102, val_mae=0.102, val_mape=0.239][A

 28%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé             | 9/32 [00:01<00:01, 14.07it/s, val_loss=0.128, val_mae=0.128, val_mape=246][A

 38%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä           | 12/32 [00:01<00:01, 17.58it/s, val_loss=0.128, val_mae=0.128, val_mape=246][A

 38%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà          | 12/32 [00:01<00:01, 17.58it/s, val_loss=0.108, val_mae=0.108, val_mape=0.725][A

 38%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä           | 12/32 [00:01<00:01, 17.58it/s, val_loss=0.124, val_mae=0.124, val_mape=394][A

 38%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé        | 12/32 [00:01<00:01, 17.58it/s, val_loss=0.0784, val_mae=0.0784, val_mape=0.292][A

 47%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå       | 15/32 [00:01<00:00, 18.84it/s, val_loss=0.0784, val_mae=0.0784, val_mape=0.292][A

 47%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà        | 15/32 [00:01<00:00, 18.84it/s, val_loss=0.0863, val_mae=0.0863, val_mape=0.52][A

 47%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ         | 15/32 [00:01<00:00, 18.84it/s, val_loss=0.119, val_mae=0.119, val_mape=2.35][A

 47%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå        | 15/32 [00:01<00:00, 18.84it/s, val_loss=0.118, val_mae=0.118, val_mape=0.655][A

 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà       | 18/32 [00:01<00:00, 20.06it/s, val_loss=0.118, val_mae=0.118, val_mape=0.655][A

 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè       | 18/32 [00:01<00:00, 20.06it/s, val_loss=0.077, val_mae=0.077, val_mape=855][A

 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå       | 18/32 [00:01<00:00, 20.06it/s, val_loss=0.103, val_mae=0.103, val_mape=0.33][A

 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà       | 18/32 [00:01<00:00, 20.06it/s, val_loss=0.107, val_mae=0.107, val_mape=0.786][A

 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå     | 21/32 [00:01<00:00, 20.44it/s, val_loss=0.107, val_mae=0.107, val_mape=0.786][A

 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè     | 21/32 [00:01<00:00, 20.44it/s, val_loss=0.115, val_mae=0.115, val_mape=1.76][A

 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå     | 21/32 [00:01<00:00, 20.44it/s, val_loss=0.113, val_mae=0.113, val_mape=0.627][A

 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 21/32 [00:01<00:00, 20.44it/s, val_loss=0.0777, val_mae=0.0777, val_mape=0.308][A

 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 24/32 [00:01<00:00, 20.85it/s, val_loss=0.0777, val_mae=0.0777, val_mape=0.308][A

 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 24/32 [00:01<00:00, 20.85it/s, val_loss=0.122, val_mae=0.122, val_mape=0.538][A

 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 24/32 [00:01<00:00, 20.85it/s, val_loss=0.133, val_mae=0.133, val_mape=1.5][A

 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 24/32 [00:01<00:00, 20.85it/s, val_loss=0.0872, val_mae=0.0872, val_mape=1.98][A

 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 27/32 [00:01<00:00, 21.03it/s, val_loss=0.0872, val_mae=0.0872, val_mape=1.98][A

 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 27/32 [00:01<00:00, 21.03it/s, val_loss=0.106, val_mae=0.106, val_mape=0.281][A

 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 27/32 [00:01<00:00, 21.03it/s, val_loss=0.0827, val_mae=0.0827, val_mape=2.12e+3][A

 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 27/32 [00:01<00:00, 21.03it/s, val_loss=0.148, val_mae=0.148, val_mape=0.318][A

 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 30/32 [00:01<00:00, 20.52it/s, val_loss=0.148, val_mae=0.148, val_mape=0.318][A

 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 30/32 [00:01<00:00, 20.52it/s, val_loss=0.113, val_mae=0.113, val_mape=0.595][A

 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 30/32 [00:02<00:00, 20.52it/s, val_loss=0.104, val_mae=0.105, val_mape=342][A
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 15.98it/s, val_loss=0.104, val_mae=0.105, val_mape=342]
                                                                                           

Best trial: 7. Best value: 0.0859608:  18%|‚ñà‚ñä        | 14/80 [2:16:30<10:03:26, 548.58s/it]
Best trial: 7. Best value: 0.0859608:  18%|‚ñà‚ñä        | 14/80 [2:16:30<10:03:26, 548.58s/it]
Best trial: 7. Best value: 0.0859608:  19%|‚ñà‚ñâ        | 15/80 [2:16:30<15:29:11, 857.72s/it]
{'val_loss': 0.10425006924197078, 'val_mae': 0.104758121073246, 'val_mape': 342.4089660644531}

üèÅ Trial #46 completed! Result: 0.098557
[I 2025-07-13 18:13:38,725] Trial 46 finished with value: 0.09855730086565018 and parameters: {'lr': 0.0005121864415075793, 'dropout_rate': 0.13998507389067327, 'weight_decay': 0.0004928608516372137, 'batch_size': 48, 'hidden_features': 96, 'coulomb_param': 0.8183055578833827, 'london_param': 0.893839756407885, 'pauli_param': 4.302424477130858, 'R_grid': 5}. Best is trial 7 with value: 0.08596083521842957.

üöÄ Starting Trial #47 (Seed: 1136)
  Parameters:
    - lr: 0.0010158174754959588
    - dropout_rate: 0.1257125558469073
    - weight_decay: 0.00023312045346909001
    - batch_size: 48
    - hidden_features: 96
    - coulomb_param: 0.6906464893307607
    - london_param: 0.7778102992495166
    - pauli_param: 3.763539095914508
    - R_grid: 5
train length: 12000 val length: 1500 test length: 1500 unused length: 0 seed : 1136
[0;31m<<<<<< ‚ö°Ô∏è cuda is used >>>>>>[0m
‚ñà
epoch     train_loss  train_mae  train_mape  lr        val_loss  val_mae   val_mape  best_val_mae  time    
1.0       0.475       0.475      6.91e+02    0.00102   0.314     0.313     5.52e+02  0.314         31.4      
2.0       0.27        0.27       2.79e+02    0.00102   0.325     0.323     2.94e+02  0.314         32.3      
3.0       0.228       0.228      2.8e+02     0.00102   0.202     0.202     1.88e+02  0.202         31.6      
4.0       0.199       0.199      2.29e+02    0.00102   0.174     0.175     3.34e+02  0.174         31.4      
5.0       0.182       0.182      1.74e+02    0.00102   0.169     0.168     3.12e+02  0.169         31.6      
6.0       0.183       0.183      1.32e+02    0.00102   0.2       0.199     1.43e+02  0.169         31.2      
7.0       0.17        0.17       1.62e+02    0.00102   0.153     0.151     1.93e+02  0.153         32.2      
8.0       0.157       0.157      1.61e+02    0.00102   0.161     0.161     1.36e+02  0.153         31.4      
9.0       0.153       0.153      1.23e+02    0.00102   0.15      0.15      2.85e+02  0.15          31.2      
10.0      0.15        0.15       2.05e+02    0.00102   0.131     0.131     1.47e+02  0.131         31.7      
11.0      0.145       0.145      1.15e+02    0.00102   0.143     0.143     73.5      0.131         30.9      
12.0      0.138       0.138      1.06e+02    0.00102   0.129     0.13      2.72e+02  0.129         31.8      
13.0      0.137       0.137      1.45e+02    0.00102   0.126     0.127     1.31e+02  0.126         31.8      
14.0      0.136       0.136      1.31e+02    0.00102   0.129     0.128     1.71e+02  0.126         31.4      
15.0      0.13        0.13       1.33e+02    0.00102   0.134     0.134     47.2      0.126         30.8      
16.0      0.13        0.13       1.25e+02    0.00102   0.12      0.12      1.54e+02  0.12          31.0      
17.0      0.124       0.124      1.07e+02    0.00102   0.123     0.123     2.15e+02  0.12          32.1      
18.0      0.127       0.127      1.17e+02    0.00102   0.126     0.125     1.4e+02   0.12          30.3      
19.0      0.123       0.123      1.33e+02    0.00102   0.122     0.122     2.23e+02  0.12          30.3      
20.0      0.117       0.117      1.02e+02    0.00102   0.133     0.132     63.1      0.12          30.9      
21.0      0.115       0.115      92.1        0.00102   0.128     0.128     1.23e+02  0.12          30.3      
22.0      0.116       0.116      85.0        0.00102   0.124     0.124     1.15e+02  0.12          30.6      
23.0      0.111       0.111      91.9        0.00102   0.127     0.127     1.27e+02  0.12          31.1      
24.0      0.109       0.109      1.15e+02    0.00102   0.112     0.111     1.87e+02  0.112         31.9      
25.0      0.11        0.11       1.03e+02    0.00102   0.125     0.125     53.3      0.112         32.0      
26.0      0.111       0.111      1.24e+02    0.00102   0.121     0.121     93.9      0.112         31.2      
27.0      0.104       0.104      1.15e+02    0.00102   0.133     0.133     86.3      0.112         31.9      
28.0      0.103       0.103      93.7        0.00102   0.122     0.122     1.45e+02  0.112         30.5      
29.0      0.1         0.1        95.2        0.00102   0.105     0.105     76.8      0.105         31.5      
30.0      0.0989      0.0989     85.8        0.00102   0.105     0.105     95.9      0.105         31.3      
31.0      0.102       0.102      1.32e+02    0.00102   0.117     0.117     86.1      0.105         31.3      
32.0      0.0958      0.0958     87.4        0.00102   0.11      0.11      1.08e+02  0.105         29.6      
33.0      0.0952      0.0952     82.1        0.00102   0.123     0.123     1.27e+02  0.105         30.8      
34.0      0.0929      0.0929     97.1        0.00102   0.107     0.106     2.23e+02  0.105         30.6      
35.0      0.089       0.089      85.1        0.00102   0.106     0.105     1.13e+02  0.105         31.2      
36.0      0.0906      0.0906     79.9        0.00102   0.107     0.107     1e+02     0.105         30.6      
37.0      0.0887      0.0887     1.23e+02    0.00102   0.107     0.107     1.33e+02  0.105         30.0      
38.0      0.0863      0.0863     1.13e+02    0.00102   0.126     0.126     1.03e+02  0.105         31.4      
39.0      0.0865      0.0865     96.7        0.00102   0.111     0.11      67.7      0.105         30.6      

‚Äã                                                                                           

Best trial: 7. Best value: 0.0859608:  19%|‚ñà‚ñâ        | 15/80 [2:37:17<15:29:11, 857.72s/it]
Best trial: 7. Best value: 0.0859608:  19%|‚ñà‚ñâ        | 15/80 [2:37:17<15:29:11, 857.72s/it]
Best trial: 7. Best value: 0.0859608:  20%|‚ñà‚ñà        | 16/80 [2:37:17<17:19:49, 974.83s/it]
‚úÇÔ∏è Trial #47 pruned!
[I 2025-07-13 18:34:25,542] Trial 47 pruned. 

üöÄ Starting Trial #48 (Seed: 1146)
  Parameters:
    - lr: 0.0005466854137052117
    - dropout_rate: 0.098691307494775
    - weight_decay: 0.00015938517914651311
    - batch_size: 48
    - hidden_features: 96
    - coulomb_param: 1.1696255779706302
    - london_param: 1.523187230013519
    - pauli_param: 4.192642876040071
    - R_grid: 6
train length: 12000 val length: 1500 test length: 1500 unused length: 0 seed : 1146
[0;31m<<<<<< ‚ö°Ô∏è cuda is used >>>>>>[0m
‚ñà
epoch     train_loss  train_mae  train_mape  lr        val_loss  val_mae   val_mape  best_val_mae  time    
1.0       0.421       0.421      5.1e+02     0.000547  0.289     0.285     3.28e+02  0.289         31.4      
2.0       0.248       0.248      2.51e+02    0.000547  0.239     0.233     2.03e+02  0.239         31.1      
3.0       0.223       0.223      3.21e+02    0.000547  0.204     0.202     1.15e+02  0.204         30.6      
4.0       0.197       0.197      2.74e+02    0.000547  0.19      0.187     2.2e+02   0.19          31.1      
5.0       0.176       0.176      3.3e+02     0.000547  0.178     0.173     1.37e+02  0.178         30.8      

‚Äã                                                                                           

Best trial: 7. Best value: 0.0859608:  20%|‚ñà‚ñà        | 16/80 [2:40:23<17:19:49, 974.83s/it]
Best trial: 7. Best value: 0.0859608:  20%|‚ñà‚ñà        | 16/80 [2:40:24<17:19:49, 974.83s/it]
Best trial: 7. Best value: 0.0859608:  21%|‚ñà‚ñà‚ñè       | 17/80 [2:40:24<12:54:35, 737.71s/it]
‚úÇÔ∏è Trial #48 pruned!
[I 2025-07-13 18:37:31,799] Trial 48 pruned. 

üöÄ Starting Trial #49 (Seed: 1156)
  Parameters:
    - lr: 0.0006816829746133621
    - dropout_rate: 0.0586628853176213
    - weight_decay: 6.137120437058603e-05
    - batch_size: 64
    - hidden_features: 192
    - coulomb_param: 0.9552832528427534
    - london_param: 1.3499425684109967
    - pauli_param: 4.030800432796239
    - R_grid: 5
train length: 12000 val length: 1500 test length: 1500 unused length: 0 seed : 1156
[0;31m<<<<<< ‚ö°Ô∏è cuda is used >>>>>>[0m
‚ñà
epoch     train_loss  train_mae  train_mape  lr        val_loss  val_mae   val_mape  best_val_mae  time    
1.0       0.586       0.587      4.07e+02    0.000682  0.332     0.331     7.92e+02  0.332         33.1      
2.0       0.284       0.284      3.19e+02    0.000682  0.228     0.228     6.61e+02  0.228         33.0      
3.0       0.235       0.234      2.53e+02    0.000682  0.196     0.195     2.73e+02  0.196         33.7      
4.0       0.206       0.206      1.72e+02    0.000682  0.174     0.173     3.06e+02  0.174         33.1      
5.0       0.187       0.187      1.29e+02    0.000682  0.195     0.193     4.42e+02  0.174         32.4      
6.0       0.177       0.177      1.04e+02    0.000682  0.161     0.16      4.26e+02  0.161         33.4      
7.0       0.171       0.171      1.28e+02    0.000682  0.158     0.157     1.88e+02  0.158         33.2      

‚Äã                                                                                           

Best trial: 7. Best value: 0.0859608:  21%|‚ñà‚ñà‚ñè       | 17/80 [2:44:49<12:54:35, 737.71s/it]
Best trial: 7. Best value: 0.0859608:  21%|‚ñà‚ñà‚ñè       | 17/80 [2:44:49<12:54:35, 737.71s/it]
Best trial: 7. Best value: 0.0859608:  22%|‚ñà‚ñà‚ñé       | 18/80 [2:44:49<10:15:40, 595.81s/it]
‚úÇÔ∏è Trial #49 pruned!
[I 2025-07-13 18:41:57,188] Trial 49 pruned. 

üöÄ Starting Trial #50 (Seed: 1166)
  Parameters:
    - lr: 0.0008334501984621826
    - dropout_rate: 0.14864770700566912
    - weight_decay: 4.168451543585909e-05
    - batch_size: 48
    - hidden_features: 160
    - coulomb_param: 1.3159974687300555
    - london_param: 0.9843605677232022
    - pauli_param: 4.76962316181691
    - R_grid: 5
train length: 12000 val length: 1500 test length: 1500 unused length: 0 seed : 1166
[0;31m<<<<<< ‚ö°Ô∏è cuda is used >>>>>>[0m
‚ñà
epoch     train_loss  train_mae  train_mape  lr        val_loss  val_mae   val_mape  best_val_mae  time    
1.0       0.554       0.554      1.35e+03    0.000833  0.349     0.347     3.05e+02  0.349         34.8      
2.0       0.279       0.279      2.79e+02    0.000833  0.206     0.207     3.64e+02  0.206         34.6      
3.0       0.219       0.219      1.69e+02    0.000833  0.182     0.182     2.86e+02  0.182         34.4      
4.0       0.207       0.207      1.59e+02    0.000833  0.174     0.174     1.8e+02   0.174         34.6      
5.0       0.182       0.182      1.56e+02    0.000833  0.195     0.196     2.25e+02  0.174         33.9      
6.0       0.18        0.18       1.56e+02    0.000833  0.167     0.167     2.88e+02  0.167         35.3      
7.0       0.171       0.171      1.24e+02    0.000833  0.145     0.145     2.17e+02  0.145         35.0      
8.0       0.164       0.164      1.18e+02    0.000833  0.152     0.151     2.23e+02  0.145         34.4      
9.0       0.157       0.157      1.43e+02    0.000833  0.22      0.219     2.45e+02  0.145         35.2      
10.0      0.157       0.157      1.08e+02    0.000833  0.136     0.135     2.37e+02  0.136         35.5      
11.0      0.15        0.15       1.52e+02    0.000833  0.136     0.138     1.68e+02  0.136         34.6      
12.0      0.145       0.145      1.06e+02    0.000833  0.144     0.144     2.42e+02  0.136         34.9      
13.0      0.141       0.141      1.13e+02    0.000833  0.186     0.187     3.49e+02  0.136         34.9      
14.0      0.137       0.137      1.14e+02    0.000833  0.132     0.132     1.77e+02  0.132         35.5      
15.0      0.133       0.133      1.45e+02    0.000833  0.132     0.131     2.19e+02  0.132         35.0      
16.0      0.134       0.134      1.17e+02    0.000833  0.126     0.126     1.57e+02  0.126         35.7      
17.0      0.131       0.131      1.17e+02    0.000833  0.121     0.122     1.92e+02  0.121         35.7      
18.0      0.127       0.127      1.11e+02    0.000833  0.133     0.134     2.35e+02  0.121         35.0      
19.0      0.125       0.125      1.02e+02    0.000833  0.134     0.132     1.73e+02  0.121         35.0      
20.0      0.121       0.121      1.06e+02    0.000833  0.129     0.128     1.66e+02  0.121         34.7      
21.0      0.121       0.121      1.1e+02     0.000833  0.122     0.122     1.98e+02  0.121         35.3      
22.0      0.118       0.118      1.09e+02    0.000833  0.124     0.124     1.77e+02  0.121         34.7      
23.0      0.114       0.114      98.5        0.000833  0.117     0.117     1.68e+02  0.117         35.0      
24.0      0.115       0.115      1.05e+02    0.000833  0.113     0.112     1.07e+02  0.113         36.1      
25.0      0.109       0.109      97.9        0.000833  0.169     0.167     1.44e+02  0.113         34.5      
26.0      0.109       0.109      1.1e+02     0.000833  0.126     0.124     2.2e+02   0.113         34.8      
27.0      0.105       0.105      92.8        0.000833  0.119     0.119     1.4e+02   0.113         34.9      
28.0      0.105       0.105      1.06e+02    0.000833  0.122     0.122     1.55e+02  0.113         34.7      
29.0      0.102       0.102      77.2        0.000833  0.122     0.121     1.95e+02  0.113         34.3      
30.0      0.1         0.1        88.9        0.000833  0.123     0.123     1.28e+02  0.113         34.4      
31.0      0.101       0.101      1.2e+02     0.000833  0.106     0.105     1.69e+02  0.106         35.7      
32.0      0.0982      0.0982     86.2        0.000833  0.12      0.119     1.86e+02  0.106         34.3      
33.0      0.0973      0.0973     90.9        0.000833  0.108     0.109     2.07e+02  0.106         34.7      
34.0      0.0954      0.0954     1.17e+02    0.000833  0.11      0.109     1.24e+02  0.106         35.0      
35.0      0.0957      0.0957     98.7        0.000833  0.112     0.112     1.34e+02  0.106         35.1      
36.0      0.0917      0.0917     79.3        0.000833  0.112     0.111     1.43e+02  0.106         34.9      
37.0      0.0914      0.0914     84.3        0.000833  0.117     0.116     1.8e+02   0.106         35.3      
38.0      0.0898      0.0898     97.5        0.000833  0.111     0.11      1.47e+02  0.106         34.8      
39.0      0.0875      0.0875     92.8        0.000833  0.102     0.102     2.03e+02  0.102         35.6      
40.0      0.086       0.086      1.2e+02     0.000833  0.113     0.112     89.6      0.102         34.9      
41.0      0.0863      0.0863     90.9        0.000833  0.108     0.107     1.41e+02  0.102         34.7      
42.0      0.085       0.085      1.18e+02    0.000833  0.102     0.102     95.0      0.102         35.1      
43.0      0.0865      0.0865     98.8        0.000833  0.116     0.115     1.98e+02  0.102         34.9      
44.0      0.0834      0.0834     1.04e+02    0.000833  0.103     0.102     1.5e+02   0.102         35.4      
45.0      0.0829      0.0829     92.0        0.000833  0.114     0.114     96.2      0.102         34.7      
46.0      0.0814      0.0814     1.03e+02    0.000833  0.109     0.108     1.81e+02  0.102         34.3      
47.0      0.0805      0.0805     92.2        0.000833  0.112     0.112     1.42e+02  0.102         35.1      
48.0      0.0772      0.0772     1.02e+02    0.000833  0.133     0.132     1.32e+02  0.102         34.8      
49.0      0.0792      0.0792     1.02e+02    0.000833  0.101     0.102     1.84e+02  0.101         35.5      
50.0      0.076       0.076      95.7        0.000833  0.104     0.103     1.47e+02  0.101         34.9      
    epoch  train_loss  train_mae  ...    val_mape  best_val_mae       time
0       1    0.554092   0.554092  ...  304.819885      0.349435  34.777269
1       2    0.278688   0.278688  ...  364.229462      0.205845  34.550924
2       3    0.219118   0.219118  ...  286.023346      0.182413  34.397677
3       4    0.207414   0.207414  ...  180.205582      0.173860  34.596017
4       5    0.182324   0.182324  ...  224.512924      0.173860  33.929899
5       6    0.180457   0.180457  ...  288.452606      0.167063  35.330935
6       7    0.170596   0.170596  ...  217.040482      0.144722  35.019124
7       8    0.164093   0.164093  ...  223.407211      0.144722  34.373657
8       9    0.157416   0.157416  ...  244.974960      0.144722  35.177695
9      10    0.156688   0.156688  ...  236.856995      0.135752  35.537163
10     11    0.149960   0.149960  ...  168.212631      0.135752  34.578161
11     12    0.144986   0.144986  ...  242.235001      0.135752  34.867558
12     13    0.141450   0.141450  ...  348.927429      0.135752  34.949860
13     14    0.137179   0.137179  ...  176.577148      0.131811  35.503085
14     15    0.132868   0.132868  ...  218.565826      0.131514  35.030277
15     16    0.134057   0.134058  ...  156.515671      0.125894  35.730716
16     17    0.131470   0.131470  ...  191.689896      0.121423  35.724673
17     18    0.127112   0.127112  ...  235.040268      0.121423  35.049109
18     19    0.125218   0.125218  ...  172.760117      0.121423  35.039500
19     20    0.121487   0.121488  ...  165.692535      0.121423  34.738491
20     21    0.121238   0.121238  ...  198.244019      0.121423  35.266830
21     22    0.117860   0.117860  ...  176.785706      0.121423  34.677020
22     23    0.113708   0.113708  ...  168.447372      0.116873  35.029839
23     24    0.114736   0.114736  ...  106.680573      0.112513  36.072510
24     25    0.108529   0.108529  ...  144.208557      0.112513  34.450380
25     26    0.109423   0.109423  ...  219.981064      0.112513  34.754431
26     27    0.105369   0.105369  ...  139.743942      0.112513  34.877663
27     28    0.105461   0.105462  ...  154.825546      0.112513  34.708313
28     29    0.102103   0.102103  ...  194.628647      0.112513  34.335218
29     30    0.100131   0.100131  ...  127.847366      0.112513  34.436471
30     31    0.101070   0.101070  ...  168.655243      0.106438  35.696257
31     32    0.098162   0.098162  ...  186.292130      0.106438  34.272233
32     33    0.097265   0.097265  ...  207.396652      0.106438  34.725541
33     34    0.095419   0.095419  ...  123.676376      0.106438  34.984518
34     35    0.095660   0.095660  ...  134.007629      0.106438  35.069654
35     36    0.091688   0.091688  ...  143.004547      0.106438  34.930376
36     37    0.091401   0.091401  ...  179.555618      0.106438  35.288712
37     38    0.089818   0.089818  ...  147.266129      0.106438  34.765943
38     39    0.087540   0.087540  ...  203.009079      0.101928  35.644650
39     40    0.086029   0.086029  ...   89.634285      0.101928  34.884375
40     41    0.086298   0.086298  ...  141.337555      0.101928  34.727521
41     42    0.084971   0.084971  ...   94.999916      0.101928  35.058535
42     43    0.086466   0.086466  ...  198.321442      0.101928  34.928915
43     44    0.083369   0.083369  ...  150.054779      0.101928  35.361949
44     45    0.082867   0.082867  ...   96.196686      0.101928  34.653116
45     46    0.081407   0.081407  ...  181.448090      0.101928  34.338383
46     47    0.080475   0.080475  ...  141.591187      0.101928  35.123107
47     48    0.077239   0.077239  ...  131.969681      0.101928  34.843624
48     49    0.079227   0.079227  ...  183.952103      0.101371  35.544720
49     50    0.075979   0.075979  ...  147.347565      0.101371  34.924857

[50 rows x 10 columns]


  0%|                                                                        | 0/32 [00:00<?, ?it/s][A

  0%|                         | 0/32 [00:00<?, ?it/s, val_loss=0.0894, val_mae=0.0894, val_mape=738][A

  3%|‚ñå                | 1/32 [00:00<00:20,  1.51it/s, val_loss=0.0894, val_mae=0.0894, val_mape=738][A

  3%|‚ñå                  | 1/32 [00:00<00:20,  1.51it/s, val_loss=0.137, val_mae=0.137, val_mape=204][A

  3%|‚ñå                | 1/32 [00:00<00:20,  1.51it/s, val_loss=0.127, val_mae=0.127, val_mape=0.452][A

  3%|‚ñå                | 1/32 [00:00<00:20,  1.51it/s, val_loss=0.109, val_mae=0.109, val_mape=0.953][A

 12%|‚ñà‚ñà‚ñè              | 4/32 [00:00<00:04,  6.37it/s, val_loss=0.109, val_mae=0.109, val_mape=0.953][A

 12%|‚ñà‚ñà‚ñè              | 4/32 [00:00<00:04,  6.37it/s, val_loss=0.117, val_mae=0.117, val_mape=0.491][A

 12%|‚ñà‚ñâ             | 4/32 [00:00<00:04,  6.37it/s, val_loss=0.0927, val_mae=0.0927, val_mape=0.249][A

 19%|‚ñà‚ñà‚ñä            | 6/32 [00:00<00:03,  7.69it/s, val_loss=0.0927, val_mae=0.0927, val_mape=0.249][A

 19%|‚ñà‚ñà‚ñà             | 6/32 [00:01<00:03,  7.69it/s, val_loss=0.0807, val_mae=0.0807, val_mape=7.09][A

 19%|‚ñà‚ñà‚ñä            | 6/32 [00:01<00:03,  7.69it/s, val_loss=0.125, val_mae=0.125, val_mape=3.48e+3][A

 19%|‚ñà‚ñà‚ñà‚ñç              | 6/32 [00:01<00:03,  7.69it/s, val_loss=0.111, val_mae=0.111, val_mape=4.01][A

 28%|‚ñà‚ñà‚ñà‚ñà‚ñà             | 9/32 [00:01<00:02, 11.25it/s, val_loss=0.111, val_mae=0.111, val_mape=4.01][A

 28%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè               | 9/32 [00:01<00:02, 11.25it/s, val_loss=0.1, val_mae=0.1, val_mape=3.03][A

 28%|‚ñà‚ñà‚ñà‚ñà‚ñè          | 9/32 [00:01<00:02, 11.25it/s, val_loss=0.0986, val_mae=0.0986, val_mape=0.476][A

 28%|‚ñà‚ñà‚ñà‚ñà‚ñä            | 9/32 [00:01<00:02, 11.25it/s, val_loss=0.111, val_mae=0.111, val_mape=0.383][A

 38%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà          | 12/32 [00:01<00:01, 13.81it/s, val_loss=0.111, val_mae=0.111, val_mape=0.383][A

 38%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé        | 12/32 [00:01<00:01, 13.81it/s, val_loss=0.0922, val_mae=0.0922, val_mape=0.659][A

 38%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà          | 12/32 [00:01<00:01, 13.81it/s, val_loss=0.102, val_mae=0.102, val_mape=0.226][A

 44%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà         | 14/32 [00:01<00:01, 14.58it/s, val_loss=0.102, val_mae=0.102, val_mape=0.226][A

 44%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå        | 14/32 [00:01<00:01, 14.58it/s, val_loss=0.112, val_mae=0.112, val_mape=5.6e+3][A

 44%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç         | 14/32 [00:01<00:01, 14.58it/s, val_loss=0.138, val_mae=0.138, val_mape=1.07][A

 50%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå        | 16/32 [00:01<00:01, 15.52it/s, val_loss=0.138, val_mae=0.138, val_mape=1.07][A

 50%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà        | 16/32 [00:01<00:01, 15.52it/s, val_loss=0.102, val_mae=0.102, val_mape=0.446][A

 50%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå        | 16/32 [00:01<00:01, 15.52it/s, val_loss=0.134, val_mae=0.134, val_mape=2.31][A

 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå       | 18/32 [00:01<00:00, 15.81it/s, val_loss=0.134, val_mae=0.134, val_mape=2.31][A

 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ      | 18/32 [00:01<00:00, 15.81it/s, val_loss=0.0862, val_mae=0.0862, val_mape=0.311][A

 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà       | 18/32 [00:01<00:00, 15.81it/s, val_loss=0.101, val_mae=0.101, val_mape=0.407][A

 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà      | 20/32 [00:01<00:00, 16.31it/s, val_loss=0.101, val_mae=0.101, val_mape=0.407][A

 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé      | 20/32 [00:01<00:00, 16.31it/s, val_loss=0.092, val_mae=0.092, val_mape=278][A

 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé      | 20/32 [00:01<00:00, 16.31it/s, val_loss=0.123, val_mae=0.123, val_mape=462][A

 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç     | 22/32 [00:01<00:00, 17.22it/s, val_loss=0.123, val_mae=0.123, val_mape=462][A

 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà     | 22/32 [00:01<00:00, 17.22it/s, val_loss=0.107, val_mae=0.107, val_mape=0.399][A

 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà      | 22/32 [00:01<00:00, 17.22it/s, val_loss=0.09, val_mae=0.09, val_mape=0.51][A

 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 24/32 [00:01<00:00, 15.91it/s, val_loss=0.09, val_mae=0.09, val_mape=0.51][A

 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 24/32 [00:02<00:00, 15.91it/s, val_loss=0.0988, val_mae=0.0988, val_mape=2.79e+3][A

 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 24/32 [00:02<00:00, 15.91it/s, val_loss=0.0989, val_mae=0.0989, val_mape=0.331][A

 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 26/32 [00:02<00:00, 16.48it/s, val_loss=0.0989, val_mae=0.0989, val_mape=0.331][A

 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 26/32 [00:02<00:00, 16.48it/s, val_loss=0.0743, val_mae=0.0743, val_mape=0.621][A

 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 26/32 [00:02<00:00, 16.48it/s, val_loss=0.118, val_mae=0.118, val_mape=1.51][A

 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 26/32 [00:02<00:00, 16.48it/s, val_loss=0.0793, val_mae=0.0793, val_mape=0.369][A

 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 29/32 [00:02<00:00, 17.79it/s, val_loss=0.0793, val_mae=0.0793, val_mape=0.369][A

 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 29/32 [00:02<00:00, 17.79it/s, val_loss=0.08, val_mae=0.08, val_mape=0.353][A

 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 29/32 [00:02<00:00, 17.79it/s, val_loss=0.0814, val_mae=0.0814, val_mape=0.271][A

 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 31/32 [00:02<00:00, 17.98it/s, val_loss=0.0814, val_mae=0.0814, val_mape=0.271][A

 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 31/32 [00:02<00:00, 17.98it/s, val_loss=0.103, val_mae=0.103, val_mape=435][A
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 13.24it/s, val_loss=0.103, val_mae=0.103, val_mape=435]
                                                                                           

Best trial: 7. Best value: 0.0859608:  22%|‚ñà‚ñà‚ñé       | 18/80 [3:13:59<10:15:40, 595.81s/it]
Best trial: 7. Best value: 0.0859608:  22%|‚ñà‚ñà‚ñé       | 18/80 [3:14:00<10:15:40, 595.81s/it]
Best trial: 7. Best value: 0.0859608:  24%|‚ñà‚ñà‚ñç       | 19/80 [3:14:00<15:58:24, 942.70s/it]
{'val_loss': 0.10324620548635721, 'val_mae': 0.10345642268657684, 'val_mape': 434.5406799316406}

üèÅ Trial #50 completed! Result: 0.101510
[I 2025-07-13 19:11:08,072] Trial 50 finished with value: 0.10151040554046631 and parameters: {'lr': 0.0008334501984621826, 'dropout_rate': 0.14864770700566912, 'weight_decay': 4.168451543585909e-05, 'batch_size': 48, 'hidden_features': 160, 'coulomb_param': 1.3159974687300555, 'london_param': 0.9843605677232022, 'pauli_param': 4.76962316181691, 'R_grid': 5}. Best is trial 7 with value: 0.08596083521842957.

üöÄ Starting Trial #51 (Seed: 1176)
  Parameters:
    - lr: 0.002763870969943385
    - dropout_rate: 0.11435897559019571
    - weight_decay: 0.00011775242922524936
    - batch_size: 96
    - hidden_features: 96
    - coulomb_param: 1.9005230490552796
    - london_param: 1.1136025584798381
    - pauli_param: 3.6828038590872847
    - R_grid: 3
train length: 12000 val length: 1500 test length: 1500 unused length: 0 seed : 1176
[0;31m<<<<<< ‚ö°Ô∏è cuda is used >>>>>>[0m
‚ñà
epoch     train_loss  train_mae  train_mape  lr        val_loss  val_mae   val_mape  best_val_mae  time    
1.0       0.68        0.68       8.67e+02    0.00276   0.27      0.27      1.25e+02  0.27          19.3      
2.0       0.274       0.274      4.25e+02    0.00276   0.238     0.238     2.65e+02  0.238         19.9      
3.0       0.24        0.24       4.05e+02    0.00276   0.297     0.297     1.93e+02  0.238         19.1      
4.0       0.213       0.213      2.25e+02    0.00276   0.236     0.236     1.46e+02  0.236         19.5      
5.0       0.195       0.195      1.95e+02    0.00276   0.171     0.17      54.4      0.171         19.7      

‚Äã                                                                                           

Best trial: 7. Best value: 0.0859608:  24%|‚ñà‚ñà‚ñç       | 19/80 [3:15:56<15:58:24, 942.70s/it]
Best trial: 7. Best value: 0.0859608:  24%|‚ñà‚ñà‚ñç       | 19/80 [3:15:56<15:58:24, 942.70s/it]
Best trial: 7. Best value: 0.0859608:  25%|‚ñà‚ñà‚ñå       | 20/80 [3:15:56<11:34:39, 694.66s/it]
‚úÇÔ∏è Trial #51 pruned!
[I 2025-07-13 19:13:04,674] Trial 51 pruned. 

üöÄ Starting Trial #52 (Seed: 1186)
  Parameters:
    - lr: 0.0004342273605468734
    - dropout_rate: 0.08323608221154105
    - weight_decay: 2.594542038877596e-05
    - batch_size: 96
    - hidden_features: 160
    - coulomb_param: 0.9823793814480164
    - london_param: 0.6182563787078439
    - pauli_param: 1.8877720809848904
    - R_grid: 5
train length: 12000 val length: 1500 test length: 1500 unused length: 0 seed : 1186
[0;31m<<<<<< ‚ö°Ô∏è cuda is used >>>>>>[0m
‚ñà
epoch     train_loss  train_mae  train_mape  lr        val_loss  val_mae   val_mape  best_val_mae  time    
1.0       0.527       0.527      6.98e+02    0.000434  0.305     0.305     1.52e+02  0.305         26.1      
2.0       0.298       0.298      4.55e+02    0.000434  0.222     0.223     1.18e+02  0.222         25.3      
3.0       0.242       0.242      3.28e+02    0.000434  0.258     0.257     1.11e+02  0.222         24.5      
4.0       0.205       0.205      3.24e+02    0.000434  0.184     0.184     1.77e+02  0.184         25.8      
5.0       0.199       0.199      2.38e+02    0.000434  0.175     0.174     49.9      0.175         25.5      

‚Äã                                                                                           

Best trial: 7. Best value: 0.0859608:  25%|‚ñà‚ñà‚ñå       | 20/80 [3:18:29<11:34:39, 694.66s/it]
Best trial: 7. Best value: 0.0859608:  25%|‚ñà‚ñà‚ñå       | 20/80 [3:18:30<11:34:39, 694.66s/it]
Best trial: 7. Best value: 0.0859608:  26%|‚ñà‚ñà‚ñã       | 21/80 [3:18:30<8:43:19, 532.20s/it] 
‚úÇÔ∏è Trial #52 pruned!
[I 2025-07-13 19:15:38,107] Trial 52 pruned. 

üöÄ Starting Trial #53 (Seed: 1196)
  Parameters:
    - lr: 0.0014378381160370392
    - dropout_rate: 0.1280340061108712
    - weight_decay: 1.744471486172877e-05
    - batch_size: 128
    - hidden_features: 160
    - coulomb_param: 1.842432746646316
    - london_param: 1.6302094191081853
    - pauli_param: 1.2504885828055234
    - R_grid: 6
train length: 12000 val length: 1500 test length: 1500 unused length: 0 seed : 1196
[0;31m<<<<<< ‚ö°Ô∏è cuda is used >>>>>>[0m
‚ñà
epoch     train_loss  train_mae  train_mape  lr        val_loss  val_mae   val_mape  best_val_mae  time    
1.0       0.759       0.76       3.98e+02    0.00144   0.293     0.294     1.14e+03  0.293         25.0      
2.0       0.288       0.288      2.81e+02    0.00144   0.288     0.289     1.06e+03  0.288         24.5      
3.0       0.245       0.245      2.82e+02    0.00144   0.232     0.233     5.49e+02  0.232         24.5      
4.0       0.217       0.217      1.24e+02    0.00144   0.195     0.196     9.37e+02  0.195         24.6      
5.0       0.198       0.198      1.36e+02    0.00144   0.176     0.177     4.61e+02  0.176         24.5      

‚Äã                                                                                          

Best trial: 7. Best value: 0.0859608:  26%|‚ñà‚ñà‚ñã       | 21/80 [3:20:57<8:43:19, 532.20s/it]
Best trial: 7. Best value: 0.0859608:  26%|‚ñà‚ñà‚ñã       | 21/80 [3:20:57<8:43:19, 532.20s/it]
Best trial: 7. Best value: 0.0859608:  28%|‚ñà‚ñà‚ñä       | 22/80 [3:20:57<6:42:48, 416.69s/it]
‚úÇÔ∏è Trial #53 pruned!
[I 2025-07-13 19:18:05,442] Trial 53 pruned. 

üöÄ Starting Trial #54 (Seed: 1206)
  Parameters:
    - lr: 0.0006255172635778766
    - dropout_rate: 0.15823308836381988
    - weight_decay: 1.1447586514937817e-05
    - batch_size: 96
    - hidden_features: 128
    - coulomb_param: 0.7769454315619717
    - london_param: 1.4079166656163413
    - pauli_param: 1.3976465816056292
    - R_grid: 3
train length: 12000 val length: 1500 test length: 1500 unused length: 0 seed : 1206
[0;31m<<<<<< ‚ö°Ô∏è cuda is used >>>>>>[0m
‚ñà
epoch     train_loss  train_mae  train_mape  lr        val_loss  val_mae   val_mape  best_val_mae  time    
1.0       0.58        0.58       1.61e+03    0.000626  0.278     0.278     4.84e+02  0.278         22.3      
2.0       0.286       0.286      3.25e+02    0.000626  0.224     0.223     3.52e+02  0.224         22.3      
3.0       0.246       0.246      3.01e+02    0.000626  0.284     0.284     2.81e+02  0.224         21.3      
4.0       0.212       0.212      4.53e+02    0.000626  0.202     0.203     1e+02     0.202         22.5      
5.0       0.193       0.193      2.58e+02    0.000626  0.217     0.217     1.56e+02  0.202         21.8      

‚Äã                                                                                          

Best trial: 7. Best value: 0.0859608:  28%|‚ñà‚ñà‚ñä       | 22/80 [3:23:09<6:42:48, 416.69s/it]
Best trial: 7. Best value: 0.0859608:  28%|‚ñà‚ñà‚ñä       | 22/80 [3:23:09<6:42:48, 416.69s/it]
Best trial: 7. Best value: 0.0859608:  29%|‚ñà‚ñà‚ñâ       | 23/80 [3:23:09<5:14:46, 331.35s/it]
‚úÇÔ∏è Trial #54 pruned!
[I 2025-07-13 19:20:17,734] Trial 54 pruned. 

üöÄ Starting Trial #55 (Seed: 1216)
  Parameters:
    - lr: 0.0012476403350387094
    - dropout_rate: 0.05138910799693427
    - weight_decay: 7.201120711931643e-05
    - batch_size: 48
    - hidden_features: 160
    - coulomb_param: 1.5766810730896494
    - london_param: 1.0602413633847732
    - pauli_param: 2.0791694002110184
    - R_grid: 4
train length: 12000 val length: 1500 test length: 1500 unused length: 0 seed : 1216
[0;31m<<<<<< ‚ö°Ô∏è cuda is used >>>>>>[0m
‚ñà
epoch     train_loss  train_mae  train_mape  lr        val_loss  val_mae   val_mape  best_val_mae  time    
1.0       0.58        0.58       8.88e+02    0.00125   0.268     0.269     31.8      0.268         34.6      
2.0       0.27        0.27       3.02e+02    0.00125   0.206     0.204     11.5      0.206         34.9      
3.0       0.227       0.227      2.21e+02    0.00125   0.223     0.222     12.8      0.206         34.4      
4.0       0.217       0.217      2.57e+02    0.00125   0.209     0.209     12.5      0.206         34.6      
5.0       0.184       0.184      2.67e+02    0.00125   0.169     0.168     22.0      0.169         35.1      

‚Äã                                                                                          

Best trial: 7. Best value: 0.0859608:  29%|‚ñà‚ñà‚ñâ       | 23/80 [3:26:37<5:14:46, 331.35s/it]
Best trial: 7. Best value: 0.0859608:  29%|‚ñà‚ñà‚ñâ       | 23/80 [3:26:37<5:14:46, 331.35s/it]
Best trial: 7. Best value: 0.0859608:  30%|‚ñà‚ñà‚ñà       | 24/80 [3:26:37<4:34:39, 294.28s/it]
‚úÇÔ∏è Trial #55 pruned!
[I 2025-07-13 19:23:45,542] Trial 55 pruned. 

üöÄ Starting Trial #56 (Seed: 1226)
  Parameters:
    - lr: 0.0010183552060158666
    - dropout_rate: 0.18814399691102154
    - weight_decay: 1.6438262759171206e-06
    - batch_size: 128
    - hidden_features: 160
    - coulomb_param: 1.43880405887333
    - london_param: 1.5789284251290927
    - pauli_param: 3.0184007230768533
    - R_grid: 3
train length: 12000 val length: 1500 test length: 1500 unused length: 0 seed : 1226
[0;31m<<<<<< ‚ö°Ô∏è cuda is used >>>>>>[0m
‚ñà
epoch     train_loss  train_mae  train_mape  lr        val_loss  val_mae   val_mape  best_val_mae  time    
1.0       0.716       0.717      1.18e+03    0.00102   0.295     0.295     2.56e+02  0.295         24.6      
2.0       0.294       0.295      4.3e+02     0.00102   0.312     0.313     4.35e+02  0.295         23.9      
3.0       0.253       0.253      3.64e+02    0.00102   0.197     0.197     2.68e+02  0.197         24.2      
4.0       0.218       0.218      2.33e+02    0.00102   0.209     0.21      2.84e+02  0.197         24.4      
5.0       0.203       0.203      2.44e+02    0.00102   0.178     0.178     2.33e+02  0.178         23.9      
6.0       0.19        0.19       2.53e+02    0.00102   0.165     0.164     2.85e+02  0.165         24.4      
7.0       0.179       0.179      1.9e+02     0.00102   0.173     0.173     2.69e+02  0.165         24.0      

‚Äã                                                                                          

Best trial: 7. Best value: 0.0859608:  30%|‚ñà‚ñà‚ñà       | 24/80 [3:29:51<4:34:39, 294.28s/it]
Best trial: 7. Best value: 0.0859608:  30%|‚ñà‚ñà‚ñà       | 24/80 [3:29:51<4:34:39, 294.28s/it]
Best trial: 7. Best value: 0.0859608:  31%|‚ñà‚ñà‚ñà‚ñè      | 25/80 [3:29:51<4:02:11, 264.20s/it]
‚úÇÔ∏è Trial #56 pruned!
[I 2025-07-13 19:26:59,548] Trial 56 pruned. 

üöÄ Starting Trial #57 (Seed: 1236)
  Parameters:
    - lr: 0.0010744513867174067
    - dropout_rate: 0.23237140129070782
    - weight_decay: 2.732669284810333e-06
    - batch_size: 128
    - hidden_features: 160
    - coulomb_param: 1.450640379755567
    - london_param: 1.688592346111719
    - pauli_param: 3.2773886865804496
    - R_grid: 3
train length: 12000 val length: 1500 test length: 1500 unused length: 0 seed : 1236
[0;31m<<<<<< ‚ö°Ô∏è cuda is used >>>>>>[0m
‚ñà
epoch     train_loss  train_mae  train_mape  lr        val_loss  val_mae   val_mape  best_val_mae  time    
1.0       0.688       0.689      1.09e+03    0.00107   0.458     0.458     80.8      0.458         24.5      
2.0       0.298       0.298      3.47e+02    0.00107   0.305     0.306     1.19e+02  0.305         24.4      
3.0       0.237       0.237      3.06e+02    0.00107   0.215     0.214     1.13e+02  0.215         25.1      
4.0       0.209       0.209      2.47e+02    0.00107   0.181     0.181     71.7      0.181         24.3      
5.0       0.217       0.217      2.26e+02    0.00107   0.256     0.256     96.2      0.181         24.1      

‚Äã                                                                                          

Best trial: 7. Best value: 0.0859608:  31%|‚ñà‚ñà‚ñà‚ñè      | 25/80 [3:32:18<4:02:11, 264.20s/it]
Best trial: 7. Best value: 0.0859608:  31%|‚ñà‚ñà‚ñà‚ñè      | 25/80 [3:32:19<4:02:11, 264.20s/it]
Best trial: 7. Best value: 0.0859608:  32%|‚ñà‚ñà‚ñà‚ñé      | 26/80 [3:32:19<3:26:14, 229.17s/it]
‚úÇÔ∏è Trial #57 pruned!
[I 2025-07-13 19:29:26,951] Trial 57 pruned. 

üöÄ Starting Trial #58 (Seed: 1246)
  Parameters:
    - lr: 0.0014564521320810041
    - dropout_rate: 0.1793969752481626
    - weight_decay: 2.1899848379301956e-06
    - batch_size: 128
    - hidden_features: 160
    - coulomb_param: 1.3210317783912675
    - london_param: 1.5205590501765225
    - pauli_param: 3.4940649995486024
    - R_grid: 3
train length: 12000 val length: 1500 test length: 1500 unused length: 0 seed : 1246
[0;31m<<<<<< ‚ö°Ô∏è cuda is used >>>>>>[0m
‚ñà
epoch     train_loss  train_mae  train_mape  lr        val_loss  val_mae   val_mape  best_val_mae  time    
1.0       0.904       0.905      4.56e+02    0.00146   0.294     0.293     5.01e+02  0.294         24.4      
2.0       0.28        0.281      4.27e+02    0.00146   0.229     0.229     5.32e+02  0.229         24.7      
3.0       0.246       0.246      3.21e+02    0.00146   0.229     0.23      4.14e+02  0.229         24.0      
4.0       0.224       0.224      2.73e+02    0.00146   0.196     0.196     4.34e+02  0.196         24.2      
5.0       0.206       0.206      2.7e+02     0.00146   0.181     0.181     4.14e+02  0.181         24.2      

‚Äã                                                                                          

Best trial: 7. Best value: 0.0859608:  32%|‚ñà‚ñà‚ñà‚ñé      | 26/80 [3:34:44<3:26:14, 229.17s/it]
Best trial: 7. Best value: 0.0859608:  32%|‚ñà‚ñà‚ñà‚ñé      | 26/80 [3:34:45<3:26:14, 229.17s/it]
Best trial: 7. Best value: 0.0859608:  34%|‚ñà‚ñà‚ñà‚ñç      | 27/80 [3:34:45<3:00:23, 204.23s/it]
‚úÇÔ∏è Trial #58 pruned!
[I 2025-07-13 19:31:52,984] Trial 58 pruned. 

üöÄ Starting Trial #59 (Seed: 1256)
  Parameters:
    - lr: 0.000744405132562001
    - dropout_rate: 0.21319508291668904
    - weight_decay: 1.1822129429494518e-06
    - batch_size: 128
    - hidden_features: 160
    - coulomb_param: 1.709498247562955
    - london_param: 1.330064752029363
    - pauli_param: 3.4042362588091386
    - R_grid: 3
train length: 12000 val length: 1500 test length: 1500 unused length: 0 seed : 1256
[0;31m<<<<<< ‚ö°Ô∏è cuda is used >>>>>>[0m
‚ñà
epoch     train_loss  train_mae  train_mape  lr        val_loss  val_mae   val_mape  best_val_mae  time    
1.0       0.671       0.672      9.93e+02    0.000744  0.28      0.281     5.61e+02  0.28          24.1      
2.0       0.303       0.303      4.02e+02    0.000744  0.271     0.271     2.77e+02  0.271         25.0      
3.0       0.258       0.258      3.45e+02    0.000744  0.198     0.198     2.45e+02  0.198         24.7      
4.0       0.227       0.227      3.25e+02    0.000744  0.171     0.171     3.8e+02   0.171         24.4      
5.0       0.199       0.199      2.17e+02    0.000744  0.186     0.187     3.39e+02  0.171         24.3      
6.0       0.174       0.174      2.82e+02    0.000744  0.165     0.165     3.77e+02  0.165         24.1      
7.0       0.168       0.168      2.01e+02    0.000744  0.159     0.16      4.2e+02   0.159         24.3      

‚Äã                                                                                          

Best trial: 7. Best value: 0.0859608:  34%|‚ñà‚ñà‚ñà‚ñç      | 27/80 [3:38:00<3:00:23, 204.23s/it]
Best trial: 7. Best value: 0.0859608:  34%|‚ñà‚ñà‚ñà‚ñç      | 27/80 [3:38:01<3:00:23, 204.23s/it]
Best trial: 7. Best value: 0.0859608:  35%|‚ñà‚ñà‚ñà‚ñå      | 28/80 [3:38:01<2:54:48, 201.70s/it]
‚úÇÔ∏è Trial #59 pruned!
[I 2025-07-13 19:35:08,789] Trial 59 pruned. 

üöÄ Starting Trial #60 (Seed: 1266)
  Parameters:
    - lr: 0.0018600738401303356
    - dropout_rate: 0.20969237714756206
    - weight_decay: 0.00039472474578953424
    - batch_size: 128
    - hidden_features: 160
    - coulomb_param: 0.511437386812301
    - london_param: 1.466507752970028
    - pauli_param: 3.250232611980884
    - R_grid: 3
train length: 12000 val length: 1500 test length: 1500 unused length: 0 seed : 1266
[0;31m<<<<<< ‚ö°Ô∏è cuda is used >>>>>>[0m
‚ñà
epoch     train_loss  train_mae  train_mape  lr        val_loss  val_mae   val_mape  best_val_mae  time    
1.0       0.842       0.844      1.1e+03     0.00186   0.266     0.266     6.54e+02  0.266         24.7      
2.0       0.275       0.275      3.42e+02    0.00186   0.276     0.276     6.86e+02  0.266         24.0      
3.0       0.242       0.242      2.58e+02    0.00186   0.217     0.217     5.45e+02  0.217         25.3      
4.0       0.21        0.21       2.52e+02    0.00186   0.248     0.247     5.41e+02  0.217         24.1      
5.0       0.212       0.212      2.42e+02    0.00186   0.175     0.175     4.66e+02  0.175         24.1      

‚Äã                                                                                          

Best trial: 7. Best value: 0.0859608:  35%|‚ñà‚ñà‚ñà‚ñå      | 28/80 [3:40:27<2:54:48, 201.70s/it]
Best trial: 7. Best value: 0.0859608:  35%|‚ñà‚ñà‚ñà‚ñå      | 28/80 [3:40:28<2:54:48, 201.70s/it]
Best trial: 7. Best value: 0.0859608:  36%|‚ñà‚ñà‚ñà‚ñã      | 29/80 [3:40:28<2:37:32, 185.34s/it]
‚úÇÔ∏è Trial #60 pruned!
[I 2025-07-13 19:37:35,924] Trial 60 pruned. 

üöÄ Starting Trial #61 (Seed: 1276)
  Parameters:
    - lr: 0.0009553897850779691
    - dropout_rate: 0.24945577292088555
    - weight_decay: 4.361503174710607e-06
    - batch_size: 64
    - hidden_features: 96
    - coulomb_param: 1.5345790473610488
    - london_param: 1.2125714289998417
    - pauli_param: 2.5562212891360785
    - R_grid: 4
train length: 12000 val length: 1500 test length: 1500 unused length: 0 seed : 1276
[0;31m<<<<<< ‚ö°Ô∏è cuda is used >>>>>>[0m
‚ñà
epoch     train_loss  train_mae  train_mape  lr        val_loss  val_mae   val_mape  best_val_mae  time    
1.0       0.468       0.468      3.47e+02    0.000955  0.315     0.31      1.69e+02  0.315         25.6      
2.0       0.271       0.271      4.11e+02    0.000955  0.219     0.216     2.43e+02  0.219         25.9      
3.0       0.225       0.225      3.13e+02    0.000955  0.203     0.198     1.02e+02  0.203         25.1      
4.0       0.208       0.207      2.48e+02    0.000955  0.185     0.182     23.6      0.185         25.2      
5.0       0.181       0.181      2.27e+02    0.000955  0.195     0.191     86.3      0.185         25.1      

‚Äã                                                                                          

Best trial: 7. Best value: 0.0859608:  36%|‚ñà‚ñà‚ñà‚ñã      | 29/80 [3:43:00<2:37:32, 185.34s/it]
Best trial: 7. Best value: 0.0859608:  36%|‚ñà‚ñà‚ñà‚ñã      | 29/80 [3:43:00<2:37:32, 185.34s/it]
Best trial: 7. Best value: 0.0859608:  38%|‚ñà‚ñà‚ñà‚ñä      | 30/80 [3:43:00<2:26:15, 175.50s/it]
‚úÇÔ∏è Trial #61 pruned!
[I 2025-07-13 19:40:08,482] Trial 61 pruned. 

üöÄ Starting Trial #62 (Seed: 1286)
  Parameters:
    - lr: 0.0005697831790154634
    - dropout_rate: 0.19721814299531587
    - weight_decay: 3.476074084675706e-05
    - batch_size: 96
    - hidden_features: 192
    - coulomb_param: 1.629912508179824
    - london_param: 1.6276565288850133
    - pauli_param: 4.065611199356757
    - R_grid: 3
train length: 12000 val length: 1500 test length: 1500 unused length: 0 seed : 1286
[0;31m<<<<<< ‚ö°Ô∏è cuda is used >>>>>>[0m
‚ñà
epoch     train_loss  train_mae  train_mape  lr        val_loss  val_mae   val_mape  best_val_mae  time    
1.0       0.694       0.694      9.46e+02    0.00057   0.35      0.351     3.23e+02  0.35          29.8      
2.0       0.3         0.3        4.84e+02    0.00057   0.246     0.246     2.54e+02  0.246         30.7      
3.0       0.24        0.24       4.14e+02    0.00057   0.237     0.236     4.38e+02  0.237         30.2      
4.0       0.218       0.218      3.65e+02    0.00057   0.199     0.198     1.88e+02  0.199         30.3      
5.0       0.194       0.194      2.71e+02    0.00057   0.179     0.179     1.44e+02  0.179         30.7      
6.0       0.179       0.179      3.09e+02    0.00057   0.161     0.161     1.76e+02  0.161         29.6      
7.0       0.172       0.172      2.95e+02    0.00057   0.173     0.172     4.33e+02  0.161         28.9      

‚Äã                                                                                          

Best trial: 7. Best value: 0.0859608:  38%|‚ñà‚ñà‚ñà‚ñä      | 30/80 [3:47:00<2:26:15, 175.50s/it]
Best trial: 7. Best value: 0.0859608:  38%|‚ñà‚ñà‚ñà‚ñä      | 30/80 [3:47:00<2:26:15, 175.50s/it]
Best trial: 7. Best value: 0.0859608:  39%|‚ñà‚ñà‚ñà‚ñâ      | 31/80 [3:47:00<2:39:05, 194.80s/it]
‚úÇÔ∏è Trial #62 pruned!
[I 2025-07-13 19:44:08,249] Trial 62 pruned. 

üöÄ Starting Trial #63 (Seed: 1296)
  Parameters:
    - lr: 0.00038955826786996593
    - dropout_rate: 0.12126488706103174
    - weight_decay: 0.0002449998565025801
    - batch_size: 128
    - hidden_features: 128
    - coulomb_param: 1.2208469771172288
    - london_param: 1.2490173450341857
    - pauli_param: 3.78953037179071
    - R_grid: 5
train length: 12000 val length: 1500 test length: 1500 unused length: 0 seed : 1296
[0;31m<<<<<< ‚ö°Ô∏è cuda is used >>>>>>[0m
‚ñà
epoch     train_loss  train_mae  train_mape  lr        val_loss  val_mae   val_mape  best_val_mae  time    
1.0       0.497       0.497      6.98e+02    0.00039   0.308     0.308     58.7      0.308         19.9      
2.0       0.29        0.291      4.19e+02    0.00039   0.248     0.249     15.7      0.248         19.9      
3.0       0.238       0.238      4.26e+02    0.00039   0.268     0.269     1.13e+02  0.248         19.6      
4.0       0.21        0.21       2.9e+02     0.00039   0.187     0.186     86.0      0.187         20.1      
5.0       0.187       0.187      2.59e+02    0.00039   0.163     0.162     1.5e+02   0.163         20.0      
6.0       0.174       0.174      2.73e+02    0.00039   0.199     0.199     1.49e+02  0.163         19.5      
7.0       0.177       0.177      3.19e+02    0.00039   0.174     0.174     1.01e+02  0.163         20.3      

‚Äã                                                                                          

Best trial: 7. Best value: 0.0859608:  39%|‚ñà‚ñà‚ñà‚ñâ      | 31/80 [3:49:40<2:39:05, 194.80s/it]
Best trial: 7. Best value: 0.0859608:  39%|‚ñà‚ñà‚ñà‚ñâ      | 31/80 [3:49:40<2:39:05, 194.80s/it]
Best trial: 7. Best value: 0.0859608:  40%|‚ñà‚ñà‚ñà‚ñà      | 32/80 [3:49:40<2:27:31, 184.40s/it]
‚úÇÔ∏è Trial #63 pruned!
[I 2025-07-13 19:46:48,480] Trial 63 pruned. 

üöÄ Starting Trial #64 (Seed: 1306)
  Parameters:
    - lr: 0.0017504228038649917
    - dropout_rate: 0.16706003999848787
    - weight_decay: 1.668349755301065e-06
    - batch_size: 96
    - hidden_features: 160
    - coulomb_param: 1.9530230046868984
    - london_param: 0.9228031019038297
    - pauli_param: 3.5453747931083184
    - R_grid: 3
train length: 12000 val length: 1500 test length: 1500 unused length: 0 seed : 1306
[0;31m<<<<<< ‚ö°Ô∏è cuda is used >>>>>>[0m
‚ñà
epoch     train_loss  train_mae  train_mape  lr        val_loss  val_mae   val_mape  best_val_mae  time    
1.0       0.675       0.675      1.96e+03    0.00175   0.292     0.292     9.48e+02  0.292         26.4      
2.0       0.291       0.291      3.48e+02    0.00175   0.276     0.276     4.1e+02   0.276         26.0      
3.0       0.246       0.246      2.8e+02     0.00175   0.232     0.231     6.08e+02  0.232         26.7      
4.0       0.226       0.226      2.02e+02    0.00175   0.24      0.24      2.72e+02  0.232         25.6      
5.0       0.195       0.195      1.67e+02    0.00175   0.221     0.221     7.21e+02  0.221         26.5      

‚Äã                                                                                          

Best trial: 7. Best value: 0.0859608:  40%|‚ñà‚ñà‚ñà‚ñà      | 32/80 [3:52:17<2:27:31, 184.40s/it]
Best trial: 7. Best value: 0.0859608:  40%|‚ñà‚ñà‚ñà‚ñà      | 32/80 [3:52:18<2:27:31, 184.40s/it]
Best trial: 7. Best value: 0.0859608:  41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 33/80 [3:52:18<2:18:06, 176.31s/it]
‚úÇÔ∏è Trial #64 pruned!
[I 2025-07-13 19:49:25,949] Trial 64 pruned. 

üöÄ Starting Trial #65 (Seed: 1316)
  Parameters:
    - lr: 0.0013171939530453737
    - dropout_rate: 0.09867939843724186
    - weight_decay: 9.842932569244498e-05
    - batch_size: 128
    - hidden_features: 160
    - coulomb_param: 1.7482913083587541
    - london_param: 1.7564950128925785
    - pauli_param: 1.809061776658735
    - R_grid: 4
train length: 12000 val length: 1500 test length: 1500 unused length: 0 seed : 1316
[0;31m<<<<<< ‚ö°Ô∏è cuda is used >>>>>>[0m
‚ñà
epoch     train_loss  train_mae  train_mape  lr        val_loss  val_mae   val_mape  best_val_mae  time    
1.0       0.803       0.804      2.15e+03    0.00132   0.254     0.255     1.23e+02  0.254         24.8      
2.0       0.283       0.283      4.29e+02    0.00132   0.24      0.241     1.31e+02  0.24          24.6      
3.0       0.237       0.237      2.87e+02    0.00132   0.231     0.232     1.15e+02  0.231         24.5      
4.0       0.203       0.203      2.57e+02    0.00132   0.234     0.234     1.36e+02  0.231         24.0      
5.0       0.19        0.19       1.62e+02    0.00132   0.247     0.247     41.8      0.231         24.0      

‚Äã                                                                                          

Best trial: 7. Best value: 0.0859608:  41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 33/80 [3:54:44<2:18:06, 176.31s/it]
Best trial: 7. Best value: 0.0859608:  41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 33/80 [3:54:44<2:18:06, 176.31s/it]
Best trial: 7. Best value: 0.0859608:  42%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 34/80 [3:54:44<2:08:18, 167.35s/it]
‚úÇÔ∏è Trial #65 pruned!
[I 2025-07-13 19:51:52,380] Trial 65 pruned. 

üöÄ Starting Trial #66 (Seed: 1326)
  Parameters:
    - lr: 0.0005100560335137991
    - dropout_rate: 0.13956895514848458
    - weight_decay: 0.00046260282760263784
    - batch_size: 48
    - hidden_features: 96
    - coulomb_param: 0.8117433916173502
    - london_param: 0.8795420365989214
    - pauli_param: 4.542002230629569
    - R_grid: 5
train length: 12000 val length: 1500 test length: 1500 unused length: 0 seed : 1326
[0;31m<<<<<< ‚ö°Ô∏è cuda is used >>>>>>[0m
‚ñà
epoch     train_loss  train_mae  train_mape  lr        val_loss  val_mae   val_mape  best_val_mae  time    
1.0       0.414       0.414      5.46e+02    0.00051   0.268     0.268     4.82e+02  0.268         27.5      
2.0       0.262       0.262      2.72e+02    0.00051   0.28      0.281     3.64e+02  0.268         31.8      
3.0       0.223       0.223      3.01e+02    0.00051   0.215     0.218     2.83e+02  0.215         32.1      
4.0       0.2         0.2        1.81e+02    0.00051   0.171     0.172     2.94e+02  0.171         31.9      
5.0       0.183       0.183      1.96e+02    0.00051   0.171     0.173     4.7e+02   0.171         31.3      

‚Äã                                                                                          

Best trial: 7. Best value: 0.0859608:  42%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 34/80 [3:57:51<2:08:18, 167.35s/it]
Best trial: 7. Best value: 0.0859608:  42%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 34/80 [3:57:51<2:08:18, 167.35s/it]
Best trial: 7. Best value: 0.0859608:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 35/80 [3:57:51<2:09:58, 173.30s/it]
‚úÇÔ∏è Trial #66 pruned!
[I 2025-07-13 19:54:59,548] Trial 66 pruned. 

üöÄ Starting Trial #67 (Seed: 1336)
  Parameters:
    - lr: 0.0005005863162987381
    - dropout_rate: 0.14311360478157698
    - weight_decay: 0.00035196385472040703
    - batch_size: 48
    - hidden_features: 96
    - coulomb_param: 1.050891320923922
    - london_param: 0.6859842601094168
    - pauli_param: 4.325242376173977
    - R_grid: 5
train length: 12000 val length: 1500 test length: 1500 unused length: 0 seed : 1336
[0;31m<<<<<< ‚ö°Ô∏è cuda is used >>>>>>[0m
‚ñà
epoch     train_loss  train_mae  train_mape  lr        val_loss  val_mae   val_mape  best_val_mae  time    
1.0       0.418       0.418      6.74e+02    0.000501  0.251     0.253     4.71e+02  0.251         31.9      
2.0       0.27        0.27       3.11e+02    0.000501  0.198     0.2       6.65e+02  0.198         32.0      
3.0       0.223       0.223      2.39e+02    0.000501  0.228     0.227     2.11e+02  0.198         31.3      
4.0       0.194       0.194      1.96e+02    0.000501  0.211     0.211     3.79e+02  0.198         31.1      
5.0       0.185       0.185      1.3e+02     0.000501  0.169     0.17      2.49e+02  0.169         31.8      
6.0       0.174       0.174      1.75e+02    0.000501  0.156     0.157     1.11e+02  0.156         32.1      
7.0       0.167       0.167      1.78e+02    0.000501  0.133     0.136     3.87e+02  0.133         32.0      
8.0       0.16        0.16       1.22e+02    0.000501  0.139     0.14      3.94e+02  0.133         31.6      
9.0       0.155       0.155      1.3e+02     0.000501  0.128     0.13      1.92e+02  0.128         32.2      
10.0      0.149       0.149      1.08e+02    0.000501  0.179     0.179     2.45e+02  0.128         31.7      
11.0      0.142       0.142      1.99e+02    0.000501  0.16      0.16      1.58e+02  0.128         31.6      
12.0      0.141       0.141      1.2e+02     0.000501  0.135     0.135     3.02e+02  0.128         31.3      
13.0      0.133       0.133      90.2        0.000501  0.127     0.128     2.7e+02   0.127         31.8      
14.0      0.131       0.131      1.12e+02    0.000501  0.128     0.128     2.11e+02  0.127         32.0      
15.0      0.13        0.13       1.14e+02    0.000501  0.121     0.122     2.54e+02  0.121         31.8      
16.0      0.13        0.13       1.23e+02    0.000501  0.118     0.12      2.88e+02  0.118         32.7      
17.0      0.124       0.124      1.16e+02    0.000501  0.124     0.125     1.3e+02   0.118         31.5      
18.0      0.122       0.122      1.19e+02    0.000501  0.117     0.118     1.5e+02   0.117         32.1      
19.0      0.122       0.122      1.07e+02    0.000501  0.124     0.125     2.05e+02  0.117         31.9      
20.0      0.119       0.119      1.18e+02    0.000501  0.119     0.12      1.25e+02  0.117         31.2      
21.0      0.113       0.113      84.9        0.000501  0.123     0.124     3.46e+02  0.117         30.7      
22.0      0.112       0.112      1.14e+02    0.000501  0.124     0.126     4.13e+02  0.117         30.7      
23.0      0.112       0.112      90.6        0.000501  0.118     0.12      1.33e+02  0.117         31.4      
24.0      0.108       0.108      1.04e+02    0.000501  0.116     0.118     1.96e+02  0.116         31.7      
25.0      0.107       0.107      96.9        0.000501  0.114     0.114     2.45e+02  0.114         31.1      
26.0      0.108       0.108      1.19e+02    0.000501  0.11      0.111     1.8e+02   0.11          30.9      
27.0      0.104       0.104      83.9        0.000501  0.111     0.112     2.32e+02  0.11          30.7      
28.0      0.103       0.103      72.1        0.000501  0.11      0.111     1.81e+02  0.11          30.9      
29.0      0.104       0.104      76.0        0.000501  0.104     0.105     59.0      0.104         30.9      
30.0      0.102       0.102      73.1        0.000501  0.109     0.11      1.08e+02  0.104         30.7      
31.0      0.0994      0.0994     88.8        0.000501  0.107     0.108     3.83e+02  0.104         30.7      
32.0      0.0976      0.0976     94.8        0.000501  0.105     0.106     1.96e+02  0.104         31.6      
33.0      0.0968      0.0968     89.6        0.000501  0.12      0.12      2.99e+02  0.104         30.2      
34.0      0.0925      0.0925     74.5        0.000501  0.109     0.111     1.71e+02  0.104         31.2      
35.0      0.0936      0.0936     83.3        0.000501  0.109     0.11      1.47e+02  0.104         31.2      
36.0      0.0919      0.0919     73.9        0.000501  0.108     0.11      3.82e+02  0.104         30.5      
37.0      0.0919      0.0919     96.9        0.000501  0.102     0.103     1.46e+02  0.102         32.0      
38.0      0.0887      0.0887     1e+02       0.000501  0.101     0.103     93.8      0.101         31.4      
39.0      0.0909      0.0909     90.3        0.000501  0.11      0.111     2.15e+02  0.101         31.0      
40.0      0.0883      0.0883     89.2        0.000501  0.102     0.104     3.33e+02  0.101         30.3      
41.0      0.0853      0.0853     1.12e+02    0.000501  0.0979    0.0992    1.56e+02  0.0979        31.4      
42.0      0.0854      0.0854     65.6        0.000501  0.0978    0.0989    1.3e+02   0.0978        31.3      
43.0      0.084       0.084      90.8        0.000501  0.108     0.108     2.98e+02  0.0978        30.8      
44.0      0.0811      0.0811     76.2        0.000501  0.111     0.111     3.08e+02  0.0978        30.4      
45.0      0.0823      0.0823     77.1        0.000501  0.102     0.103     2.59e+02  0.0978        30.6      
46.0      0.0807      0.0807     70.8        0.000501  0.103     0.104     2.65e+02  0.0978        31.0      
47.0      0.0783      0.0783     81.5        0.000501  0.103     0.104     1.48e+02  0.0978        31.1      
48.0      0.0796      0.0796     1e+02       0.000501  0.102     0.103     2.63e+02  0.0978        30.8      
49.0      0.0794      0.0794     73.3        0.000501  0.117     0.117     1.58e+02  0.0978        30.5      
50.0      0.0765      0.0765     73.7        0.000501  0.0963    0.0975    2.24e+02  0.0963        31.3      
    epoch  train_loss  train_mae  ...    val_mape  best_val_mae       time
0       1    0.418060   0.418060  ...  470.811798      0.250750  31.892599
1       2    0.269711   0.269711  ...  664.501099      0.197934  31.989506
2       3    0.222563   0.222563  ...  210.848328      0.197934  31.296293
3       4    0.193642   0.193642  ...  378.816589      0.197934  31.146717
4       5    0.185431   0.185430  ...  248.640320      0.169278  31.785560
5       6    0.173836   0.173836  ...  110.849312      0.156444  32.130466
6       7    0.167337   0.167337  ...  387.310364      0.133275  31.962226
7       8    0.159848   0.159848  ...  393.815369      0.133275  31.586401
8       9    0.155457   0.155457  ...  192.058167      0.128215  32.218834
9      10    0.149215   0.149215  ...  244.887939      0.128215  31.703583
10     11    0.142158   0.142158  ...  158.175873      0.128215  31.570732
11     12    0.141221   0.141221  ...  302.048615      0.128215  31.342138
12     13    0.133077   0.133077  ...  270.099762      0.126619  31.807615
13     14    0.131065   0.131065  ...  210.720444      0.126619  32.018846
14     15    0.129522   0.129522  ...  254.486710      0.120882  31.790525
15     16    0.130036   0.130036  ...  287.980194      0.118479  32.679222
16     17    0.123908   0.123908  ...  129.728775      0.118479  31.496004
17     18    0.122182   0.122182  ...  150.094421      0.117023  32.104888
18     19    0.121857   0.121857  ...  204.515091      0.117023  31.880452
19     20    0.119474   0.119474  ...  124.515457      0.117023  31.157111
20     21    0.112755   0.112755  ...  345.700806      0.117023  30.727919
21     22    0.111645   0.111645  ...  413.319489      0.117023  30.672611
22     23    0.111713   0.111713  ...  133.080048      0.117023  31.374611
23     24    0.108363   0.108363  ...  195.948807      0.116345  31.650450
24     25    0.106971   0.106971  ...  244.675003      0.113574  31.109031
25     26    0.107844   0.107844  ...  180.245850      0.109682  30.873437
26     27    0.104143   0.104143  ...  231.669357      0.109682  30.663597
27     28    0.102569   0.102569  ...  181.019897      0.109682  30.894633
28     29    0.104377   0.104377  ...   59.011734      0.103794  30.854897
29     30    0.101680   0.101680  ...  107.668221      0.103794  30.741612
30     31    0.099437   0.099437  ...  383.057159      0.103794  30.707651
31     32    0.097556   0.097556  ...  195.668411      0.103794  31.590781
32     33    0.096823   0.096823  ...  299.398346      0.103794  30.227021
33     34    0.092548   0.092548  ...  170.884659      0.103794  31.155675
34     35    0.093598   0.093598  ...  147.007843      0.103794  31.153250
35     36    0.091857   0.091857  ...  381.886383      0.103794  30.504256
36     37    0.091938   0.091938  ...  145.791351      0.101589  31.961715
37     38    0.088710   0.088710  ...   93.847603      0.101359  31.398251
38     39    0.090883   0.090883  ...  215.451828      0.101359  30.969530
39     40    0.088275   0.088275  ...  332.887634      0.101359  30.267228
40     41    0.085283   0.085283  ...  155.531342      0.097919  31.437577
41     42    0.085448   0.085448  ...  129.603745      0.097775  31.257017
42     43    0.084000   0.084000  ...  297.856079      0.097775  30.763904
43     44    0.081125   0.081125  ...  307.540131      0.097775  30.402826
44     45    0.082333   0.082333  ...  258.738068      0.097775  30.619064
45     46    0.080711   0.080711  ...  264.840149      0.097775  30.993381
46     47    0.078292   0.078292  ...  147.888596      0.097775  31.098948
47     48    0.079618   0.079618  ...  263.224701      0.097775  30.784258
48     49    0.079388   0.079388  ...  157.512115      0.097775  30.542756
49     50    0.076530   0.076530  ...  224.147064      0.096291  31.324702

[50 rows x 10 columns]


  0%|                                                                        | 0/32 [00:00<?, ?it/s][A

  0%|                       | 0/32 [00:00<?, ?it/s, val_loss=0.0891, val_mae=0.0891, val_mape=0.165][A

  3%|‚ñç              | 1/32 [00:00<00:20,  1.50it/s, val_loss=0.0891, val_mae=0.0891, val_mape=0.165][A

  3%|‚ñç              | 1/32 [00:00<00:20,  1.50it/s, val_loss=0.0952, val_mae=0.0952, val_mape=0.274][A

  3%|‚ñå               | 1/32 [00:00<00:20,  1.50it/s, val_loss=0.0771, val_mae=0.0771, val_mape=0.84][A

  3%|‚ñç              | 1/32 [00:00<00:20,  1.50it/s, val_loss=0.0676, val_mae=0.0676, val_mape=0.143][A

  3%|‚ñå                | 1/32 [00:00<00:20,  1.50it/s, val_loss=0.136, val_mae=0.136, val_mape=0.334][A

 16%|‚ñà‚ñà‚ñã              | 5/32 [00:00<00:03,  8.07it/s, val_loss=0.136, val_mae=0.136, val_mape=0.334][A

 16%|‚ñà‚ñà‚ñâ                | 5/32 [00:00<00:03,  8.07it/s, val_loss=0.15, val_mae=0.15, val_mape=0.404][A

 16%|‚ñà‚ñà‚ñä               | 5/32 [00:00<00:03,  8.07it/s, val_loss=0.103, val_mae=0.103, val_mape=2.82][A

 16%|‚ñà‚ñà‚ñã              | 5/32 [00:00<00:03,  8.07it/s, val_loss=0.119, val_mae=0.119, val_mape=0.367][A

 25%|‚ñà‚ñà‚ñà‚ñà‚ñé            | 8/32 [00:00<00:02, 10.95it/s, val_loss=0.119, val_mae=0.119, val_mape=0.367][A

 25%|‚ñà‚ñà‚ñà‚ñà‚ñé            | 8/32 [00:01<00:02, 10.95it/s, val_loss=0.101, val_mae=0.101, val_mape=0.467][A

 25%|‚ñà‚ñà‚ñà‚ñä           | 8/32 [00:01<00:02, 10.95it/s, val_loss=0.0575, val_mae=0.0575, val_mape=0.269][A

 25%|‚ñà‚ñà‚ñà‚ñà‚ñä              | 8/32 [00:01<00:02, 10.95it/s, val_loss=0.196, val_mae=0.196, val_mape=774][A

 34%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè           | 11/32 [00:01<00:01, 14.26it/s, val_loss=0.196, val_mae=0.196, val_mape=774][A

 34%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå          | 11/32 [00:01<00:01, 14.26it/s, val_loss=0.108, val_mae=0.108, val_mape=0.284][A

 34%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå          | 11/32 [00:01<00:01, 14.26it/s, val_loss=0.134, val_mae=0.134, val_mape=0.505][A

 34%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ             | 11/32 [00:01<00:01, 14.26it/s, val_loss=0.1, val_mae=0.1, val_mape=0.302][A

 44%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä           | 14/32 [00:01<00:01, 16.53it/s, val_loss=0.1, val_mae=0.1, val_mape=0.302][A

 44%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå        | 14/32 [00:01<00:01, 16.53it/s, val_loss=0.0855, val_mae=0.0855, val_mape=34.4][A

 44%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè       | 14/32 [00:01<00:01, 16.53it/s, val_loss=0.0793, val_mae=0.0793, val_mape=0.181][A

 44%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè       | 14/32 [00:01<00:01, 16.53it/s, val_loss=0.0981, val_mae=0.0981, val_mape=0.948][A

 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç      | 17/32 [00:01<00:00, 17.60it/s, val_loss=0.0981, val_mae=0.0981, val_mape=0.948][A

 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå       | 17/32 [00:01<00:00, 17.60it/s, val_loss=0.105, val_mae=0.105, val_mape=0.497][A

 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà        | 17/32 [00:01<00:00, 17.60it/s, val_loss=0.121, val_mae=0.121, val_mape=0.33][A

 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç      | 17/32 [00:01<00:00, 17.60it/s, val_loss=0.0779, val_mae=0.0779, val_mape=0.539][A

 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä     | 20/32 [00:01<00:00, 17.20it/s, val_loss=0.0779, val_mae=0.0779, val_mape=0.539][A

 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã      | 20/32 [00:01<00:00, 17.20it/s, val_loss=0.103, val_mae=0.103, val_mape=1.34][A

 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 20/32 [00:01<00:00, 17.20it/s, val_loss=0.0891, val_mae=0.0891, val_mape=1.18e+3][A

 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä     | 20/32 [00:01<00:00, 17.20it/s, val_loss=0.0853, val_mae=0.0853, val_mape=0.443][A

 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 23/32 [00:01<00:00, 18.60it/s, val_loss=0.0853, val_mae=0.0853, val_mape=0.443][A

 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 23/32 [00:01<00:00, 18.60it/s, val_loss=0.126, val_mae=0.126, val_mape=0.635][A

 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 23/32 [00:01<00:00, 18.60it/s, val_loss=0.124, val_mae=0.124, val_mape=0.306][A

 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 23/32 [00:01<00:00, 18.60it/s, val_loss=0.0711, val_mae=0.0711, val_mape=0.791][A

 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 26/32 [00:01<00:00, 19.66it/s, val_loss=0.0711, val_mae=0.0711, val_mape=0.791][A

 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 26/32 [00:01<00:00, 19.66it/s, val_loss=0.22, val_mae=0.22, val_mape=717][A

 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 26/32 [00:01<00:00, 19.66it/s, val_loss=0.0829, val_mae=0.0829, val_mape=0.423][A

 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 26/32 [00:01<00:00, 19.66it/s, val_loss=0.0862, val_mae=0.0862, val_mape=2.3][A

 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 29/32 [00:01<00:00, 19.62it/s, val_loss=0.0862, val_mae=0.0862, val_mape=2.3][A

 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 29/32 [00:01<00:00, 19.62it/s, val_loss=0.0876, val_mae=0.0876, val_mape=0.27][A

 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 29/32 [00:02<00:00, 19.62it/s, val_loss=0.0696, val_mae=0.0696, val_mape=0.173][A

 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 29/32 [00:02<00:00, 19.62it/s, val_loss=0.105, val_mae=0.105, val_mape=87.2][A

100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 18.11it/s, val_loss=0.105, val_mae=0.105, val_mape=87.2][A
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 14.92it/s, val_loss=0.105, val_mae=0.105, val_mape=87.2]
                                                                                          

Best trial: 7. Best value: 0.0859608:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 35/80 [4:23:58<2:09:58, 173.30s/it]
Best trial: 7. Best value: 0.0859608:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 35/80 [4:23:59<2:09:58, 173.30s/it]
Best trial: 7. Best value: 0.0859608:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 36/80 [4:23:59<7:13:49, 591.58s/it]
{'val_loss': 0.1050067248288542, 'val_mae': 0.10478377342224121, 'val_mape': 87.24845123291016}

üèÅ Trial #67 completed! Result: 0.097525
[I 2025-07-13 20:21:07,030] Trial 67 finished with value: 0.09752453863620758 and parameters: {'lr': 0.0005005863162987381, 'dropout_rate': 0.14311360478157698, 'weight_decay': 0.00035196385472040703, 'batch_size': 48, 'hidden_features': 96, 'coulomb_param': 1.050891320923922, 'london_param': 0.6859842601094168, 'pauli_param': 4.325242376173977, 'R_grid': 5}. Best is trial 7 with value: 0.08596083521842957.

üöÄ Starting Trial #68 (Seed: 1346)
  Parameters:
    - lr: 0.0007104312376794284
    - dropout_rate: 0.14894085202696553
    - weight_decay: 0.00021007977025206794
    - batch_size: 48
    - hidden_features: 96
    - coulomb_param: 1.0487007277091414
    - london_param: 0.7207934535617982
    - pauli_param: 3.9472623304644117
    - R_grid: 5
train length: 12000 val length: 1500 test length: 1500 unused length: 0 seed : 1346
[0;31m<<<<<< ‚ö°Ô∏è cuda is used >>>>>>[0m
‚ñà
epoch     train_loss  train_mae  train_mape  lr        val_loss  val_mae   val_mape  best_val_mae  time    
1.0       0.454       0.454      3.49e+02    0.00071   0.218     0.219     6.11e+02  0.218         31.5      
2.0       0.252       0.252      3.16e+02    0.00071   0.185     0.185     6.24e+02  0.185         31.6      
3.0       0.224       0.224      2.8e+02     0.00071   0.175     0.176     4.71e+02  0.175         31.4      
4.0       0.197       0.197      2.53e+02    0.00071   0.166     0.166     5.5e+02   0.166         31.7      
5.0       0.186       0.186      2.29e+02    0.00071   0.168     0.168     7.52e+02  0.166         30.6      
6.0       0.184       0.184      2.08e+02    0.00071   0.162     0.163     4.54e+02  0.162         31.1      
7.0       0.17        0.17       2.16e+02    0.00071   0.138     0.139     9.02e+02  0.138         31.0      
8.0       0.164       0.164      1.67e+02    0.00071   0.139     0.138     6.78e+02  0.138         30.5      
9.0       0.158       0.158      1.56e+02    0.00071   0.159     0.158     6.29e+02  0.138         30.9      
10.0      0.158       0.158      1.8e+02     0.00071   0.137     0.137     4.55e+02  0.137         31.0      
11.0      0.145       0.145      1.96e+02    0.00071   0.12      0.12      8.72e+02  0.12          32.6      
12.0      0.142       0.142      1.8e+02     0.00071   0.119     0.119     7.21e+02  0.119         31.4      
13.0      0.14        0.14       1.69e+02    0.00071   0.12      0.12      4.97e+02  0.119         31.5      
14.0      0.139       0.139      1.29e+02    0.00071   0.138     0.137     6.2e+02   0.119         32.1      
15.0      0.134       0.134      1.24e+02    0.00071   0.12      0.119     3.98e+02  0.119         31.5      
16.0      0.13        0.13       1.34e+02    0.00071   0.134     0.133     3.52e+02  0.119         31.3      
17.0      0.127       0.127      1.62e+02    0.00071   0.145     0.145     3.93e+02  0.119         32.2      
18.0      0.127       0.127      1.31e+02    0.00071   0.129     0.13      5.15e+02  0.119         32.2      
19.0      0.125       0.125      1.39e+02    0.00071   0.114     0.114     3.99e+02  0.114         32.2      
20.0      0.118       0.118      1.6e+02     0.00071   0.131     0.13      3.04e+02  0.114         32.0      
21.0      0.118       0.118      1.4e+02     0.00071   0.119     0.118     4.69e+02  0.114         30.4      
22.0      0.115       0.115      1.31e+02    0.00071   0.109     0.109     4.54e+02  0.109         32.3      
23.0      0.112       0.112      1.24e+02    0.00071   0.108     0.108     2.94e+02  0.108         31.8      
24.0      0.113       0.113      96.4        0.00071   0.106     0.106     2.97e+02  0.106         31.4      
25.0      0.11        0.11       1.13e+02    0.00071   0.111     0.11      3.14e+02  0.106         31.4      
26.0      0.111       0.111      1.34e+02    0.00071   0.124     0.124     2.83e+02  0.106         31.0      
27.0      0.109       0.109      86.2        0.00071   0.104     0.104     1.97e+02  0.104         31.8      
28.0      0.106       0.106      1.11e+02    0.00071   0.104     0.105     1.89e+02  0.104         31.3      
29.0      0.102       0.102      1.28e+02    0.00071   0.105     0.105     2.29e+02  0.104         30.4      
30.0      0.102       0.102      1.16e+02    0.00071   0.0982    0.0981    3.05e+02  0.0982        30.9      
31.0      0.101       0.101      1.05e+02    0.00071   0.0972    0.0968    2.41e+02  0.0972        32.4      
32.0      0.0995      0.0995     1.24e+02    0.00071   0.102     0.101     1.93e+02  0.0972        31.5      
33.0      0.0967      0.0967     1.32e+02    0.00071   0.104     0.104     2.57e+02  0.0972        31.5      
34.0      0.0952      0.0952     93.3        0.00071   0.098     0.0982    2.58e+02  0.0972        31.6      
35.0      0.0933      0.0933     93.0        0.00071   0.0994    0.0985    1.68e+02  0.0972        31.4      
36.0      0.0917      0.0917     1.02e+02    0.00071   0.103     0.103     2.61e+02  0.0972        31.5      
37.0      0.0924      0.0924     1.35e+02    0.00071   0.0961    0.0955    1.42e+02  0.0961        31.7      
38.0      0.0917      0.0917     89.4        0.00071   0.0963    0.0959    2.84e+02  0.0961        31.5      
39.0      0.0879      0.0879     95.4        0.00071   0.112     0.111     2.55e+02  0.0961        31.3      
40.0      0.085       0.085      91.0        0.00071   0.0945    0.0948    2.95e+02  0.0945        32.1      
41.0      0.085       0.085      95.3        0.00071   0.0992    0.0991    1.7e+02   0.0945        31.4      
42.0      0.0851      0.0851     1.02e+02    0.00071   0.0935    0.0932    2.26e+02  0.0935        32.2      
43.0      0.0873      0.0873     82.2        0.00071   0.0995    0.0992    1.78e+02  0.0935        31.4      
44.0      0.0825      0.0825     88.2        0.00071   0.0966    0.097     1.56e+02  0.0935        31.1      
45.0      0.0831      0.0831     98.9        0.00071   0.0958    0.0958    2.12e+02  0.0935        31.4      
46.0      0.0798      0.0798     91.8        0.00071   0.111     0.111     2.05e+02  0.0935        30.7      
47.0      0.0802      0.0802     95.0        0.00071   0.0961    0.0955    3.53e+02  0.0935        30.8      
48.0      0.0803      0.0803     1.38e+02    0.00071   0.0933    0.0931    1.78e+02  0.0933        31.9      
49.0      0.0791      0.0791     76.3        0.00071   0.106     0.106     2.14e+02  0.0933        32.0      
50.0      0.0777      0.0777     78.5        0.00071   0.103     0.104     4.19e+02  0.0933        31.4      
    epoch  train_loss  train_mae  ...    val_mape  best_val_mae       time
0       1    0.453551   0.453551  ...  611.122070      0.217507  31.541557
1       2    0.252205   0.252205  ...  623.882996      0.184641  31.569893
2       3    0.224008   0.224008  ...  471.054871      0.174709  31.446955
3       4    0.196860   0.196861  ...  549.942932      0.165814  31.651635
4       5    0.186137   0.186137  ...  751.627502      0.165814  30.623100
5       6    0.184240   0.184240  ...  454.316528      0.161528  31.142258
6       7    0.169837   0.169837  ...  902.412720      0.137939  31.014018
7       8    0.163535   0.163535  ...  678.043640      0.137939  30.482303
8       9    0.158192   0.158192  ...  628.827148      0.137939  30.946088
9      10    0.157849   0.157849  ...  455.242950      0.136550  31.027360
10     11    0.144678   0.144678  ...  871.760254      0.120360  32.570037
11     12    0.141821   0.141821  ...  721.453186      0.119041  31.369288
12     13    0.139674   0.139674  ...  497.382416      0.119041  31.487713
13     14    0.138779   0.138779  ...  620.079041      0.119041  32.145791
14     15    0.134345   0.134345  ...  397.629883      0.119041  31.507551
15     16    0.130089   0.130089  ...  352.205261      0.119041  31.325085
16     17    0.127074   0.127074  ...  392.768829      0.119041  32.218964
17     18    0.126894   0.126894  ...  515.021973      0.119041  32.225992
18     19    0.124613   0.124613  ...  398.538971      0.113817  32.150520
19     20    0.117665   0.117665  ...  304.266357      0.113817  31.982601
20     21    0.117506   0.117506  ...  468.515594      0.113817  30.422048
21     22    0.115245   0.115245  ...  454.200043      0.109392  32.327400
22     23    0.111799   0.111799  ...  293.794342      0.107517  31.827034
23     24    0.112722   0.112722  ...  297.097137      0.106309  31.388744
24     25    0.109565   0.109565  ...  313.747467      0.106309  31.443422
25     26    0.111447   0.111447  ...  283.011627      0.106309  31.010181
26     27    0.108723   0.108723  ...  196.828232      0.104242  31.832431
27     28    0.105559   0.105559  ...  189.102356      0.104242  31.312679
28     29    0.102280   0.102280  ...  228.681625      0.104242  30.446532
29     30    0.101572   0.101572  ...  304.705170      0.098186  30.883630
30     31    0.100643   0.100643  ...  241.128876      0.097197  32.382638
31     32    0.099519   0.099519  ...  193.498184      0.097197  31.510124
32     33    0.096676   0.096676  ...  256.602203      0.097197  31.539104
33     34    0.095194   0.095194  ...  258.388580      0.097197  31.587838
34     35    0.093271   0.093271  ...  168.300995      0.097197  31.423587
35     36    0.091671   0.091671  ...  261.440247      0.097197  31.499133
36     37    0.092396   0.092396  ...  142.373215      0.096128  31.698536
37     38    0.091654   0.091654  ...  284.008514      0.096128  31.548518
38     39    0.087869   0.087869  ...  255.481705      0.096128  31.263735
39     40    0.084971   0.084971  ...  295.259705      0.094548  32.138835
40     41    0.085035   0.085035  ...  170.397324      0.094548  31.369960
41     42    0.085079   0.085079  ...  225.751877      0.093486  32.174671
42     43    0.087334   0.087334  ...  178.052521      0.093486  31.361731
43     44    0.082522   0.082522  ...  155.754150      0.093486  31.095285
44     45    0.083128   0.083128  ...  212.197235      0.093486  31.351054
45     46    0.079764   0.079764  ...  204.966431      0.093486  30.661912
46     47    0.080243   0.080243  ...  352.963806      0.093486  30.849461
47     48    0.080293   0.080293  ...  177.786743      0.093289  31.863191
48     49    0.079089   0.079089  ...  213.725494      0.093289  32.024215
49     50    0.077720   0.077720  ...  419.449280      0.093289  31.378519

[50 rows x 10 columns]


  0%|                                                                        | 0/32 [00:00<?, ?it/s][A

  0%|                           | 0/32 [00:00<?, ?it/s, val_loss=0.237, val_mae=0.237, val_mape=501][A

  3%|‚ñå                  | 1/32 [00:00<00:23,  1.34it/s, val_loss=0.237, val_mae=0.237, val_mape=501][A

  3%|‚ñç              | 1/32 [00:00<00:23,  1.34it/s, val_loss=0.0752, val_mae=0.0752, val_mape=0.828][A

  3%|‚ñå                | 1/32 [00:00<00:23,  1.34it/s, val_loss=0.106, val_mae=0.106, val_mape=0.355][A

  3%|‚ñå                 | 1/32 [00:00<00:23,  1.34it/s, val_loss=0.137, val_mae=0.137, val_mape=0.37][A

 12%|‚ñà‚ñà‚ñé               | 4/32 [00:00<00:04,  5.72it/s, val_loss=0.137, val_mae=0.137, val_mape=0.37][A

 12%|‚ñà‚ñà‚ñè              | 4/32 [00:00<00:04,  5.72it/s, val_loss=0.116, val_mae=0.116, val_mape=0.444][A

 12%|‚ñà‚ñà‚ñè              | 4/32 [00:00<00:04,  5.72it/s, val_loss=0.0609, val_mae=0.0609, val_mape=0.2][A

 12%|‚ñà‚ñà‚ñè              | 4/32 [00:01<00:04,  5.72it/s, val_loss=0.109, val_mae=0.109, val_mape=0.509][A

 22%|‚ñà‚ñà‚ñà‚ñã             | 7/32 [00:01<00:02,  9.04it/s, val_loss=0.109, val_mae=0.109, val_mape=0.509][A

 22%|‚ñà‚ñà‚ñà‚ñã             | 7/32 [00:01<00:02,  9.04it/s, val_loss=0.108, val_mae=0.108, val_mape=0.848][A

 22%|‚ñà‚ñà‚ñà‚ñà‚ñè              | 7/32 [00:01<00:02,  9.04it/s, val_loss=0.107, val_mae=0.107, val_mape=3.2][A

 22%|‚ñà‚ñà‚ñà‚ñå            | 7/32 [00:01<00:02,  9.04it/s, val_loss=0.0969, val_mae=0.0969, val_mape=0.25][A

 22%|‚ñà‚ñà‚ñà‚ñé           | 7/32 [00:01<00:02,  9.04it/s, val_loss=0.0927, val_mae=0.0927, val_mape=0.402][A

 34%|‚ñà‚ñà‚ñà‚ñà‚ñä         | 11/32 [00:01<00:01, 14.33it/s, val_loss=0.0927, val_mae=0.0927, val_mape=0.402][A

 34%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå          | 11/32 [00:01<00:01, 14.33it/s, val_loss=0.101, val_mae=0.101, val_mape=0.277][A

 34%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå          | 11/32 [00:01<00:01, 14.33it/s, val_loss=0.085, val_mae=0.085, val_mape=0.239][A

 34%|‚ñà‚ñà‚ñà‚ñà‚ñä         | 11/32 [00:01<00:01, 14.33it/s, val_loss=0.0875, val_mae=0.0875, val_mape=0.541][A

 44%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè       | 14/32 [00:01<00:01, 16.24it/s, val_loss=0.0875, val_mae=0.0875, val_mape=0.541][A

 44%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä           | 14/32 [00:01<00:01, 16.24it/s, val_loss=0.12, val_mae=0.12, val_mape=396][A

 44%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè       | 14/32 [00:01<00:01, 16.24it/s, val_loss=0.0928, val_mae=0.0928, val_mape=0.554][A

 44%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà         | 14/32 [00:01<00:01, 16.24it/s, val_loss=0.112, val_mae=0.112, val_mape=0.818][A

 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå       | 17/32 [00:01<00:00, 17.50it/s, val_loss=0.112, val_mae=0.112, val_mape=0.818][A

 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà        | 17/32 [00:01<00:00, 17.50it/s, val_loss=0.215, val_mae=0.215, val_mape=1.23][A

 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà        | 17/32 [00:01<00:00, 17.50it/s, val_loss=0.117, val_mae=0.117, val_mape=0.84][A

 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå       | 17/32 [00:01<00:00, 17.50it/s, val_loss=0.099, val_mae=0.099, val_mape=0.994][A

 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà      | 20/32 [00:01<00:00, 18.85it/s, val_loss=0.099, val_mae=0.099, val_mape=0.994][A

 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä     | 20/32 [00:01<00:00, 18.85it/s, val_loss=0.0917, val_mae=0.0917, val_mape=0.405][A

 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä     | 20/32 [00:01<00:00, 18.85it/s, val_loss=0.0985, val_mae=0.0985, val_mape=0.845][A

 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä     | 20/32 [00:01<00:00, 18.85it/s, val_loss=0.0812, val_mae=0.0812, val_mape=0.233][A

 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 23/32 [00:01<00:00, 19.44it/s, val_loss=0.0812, val_mae=0.0812, val_mape=0.233][A

 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 23/32 [00:01<00:00, 19.44it/s, val_loss=0.0913, val_mae=0.0913, val_mape=0.336][A

 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 23/32 [00:01<00:00, 19.44it/s, val_loss=0.0832, val_mae=0.0832, val_mape=0.191][A

 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 23/32 [00:01<00:00, 19.44it/s, val_loss=0.0701, val_mae=0.0701, val_mape=0.4][A

 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 26/32 [00:01<00:00, 19.75it/s, val_loss=0.0701, val_mae=0.0701, val_mape=0.4][A

 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 26/32 [00:01<00:00, 19.75it/s, val_loss=0.0889, val_mae=0.0889, val_mape=0.267][A

 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 26/32 [00:01<00:00, 19.75it/s, val_loss=0.0939, val_mae=0.0939, val_mape=0.256][A

 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 26/32 [00:02<00:00, 19.75it/s, val_loss=0.0663, val_mae=0.0663, val_mape=0.126][A

 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 29/32 [00:02<00:00, 20.35it/s, val_loss=0.0663, val_mae=0.0663, val_mape=0.126][A

 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 29/32 [00:02<00:00, 20.35it/s, val_loss=0.0911, val_mae=0.0911, val_mape=0.211][A

 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 29/32 [00:02<00:00, 20.35it/s, val_loss=0.0898, val_mae=0.0898, val_mape=0.326][A

 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 29/32 [00:02<00:00, 20.35it/s, val_loss=0.104, val_mae=0.104, val_mape=29.3][A

100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 18.69it/s, val_loss=0.104, val_mae=0.104, val_mape=29.3][A
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 14.60it/s, val_loss=0.104, val_mae=0.104, val_mape=29.3]
                                                                                          

Best trial: 7. Best value: 0.0859608:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 36/80 [4:50:16<7:13:49, 591.58s/it]
Best trial: 7. Best value: 0.0859608:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 36/80 [4:50:16<7:13:49, 591.58s/it]
Best trial: 7. Best value: 0.0859608:  46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 37/80 [4:50:16<10:35:54, 887.31s/it]
{'val_loss': 0.10428250709082931, 'val_mae': 0.1039753407239914, 'val_mape': 29.260591506958008}

üèÅ Trial #68 completed! Result: 0.093143
[I 2025-07-13 20:47:24,408] Trial 68 finished with value: 0.09314342588186264 and parameters: {'lr': 0.0007104312376794284, 'dropout_rate': 0.14894085202696553, 'weight_decay': 0.00021007977025206794, 'batch_size': 48, 'hidden_features': 96, 'coulomb_param': 1.0487007277091414, 'london_param': 0.7207934535617982, 'pauli_param': 3.9472623304644117, 'R_grid': 5}. Best is trial 7 with value: 0.08596083521842957.

üöÄ Starting Trial #69 (Seed: 1356)
  Parameters:
    - lr: 0.0007180161051349673
    - dropout_rate: 0.23083007326785704
    - weight_decay: 0.0002137700889571036
    - batch_size: 48
    - hidden_features: 96
    - coulomb_param: 1.0941015398187166
    - london_param: 0.807353262358255
    - pauli_param: 3.953162908425148
    - R_grid: 5
train length: 12000 val length: 1500 test length: 1500 unused length: 0 seed : 1356
[0;31m<<<<<< ‚ö°Ô∏è cuda is used >>>>>>[0m
‚ñà
epoch     train_loss  train_mae  train_mape  lr        val_loss  val_mae   val_mape  best_val_mae  time    
1.0       0.445       0.445      8.88e+02    0.000718  0.312     0.313     4.89e+02  0.312         31.7      
2.0       0.261       0.261      3.1e+02     0.000718  0.211     0.211     2.64e+02  0.211         32.4      
3.0       0.224       0.224      2.18e+02    0.000718  0.207     0.208     4.07e+02  0.207         32.0      
4.0       0.206       0.206      1.82e+02    0.000718  0.224     0.226     80.9      0.207         31.9      
5.0       0.189       0.189      2.38e+02    0.000718  0.191     0.192     2.19e+02  0.191         31.7      
6.0       0.179       0.179      1.37e+02    0.000718  0.165     0.165     1.78e+02  0.165         32.4      
7.0       0.17        0.17       1.78e+02    0.000718  0.164     0.165     2.62e+02  0.164         31.4      

‚Äã                                                                                           

Best trial: 7. Best value: 0.0859608:  46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 37/80 [4:54:32<10:35:54, 887.31s/it]
Best trial: 7. Best value: 0.0859608:  46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 37/80 [4:54:32<10:35:54, 887.31s/it]
Best trial: 7. Best value: 0.0859608:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 38/80 [4:54:32<8:08:31, 697.90s/it] 
‚úÇÔ∏è Trial #69 pruned!
[I 2025-07-13 20:51:40,445] Trial 69 pruned. 

üöÄ Starting Trial #70 (Seed: 1366)
  Parameters:
    - lr: 0.0008140698498861122
    - dropout_rate: 0.14940703490218832
    - weight_decay: 0.0001629493837846854
    - batch_size: 96
    - hidden_features: 96
    - coulomb_param: 1.3586411615666825
    - london_param: 0.5836818946039624
    - pauli_param: 3.4419857888595327
    - R_grid: 5
train length: 12000 val length: 1500 test length: 1500 unused length: 0 seed : 1366
[0;31m<<<<<< ‚ö°Ô∏è cuda is used >>>>>>[0m
‚ñà
epoch     train_loss  train_mae  train_mape  lr        val_loss  val_mae   val_mape  best_val_mae  time    
1.0       0.461       0.461      6.23e+02    0.000814  0.257     0.256     96.6      0.257         19.5      
2.0       0.26        0.26       4.8e+02     0.000814  0.23      0.229     17.1      0.23          19.4      
3.0       0.244       0.244      3.41e+02    0.000814  0.262     0.261     67.4      0.23          18.7      
4.0       0.199       0.199      2.32e+02    0.000814  0.195     0.194     43.3      0.195         19.1      
5.0       0.185       0.185      1.82e+02    0.000814  0.202     0.201     91.2      0.195         19.3      
6.0       0.18        0.18       2.57e+02    0.000814  0.158     0.157     97.7      0.158         19.3      
7.0       0.17        0.17       1.84e+02    0.000814  0.158     0.157     7.48      0.158         19.3      

‚Äã                                                                                          

Best trial: 7. Best value: 0.0859608:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 38/80 [4:57:06<8:08:31, 697.90s/it]
Best trial: 7. Best value: 0.0859608:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 38/80 [4:57:06<8:08:31, 697.90s/it]
Best trial: 7. Best value: 0.0859608:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 39/80 [4:57:06<6:05:22, 534.71s/it]
‚úÇÔ∏è Trial #70 pruned!
[I 2025-07-13 20:54:14,364] Trial 70 pruned. 

üöÄ Starting Trial #71 (Seed: 1376)
  Parameters:
    - lr: 0.0010966566555888828
    - dropout_rate: 0.0701267430906252
    - weight_decay: 0.00012994377719649505
    - batch_size: 64
    - hidden_features: 128
    - coulomb_param: 1.255263919427607
    - london_param: 0.7427972030478789
    - pauli_param: 3.666443212838975
    - R_grid: 6
train length: 12000 val length: 1500 test length: 1500 unused length: 0 seed : 1376
[0;31m<<<<<< ‚ö°Ô∏è cuda is used >>>>>>[0m
‚ñà
epoch     train_loss  train_mae  train_mape  lr        val_loss  val_mae   val_mape  best_val_mae  time    
1.0       0.535       0.535      5.43e+02    0.0011    0.349     0.349     1.04e+02  0.349         27.0      
2.0       0.28        0.28       3.67e+02    0.0011    0.228     0.229     15.5      0.228         26.5      
3.0       0.219       0.219      2.76e+02    0.0011    0.291     0.291     72.7      0.228         26.8      
4.0       0.211       0.21       2.47e+02    0.0011    0.169     0.169     96.6      0.169         27.0      
5.0       0.186       0.186      1.84e+02    0.0011    0.164     0.163     46.0      0.164         27.6      
6.0       0.181       0.182      1.44e+02    0.0011    0.151     0.15      35.0      0.151         27.3      
7.0       0.16        0.16       1.96e+02    0.0011    0.167     0.167     52.3      0.151         27.2      
8.0       0.164       0.164      1.68e+02    0.0011    0.157     0.157     28.2      0.151         26.7      
9.0       0.15        0.15       2.2e+02     0.0011    0.151     0.151     82.1      0.151         26.8      
10.0      0.144       0.144      1.78e+02    0.0011    0.147     0.148     36.8      0.147         27.4      
11.0      0.144       0.144      1.47e+02    0.0011    0.164     0.165     36.8      0.147         26.7      

‚Äã                                                                                          

Best trial: 7. Best value: 0.0859608:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 39/80 [5:02:30<6:05:22, 534.71s/it]
Best trial: 7. Best value: 0.0859608:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 39/80 [5:02:30<6:05:22, 534.71s/it]
Best trial: 7. Best value: 0.0859608:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 40/80 [5:02:30<5:14:19, 471.48s/it]
‚úÇÔ∏è Trial #71 pruned!
[I 2025-07-13 20:59:38,305] Trial 71 pruned. 

üöÄ Starting Trial #72 (Seed: 1386)
  Parameters:
    - lr: 0.0009097705373876821
    - dropout_rate: 0.16360589604455214
    - weight_decay: 4.319768665431127e-05
    - batch_size: 48
    - hidden_features: 160
    - coulomb_param: 0.9817552312989736
    - london_param: 1.4200747322360938
    - pauli_param: 1.1168003192369989
    - R_grid: 5
train length: 12000 val length: 1500 test length: 1500 unused length: 0 seed : 1386
[0;31m<<<<<< ‚ö°Ô∏è cuda is used >>>>>>[0m
‚ñà
epoch     train_loss  train_mae  train_mape  lr        val_loss  val_mae   val_mape  best_val_mae  time    
1.0       0.569       0.569      5.39e+02    0.00091   0.273     0.274     9.51e+02  0.273         35.7      
2.0       0.269       0.269      3.08e+02    0.00091   0.207     0.207     5.3e+02   0.207         35.0      
3.0       0.237       0.237      2.41e+02    0.00091   0.217     0.219     3.86e+02  0.207         34.2      
4.0       0.21        0.21       2.11e+02    0.00091   0.237     0.238     2.77e+02  0.207         35.8      
5.0       0.197       0.197      2.5e+02     0.00091   0.194     0.194     3.48e+02  0.194         35.8      
6.0       0.185       0.185      1.78e+02    0.00091   0.154     0.155     5.37e+02  0.154         35.6      
7.0       0.17        0.17       1.88e+02    0.00091   0.16      0.161     2.64e+02  0.154         35.1      

‚Äã                                                                                          

Best trial: 7. Best value: 0.0859608:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 40/80 [5:07:11<5:14:19, 471.48s/it]
Best trial: 7. Best value: 0.0859608:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 40/80 [5:07:12<5:14:19, 471.48s/it]
Best trial: 7. Best value: 0.0859608:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 41/80 [5:07:12<4:29:28, 414.57s/it]
‚úÇÔ∏è Trial #72 pruned!
[I 2025-07-13 21:04:20,049] Trial 72 pruned. 

üöÄ Starting Trial #73 (Seed: 1396)
  Parameters:
    - lr: 0.002219213285411452
    - dropout_rate: 0.1334043356443178
    - weight_decay: 1.554412056497543e-05
    - batch_size: 96
    - hidden_features: 96
    - coulomb_param: 1.4272785137800865
    - london_param: 1.5551704789814809
    - pauli_param: 2.308641069649251
    - R_grid: 4
train length: 12000 val length: 1500 test length: 1500 unused length: 0 seed : 1396
[0;31m<<<<<< ‚ö°Ô∏è cuda is used >>>>>>[0m
‚ñà
epoch     train_loss  train_mae  train_mape  lr        val_loss  val_mae   val_mape  best_val_mae  time    
1.0       0.609       0.609      9.86e+02    0.00222   0.307     0.308     2.61e+02  0.307         20.1      
2.0       0.277       0.277      4.56e+02    0.00222   0.272     0.273     1.15e+02  0.272         19.4      
3.0       0.258       0.258      3.18e+02    0.00222   0.232     0.232     1.2e+02   0.232         19.4      
4.0       0.222       0.222      1.97e+02    0.00222   0.358     0.36      39.4      0.232         19.2      
5.0       0.201       0.201      2.3e+02     0.00222   0.166     0.164     1.16e+02  0.166         19.1      
6.0       0.183       0.183      2.86e+02    0.00222   0.191     0.191     1.12e+02  0.166         19.1      
7.0       0.18        0.18       2.58e+02    0.00222   0.164     0.164     42.9      0.164         18.9      
8.0       0.165       0.165      2.3e+02     0.00222   0.145     0.145     1.14e+02  0.145         19.1      
9.0       0.152       0.152      2.06e+02    0.00222   0.147     0.147     34.5      0.145         18.7      
10.0      0.163       0.163      1.56e+02    0.00222   0.138     0.138     1.2e+02   0.138         19.4      
11.0      0.148       0.148      1.74e+02    0.00222   0.15      0.15      1.52e+02  0.138         18.8      
12.0      0.148       0.148      1.66e+02    0.00222   0.138     0.138     1.84e+02  0.138         19.3      
13.0      0.144       0.144      1.22e+02    0.00222   0.128     0.128     95.3      0.128         20.1      
14.0      0.133       0.133      1.24e+02    0.00222   0.141     0.141     69.2      0.128         19.2      
15.0      0.126       0.126      1.33e+02    0.00222   0.128     0.127     98.1      0.128         20.3      
16.0      0.128       0.128      1.53e+02    0.00222   0.139     0.139     20.6      0.128         19.2      
17.0      0.125       0.125      1.8e+02     0.00222   0.127     0.128     1.41e+02  0.127         19.2      
18.0      0.125       0.125      1.41e+02    0.00222   0.124     0.123     1.11e+02  0.124         19.2      
19.0      0.121       0.121      1.42e+02    0.00222   0.125     0.125     39.2      0.124         19.1      
20.0      0.12        0.12       1.22e+02    0.00222   0.122     0.122     91.7      0.122         19.3      
21.0      0.127       0.127      1.01e+02    0.00222   0.127     0.127     84.4      0.122         18.9      
22.0      0.116       0.116      2.18e+02    0.00222   0.117     0.116     1.37e+02  0.117         19.6      
23.0      0.118       0.118      1.41e+02    0.00222   0.118     0.117     1.06e+02  0.117         18.7      
24.0      0.112       0.112      1.2e+02     0.00222   0.116     0.115     64.1      0.116         19.2      
25.0      0.113       0.113      1.43e+02    0.00222   0.124     0.124     49.5      0.116         19.2      
26.0      0.105       0.105      1.24e+02    0.00222   0.111     0.111     56.6      0.111         19.3      
27.0      0.109       0.109      1.43e+02    0.00222   0.119     0.119     52.4      0.111         19.0      
28.0      0.105       0.105      99.4        0.00222   0.115     0.114     64.4      0.111         18.9      
29.0      0.105       0.105      98.7        0.00222   0.112     0.112     87.8      0.111         18.7      
30.0      0.103       0.103      1.2e+02     0.00222   0.122     0.121     67.9      0.111         18.8      
31.0      0.101       0.101      1.23e+02    0.00222   0.11      0.109     1.2e+02   0.11          19.9      
32.0      0.0978      0.0978     1.28e+02    0.00222   0.137     0.137     90.5      0.11          18.8      
33.0      0.101       0.101      1.41e+02    0.00222   0.11      0.111     29.0      0.11          19.9      
34.0      0.0953      0.0953     85.8        0.00222   0.106     0.106     53.0      0.106         19.6      
35.0      0.0966      0.0966     1.17e+02    0.00222   0.12      0.119     63.8      0.106         19.0      
36.0      0.103       0.103      1.13e+02    0.00222   0.11      0.11      1.92e+02  0.106         19.1      
37.0      0.0911      0.0911     1.21e+02    0.00222   0.109     0.109     62.9      0.106         18.6      
38.0      0.093       0.093      73.3        0.00222   0.102     0.102     85.7      0.102         19.3      
39.0      0.0888      0.0888     1.24e+02    0.00222   0.112     0.112     58.6      0.102         19.0      
40.0      0.0934      0.0934     1.22e+02    0.00222   0.102     0.101     40.4      0.102         19.6      
41.0      0.093       0.093      92.0        0.00222   0.106     0.106     51.0      0.102         19.3      
42.0      0.0897      0.0897     98.4        0.00222   0.102     0.102     1.17e+02  0.102         18.9      
43.0      0.0878      0.0878     1.3e+02     0.00222   0.106     0.106     19.3      0.102         18.9      
44.0      0.0866      0.0866     1.01e+02    0.00222   0.109     0.109     96.8      0.102         18.9      
45.0      0.0875      0.0875     70.3        0.00222   0.105     0.104     80.8      0.102         19.1      
46.0      0.0907      0.0907     1.06e+02    0.00222   0.114     0.114     63.0      0.102         19.5      
47.0      0.0831      0.0831     1.1e+02     0.00222   0.103     0.103     33.2      0.102         18.9      

‚Äã                                                                                          

Best trial: 7. Best value: 0.0859608:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 41/80 [5:22:34<4:29:28, 414.57s/it]
Best trial: 7. Best value: 0.0859608:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 41/80 [5:22:34<4:29:28, 414.57s/it]
Best trial: 7. Best value: 0.0859608:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 42/80 [5:22:34<5:59:05, 566.97s/it]
‚úÇÔ∏è Trial #73 pruned!
[I 2025-07-13 21:19:42,649] Trial 73 pruned. 

üöÄ Starting Trial #74 (Seed: 1406)
  Parameters:
    - lr: 0.0006161405985879846
    - dropout_rate: 0.17947638770587693
    - weight_decay: 0.0002691957489868025
    - batch_size: 96
    - hidden_features: 160
    - coulomb_param: 1.1754234026493828
    - london_param: 0.5429826820159909
    - pauli_param: 1.6089859543236646
    - R_grid: 3
train length: 12000 val length: 1500 test length: 1500 unused length: 0 seed : 1406
[0;31m<<<<<< ‚ö°Ô∏è cuda is used >>>>>>[0m
‚ñà
epoch     train_loss  train_mae  train_mape  lr        val_loss  val_mae   val_mape  best_val_mae  time    
1.0       0.595       0.595      7e+02       0.000616  0.275     0.276     1.71e+02  0.275         26.2      
2.0       0.296       0.296      3.86e+02    0.000616  0.251     0.252     7.41e+02  0.251         26.0      
3.0       0.242       0.242      3.82e+02    0.000616  0.232     0.233     2.47e+02  0.232         25.9      
4.0       0.208       0.208      2.75e+02    0.000616  0.174     0.175     2.99e+02  0.174         26.3      
5.0       0.188       0.188      2.78e+02    0.000616  0.18      0.18      2.63e+02  0.174         25.6      
6.0       0.176       0.176      3e+02       0.000616  0.157     0.157     1.27e+02  0.157         25.1      
7.0       0.17        0.17       2.78e+02    0.000616  0.165     0.166     2.27e+02  0.157         25.3      

‚Äã                                                                                          

Best trial: 7. Best value: 0.0859608:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 42/80 [5:26:00<5:59:05, 566.97s/it]
Best trial: 7. Best value: 0.0859608:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 42/80 [5:26:00<5:59:05, 566.97s/it]
Best trial: 7. Best value: 0.0859608:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 43/80 [5:26:00<4:42:51, 458.70s/it]
‚úÇÔ∏è Trial #74 pruned!
[I 2025-07-13 21:23:08,745] Trial 74 pruned. 

üöÄ Starting Trial #75 (Seed: 1416)
  Parameters:
    - lr: 0.0011806881183950132
    - dropout_rate: 0.18785256484328675
    - weight_decay: 9.290759110234222e-06
    - batch_size: 128
    - hidden_features: 128
    - coulomb_param: 1.5096871211610903
    - london_param: 0.7191488563728002
    - pauli_param: 1.3835869736206927
    - R_grid: 5
train length: 12000 val length: 1500 test length: 1500 unused length: 0 seed : 1416
[0;31m<<<<<< ‚ö°Ô∏è cuda is used >>>>>>[0m
‚ñà
epoch     train_loss  train_mae  train_mape  lr        val_loss  val_mae   val_mape  best_val_mae  time    
1.0       0.608       0.609      1.21e+03    0.00118   0.312     0.313     6.67e+02  0.312         20.7      
2.0       0.275       0.275      5.21e+02    0.00118   0.302     0.303     8.28e+02  0.302         20.6      
3.0       0.233       0.233      3.43e+02    0.00118   0.245     0.245     3.48e+02  0.245         20.4      
4.0       0.216       0.215      3.61e+02    0.00118   0.274     0.274     2.1e+02   0.245         20.1      
5.0       0.196       0.196      2.85e+02    0.00118   0.292     0.292     1.74e+02  0.245         19.9      

‚Äã                                                                                          

Best trial: 7. Best value: 0.0859608:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 43/80 [5:28:02<4:42:51, 458.70s/it]
Best trial: 7. Best value: 0.0859608:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 43/80 [5:28:03<4:42:51, 458.70s/it]
Best trial: 7. Best value: 0.0859608:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 44/80 [5:28:03<3:34:37, 357.71s/it]
‚úÇÔ∏è Trial #75 pruned!
[I 2025-07-13 21:25:10,822] Trial 75 pruned. 

üöÄ Starting Trial #76 (Seed: 1426)
  Parameters:
    - lr: 0.0004685780366973741
    - dropout_rate: 0.14465264835225738
    - weight_decay: 0.0003562757434718507
    - batch_size: 48
    - hidden_features: 96
    - coulomb_param: 1.036806716047176
    - london_param: 0.6769127905416477
    - pauli_param: 4.1256630960701095
    - R_grid: 5
train length: 12000 val length: 1500 test length: 1500 unused length: 0 seed : 1426
[0;31m<<<<<< ‚ö°Ô∏è cuda is used >>>>>>[0m
‚ñà
epoch     train_loss  train_mae  train_mape  lr        val_loss  val_mae   val_mape  best_val_mae  time    
1.0       0.443       0.443      6.21e+02    0.000469  0.297     0.297     2.85e+02  0.297         31.9      
2.0       0.26        0.26       3.48e+02    0.000469  0.24      0.241     3.41e+02  0.24          31.9      
3.0       0.221       0.221      2.35e+02    0.000469  0.189     0.19      2.32e+02  0.189         31.8      
4.0       0.2         0.2        2.28e+02    0.000469  0.161     0.163     3.02e+02  0.161         32.1      
5.0       0.185       0.185      1.9e+02     0.000469  0.161     0.162     3.03e+02  0.161         31.9      
6.0       0.177       0.177      1.85e+02    0.000469  0.165     0.166     2.06e+02  0.161         31.8      
7.0       0.166       0.166      1.78e+02    0.000469  0.153     0.154     1.38e+02  0.153         32.2      

‚Äã                                                                                          

Best trial: 7. Best value: 0.0859608:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 44/80 [5:32:17<3:34:37, 357.71s/it]
Best trial: 7. Best value: 0.0859608:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 44/80 [5:32:17<3:34:37, 357.71s/it]
Best trial: 7. Best value: 0.0859608:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 45/80 [5:32:17<3:10:37, 326.79s/it]
‚úÇÔ∏è Trial #76 pruned!
[I 2025-07-13 21:29:25,440] Trial 76 pruned. 

üöÄ Starting Trial #77 (Seed: 1436)
  Parameters:
    - lr: 0.0005698576930976432
    - dropout_rate: 0.10427776545254248
    - weight_decay: 0.00035262335925205534
    - batch_size: 48
    - hidden_features: 96
    - coulomb_param: 0.8911195555870125
    - london_param: 0.6323074511560739
    - pauli_param: 4.357528265087965
    - R_grid: 5
train length: 12000 val length: 1500 test length: 1500 unused length: 0 seed : 1436
[0;31m<<<<<< ‚ö°Ô∏è cuda is used >>>>>>[0m
‚ñà
epoch     train_loss  train_mae  train_mape  lr        val_loss  val_mae   val_mape  best_val_mae  time    
1.0       0.415       0.415      4.18e+02    0.00057   0.303     0.299     1.88e+02  0.303         31.1      
2.0       0.261       0.261      2.73e+02    0.00057   0.222     0.218     2.02e+02  0.222         31.9      
3.0       0.22        0.22       2.46e+02    0.00057   0.204     0.202     2.4e+02   0.204         31.6      
4.0       0.198       0.198      2.56e+02    0.00057   0.183     0.181     1.92e+02  0.183         32.4      
5.0       0.177       0.177      2.22e+02    0.00057   0.182     0.183     2.11e+02  0.182         31.9      
6.0       0.169       0.169      1.48e+02    0.00057   0.156     0.156     2.24e+02  0.156         32.0      
7.0       0.163       0.163      1.93e+02    0.00057   0.193     0.192     2.1e+02   0.156         31.3      

‚Äã                                                                                          

Best trial: 7. Best value: 0.0859608:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 45/80 [5:36:31<3:10:37, 326.79s/it]
Best trial: 7. Best value: 0.0859608:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 45/80 [5:36:32<3:10:37, 326.79s/it]
Best trial: 7. Best value: 0.0859608:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 46/80 [5:36:32<2:52:54, 305.12s/it]
‚úÇÔ∏è Trial #77 pruned!
[I 2025-07-13 21:33:39,954] Trial 77 pruned. 

üöÄ Starting Trial #78 (Seed: 1446)
  Parameters:
    - lr: 0.000710293039443355
    - dropout_rate: 0.11742323977492009
    - weight_decay: 0.00018124687304691385
    - batch_size: 48
    - hidden_features: 96
    - coulomb_param: 1.1234482159801449
    - london_param: 1.5032319901931452
    - pauli_param: 4.537060489896154
    - R_grid: 5
train length: 12000 val length: 1500 test length: 1500 unused length: 0 seed : 1446
[0;31m<<<<<< ‚ö°Ô∏è cuda is used >>>>>>[0m
‚ñà
epoch     train_loss  train_mae  train_mape  lr        val_loss  val_mae   val_mape  best_val_mae  time    
1.0       0.461       0.461      3.59e+02    0.00071   0.397     0.397     3.85e+02  0.397         32.0      
2.0       0.259       0.259      1.6e+02     0.00071   0.22      0.222     1.88e+02  0.22          31.6      
3.0       0.217       0.217      2.65e+02    0.00071   0.197     0.198     2.68e+02  0.197         32.1      
4.0       0.199       0.199      1.55e+02    0.00071   0.22      0.222     5.6e+02   0.197         31.0      
5.0       0.191       0.191      1.81e+02    0.00071   0.184     0.186     1.67e+02  0.184         31.3      

‚Äã                                                                                          

Best trial: 7. Best value: 0.0859608:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 46/80 [5:39:41<2:52:54, 305.12s/it]
Best trial: 7. Best value: 0.0859608:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 46/80 [5:39:42<2:52:54, 305.12s/it]
Best trial: 7. Best value: 0.0859608:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 47/80 [5:39:42<2:28:48, 270.57s/it]
‚úÇÔ∏è Trial #78 pruned!
[I 2025-07-13 21:36:49,970] Trial 78 pruned. 

üöÄ Starting Trial #79 (Seed: 1456)
  Parameters:
    - lr: 0.0007983815898534017
    - dropout_rate: 0.15424695934410187
    - weight_decay: 1.3353390571136753e-06
    - batch_size: 48
    - hidden_features: 96
    - coulomb_param: 1.0410153164573903
    - london_param: 0.806883944436394
    - pauli_param: 3.9277737613656054
    - R_grid: 5
train length: 12000 val length: 1500 test length: 1500 unused length: 0 seed : 1456
[0;31m<<<<<< ‚ö°Ô∏è cuda is used >>>>>>[0m
‚ñà
epoch     train_loss  train_mae  train_mape  lr        val_loss  val_mae   val_mape  best_val_mae  time    
1.0       0.448       0.448      6.81e+02    0.000798  0.267     0.268     1.64e+02  0.267         31.5      
2.0       0.274       0.274      3.28e+02    0.000798  0.227     0.228     1.16e+02  0.227         32.2      
3.0       0.222       0.222      2.41e+02    0.000798  0.204     0.206     1.98e+02  0.204         31.8      
4.0       0.203       0.203      2.14e+02    0.000798  0.185     0.186     2.9e+02   0.185         32.0      
5.0       0.183       0.183      1.78e+02    0.000798  0.165     0.166     1.25e+02  0.165         31.7      
6.0       0.171       0.171      1.47e+02    0.000798  0.172     0.174     2.49e+02  0.165         31.4      
7.0       0.168       0.168      1.55e+02    0.000798  0.17      0.171     3.95e+02  0.165         31.4      

‚Äã                                                                                          

Best trial: 7. Best value: 0.0859608:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 47/80 [5:43:56<2:28:48, 270.57s/it]
Best trial: 7. Best value: 0.0859608:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 47/80 [5:43:56<2:28:48, 270.57s/it]
Best trial: 7. Best value: 0.0859608:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 48/80 [5:43:56<2:21:41, 265.66s/it]
‚úÇÔ∏è Trial #79 pruned!
[I 2025-07-13 21:41:04,168] Trial 79 pruned. 

üöÄ Starting Trial #80 (Seed: 1466)
  Parameters:
    - lr: 0.0005202029644904958
    - dropout_rate: 0.1364478010752424
    - weight_decay: 2.964423565684646e-05
    - batch_size: 48
    - hidden_features: 96
    - coulomb_param: 0.9399030231641862
    - london_param: 0.9422852937146096
    - pauli_param: 4.185252721775202
    - R_grid: 5
train length: 12000 val length: 1500 test length: 1500 unused length: 0 seed : 1466
[0;31m<<<<<< ‚ö°Ô∏è cuda is used >>>>>>[0m
‚ñà
epoch     train_loss  train_mae  train_mape  lr        val_loss  val_mae   val_mape  best_val_mae  time    
1.0       0.447       0.447      7.28e+02    0.00052   0.342     0.343     5.23e+02  0.342         31.7      
2.0       0.263       0.263      3.42e+02    0.00052   0.265     0.267     2.18e+02  0.265         32.0      
3.0       0.232       0.232      3.39e+02    0.00052   0.216     0.217     1.88e+02  0.216         32.6      
4.0       0.209       0.209      2.98e+02    0.00052   0.195     0.194     2.07e+02  0.195         31.7      
5.0       0.189       0.189      2.04e+02    0.00052   0.177     0.177     1.71e+02  0.177         31.3      

‚Äã                                                                                          

Best trial: 7. Best value: 0.0859608:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 48/80 [5:47:07<2:21:41, 265.66s/it]
Best trial: 7. Best value: 0.0859608:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 48/80 [5:47:07<2:21:41, 265.66s/it]
Best trial: 7. Best value: 0.0859608:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 49/80 [5:47:07<2:05:44, 243.37s/it]
‚úÇÔ∏è Trial #80 pruned!
[I 2025-07-13 21:44:15,511] Trial 80 pruned. 

üöÄ Starting Trial #81 (Seed: 1476)
  Parameters:
    - lr: 0.0008860367215018014
    - dropout_rate: 0.11202799642347236
    - weight_decay: 0.00040990630479205686
    - batch_size: 48
    - hidden_features: 192
    - coulomb_param: 1.6936549702572095
    - london_param: 0.7216094191424003
    - pauli_param: 3.3213266630796925
    - R_grid: 4
train length: 12000 val length: 1500 test length: 1500 unused length: 0 seed : 1476
[0;31m<<<<<< ‚ö°Ô∏è cuda is used >>>>>>[0m
‚ñà
epoch     train_loss  train_mae  train_mape  lr        val_loss  val_mae   val_mape  best_val_mae  time    
1.0       0.572       0.572      5.85e+02    0.000886  0.361     0.364     1.11e+03  0.361         38.2      